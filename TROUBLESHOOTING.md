# üîß Guide de d√©pannage

## ‚ùå Erreur : 'Prediction' object has no attribute 'rationale'

### Cause
Cette erreur se produit avec certaines versions de DSPy o√π l'attribut pour le raisonnement a un nom diff√©rent.

### ‚úÖ Solution rapide

Utilisez la version simplifi√©e du code :

```bash
python main_simple.py
```

Cette version √©vite compl√®tement le probl√®me et fonctionne avec toutes les versions de DSPy.

### ‚úÖ Solution alternative

Si vous voulez continuer √† utiliser `main.py`, le fichier a √©t√© corrig√© automatiquement. Si vous avez encore des probl√®mes, voici le correctif manuel :

Dans `main.py`, remplacez :

```python
def forward(self, ticket):
    result = self.classifier(ticket=ticket)
    return dspy.Prediction(
        category=result.category,
        priority=result.priority,
        reasoning=result.rationale  # ‚Üê PROBL√àME ICI
    )
```

Par :

```python
def forward(self, ticket):
    result = self.classifier(ticket=ticket)
    # Acc√®s robuste au raisonnement
    reasoning = getattr(result, 'rationale', None) or getattr(result, 'reasoning', '') or ''
    return dspy.Prediction(
        category=result.category,
        priority=result.priority,
        reasoning=reasoning
    )
```

## ‚ùå Erreur : GEPA got an unexpected keyword argument 'max_bootstrapped_demos'

### Cause
L'API de GEPA a chang√© dans les versions r√©centes de DSPy. Les anciens param√®tres ne sont plus support√©s.

### ‚úÖ Solution

Les fichiers ont √©t√© corrig√©s pour utiliser les nouveaux param√®tres. Si vous rencontrez encore cette erreur :

**Anciens param√®tres (obsol√®tes) :**
```python
optimizer = GEPA(
    metric=my_metric,
    max_bootstrapped_demos=3,
    max_labeled_demos=5,
    num_candidates=5
)
```

**Nouveaux param√®tres (actuels) :**
```python
optimizer = GEPA(
    metric=my_metric,
    breadth=5,  # Nombre de candidats par it√©ration
    depth=2     # Nombre d'it√©rations
)
```

**Consultez le guide complet :** `GEPA_API_CHANGES.md`

## ‚ùå Erreur : Connection refused to localhost:11434

### Cause
Ollama n'est pas en cours d'ex√©cution.

### ‚úÖ Solution

Dans un terminal s√©par√©, lancez :
```bash
ollama serve
```

Puis relancez votre script Python.

## ‚ùå Erreur : Model 'llama3.1:8b' not found

### Cause
Le mod√®le n'est pas t√©l√©charg√©.

### ‚úÖ Solution

```bash
ollama pull llama3.1:8b
```

Attendez que le t√©l√©chargement soit termin√© (environ 5 minutes selon votre connexion).

## ‚ùå Erreur : ModuleNotFoundError: No module named 'dspy'

### Cause
DSPy n'est pas install√©.

### ‚úÖ Solution

```bash
pip install dspy-ai
# OU
uv pip install dspy-ai
```

## ‚ùå Performance tr√®s lente

### Causes possibles
1. Mod√®le trop gros pour votre machine
2. Pas de GPU disponible
3. Peu de RAM

### ‚úÖ Solutions

**Option 1 : Utiliser un mod√®le plus petit**
```bash
ollama pull phi3:3.8b  # Seulement 2.3 GB
```

Puis dans le code :
```python
lm = dspy.LM(
    model='ollama_chat/phi3:3.8b',  # Plus rapide
    api_base='http://localhost:11434'
)
```

**Option 2 : R√©duire la temp√©rature**
```python
lm = dspy.LM(
    model='ollama_chat/llama3.1:8b',
    api_base='http://localhost:11434',
    temperature=0.1  # Plus d√©terministe = plus rapide
)
```

## ‚ùå R√©sultats incoh√©rents ou mauvais

### Causes
1. Pas assez de donn√©es d'entra√Ænement
2. Mod√®le pas assez puissant
3. Besoin d'optimisation

### ‚úÖ Solutions

**Option 1 : Ajouter plus de donn√©es**
√âditez `data.py` et ajoutez au moins 20-30 exemples.

**Option 2 : Utiliser un meilleur mod√®le**
```bash
ollama pull llama3.1:70b  # N√©cessite ~40GB RAM
```

**Option 3 : Optimiser avec GEPA**
Ex√©cutez :
```bash
python gepa_guide.py
```

## ‚ùå Erreur lors de l'optimisation GEPA

### Cause
GEPA n√©cessite plusieurs appels au LLM et peut prendre du temps.

### ‚úÖ Solutions

**Option 1 : √ätre patient**
L'optimisation GEPA avec Ollama local prend 5-10 minutes. C'est normal.

**Option 2 : R√©duire le budget**
Dans le code GEPA :
```python
optimizer = GEPA(
    metric=your_metric,
    num_candidates=3,  # Au lieu de 10
    max_rounds=1       # Au lieu de 3
)
```

**Option 3 : Utiliser un service cloud**
Si vous avez une cl√© API OpenAI :
```python
lm = dspy.LM('openai/gpt-4o-mini')
dspy.configure(lm=lm)
```

L'optimisation sera beaucoup plus rapide.

## ‚ùå ImportError: cannot import name 'GEPA'

### Cause
Version de DSPy trop ancienne.

### ‚úÖ Solution

```bash
pip install --upgrade dspy-ai
```

## üÜò Autres probl√®mes

### V√©rifier votre installation

Ex√©cutez ce script de diagnostic :

```python
import sys
print(f"Python version: {sys.version}")

try:
    import dspy
    print(f"DSPy version: {dspy.__version__}")
except:
    print("‚ùå DSPy non install√©")

try:
    import requests
    r = requests.get('http://localhost:11434/api/tags')
    if r.status_code == 200:
        print("‚úÖ Ollama fonctionne")
        models = r.json()
        print(f"Mod√®les disponibles: {[m['name'] for m in models.get('models', [])]}")
    else:
        print("‚ùå Ollama ne r√©pond pas correctement")
except:
    print("‚ùå Impossible de se connecter √† Ollama")
```

### R√©initialisation compl√®te

Si rien ne fonctionne :

```bash
# 1. D√©sinstaller DSPy
pip uninstall dspy-ai

# 2. R√©installer DSPy
pip install dspy-ai

# 3. Red√©marrer Ollama
pkill -f ollama
ollama serve &

# 4. Ret√©l√©charger un mod√®le
ollama pull llama3.1:8b

# 5. Tester avec la version simple
python main_simple.py
```

## üìö Ressources d'aide

- **DSPy GitHub Issues** : https://github.com/stanfordnlp/dspy/issues
- **DSPy Discord** : https://discord.gg/VzS6RHHK6F
- **Ollama GitHub** : https://github.com/ollama/ollama
- **Documentation DSPy** : https://dspy-docs.vercel.app/

## üí° Astuces

### Pour d√©boguer

Activez les logs d√©taill√©s :
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Pour tester la connexion Ollama

```bash
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.1:8b",
  "prompt": "Why is the sky blue?"
}'
```

Si √ßa fonctionne, Ollama est OK. Le probl√®me est dans le code Python.

---

**Besoin d'aide suppl√©mentaire ?**
Consultez le fichier `fixes.py` pour des solutions alternatives test√©es.
