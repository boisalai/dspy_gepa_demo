# üîÑ Notes sur les versions de GEPA

## ‚ö†Ô∏è Changements d'API entre versions

L'API de GEPA a √©volu√© entre les versions. Si vous rencontrez des erreurs comme :
```
TypeError: GEPA.__init__() got an unexpected keyword argument 'breadth'
AssertionError: GEPA requires a reflection language model to be provided
```

Cela signifie que vous utilisez DSPy 3.0+ avec l'ancienne API.

## ‚úÖ Param√®tres actuels (DSPy 3.0+)

### Configuration de base
```python
from dspy.teleprompt import GEPA
import dspy

# REQUIS : Un mod√®le de r√©flexion pour analyser les erreurs
reflection_lm = dspy.LM(
    model='ollama_chat/llama3.1:8b',  # ou autre mod√®le
    api_base='http://localhost:11434',
    temperature=1.0,
    max_tokens=8000
)

optimizer = GEPA(
    metric=your_metric_function,
    auto='light',  # 'light', 'medium', ou 'heavy'
    reflection_lm=reflection_lm,  # REQUIS
)
```

### Configuration avanc√©e
```python
optimizer = GEPA(
    metric=your_metric_function,
    auto='heavy',  # Optimisation approfondie
    reflection_lm=reflection_lm,  # REQUIS
    max_full_evals=30,  # Alternative √† 'auto'
)
```

## ‚ùå Anciens param√®tres (obsol√®tes dans DSPy 3.0+)

Ces param√®tres ne fonctionnent **plus** dans DSPy 3.0+ :
- `breadth` ‚Üí Remplac√© par `auto` ou `max_full_evals`
- `depth` ‚Üí Remplac√© par `auto` ou `max_full_evals`
- `max_bootstrapped_demos` ‚Üí Remplac√© par le syst√®me interne
- `max_labeled_demos` ‚Üí Remplac√© par le syst√®me interne
- `num_candidates` ‚Üí Remplac√© par `auto`

## üìä Guide de migration

Si vous avez du code ancien :

### Avant (DSPy < 3.0)
```python
optimizer = GEPA(
    metric=my_metric,
    breadth=5,
    depth=2
)
```

### Apr√®s (DSPy 3.0+)
```python
import dspy

# NOUVEAU : reflection_lm est maintenant REQUIS
reflection_lm = dspy.LM(
    model='ollama_chat/llama3.1:8b',
    api_base='http://localhost:11434',
    temperature=1.0,
    max_tokens=8000
)

optimizer = GEPA(
    metric=my_metric,
    auto='light',  # Remplace breadth/depth
    reflection_lm=reflection_lm,  # REQUIS
)
```

## üéØ Explication des param√®tres actuels (DSPy 3.0+)

### `auto` (budget automatique)
- **D√©faut** : None (un de `auto`, `max_full_evals`, ou `max_metric_calls` est requis)
- **Description** : Preset de budget d'optimisation
- **Options** :
  - `'light'` : Optimisation rapide (~5-10 min avec Ollama)
  - `'medium'` : Optimisation √©quilibr√©e (~10-20 min)
  - `'heavy'` : Optimisation approfondie (~20-40 min)
- **Recommandation** :
  - Test rapide : `'light'`
  - Production : `'medium'` ou `'heavy'`

### `reflection_lm` (mod√®le de r√©flexion)
- **Requis** : **OUI** (obligatoire dans DSPy 3.0+)
- **Type** : `dspy.LM`
- **Description** : Mod√®le utilis√© pour analyser les erreurs et proposer des am√©liorations
- **Recommandation** : Utiliser un mod√®le puissant avec `temperature=1.0`
- **Exemple** :
```python
reflection_lm = dspy.LM(
    model='ollama_chat/llama3.1:8b',
    api_base='http://localhost:11434',
    temperature=1.0,
    max_tokens=8000
)
```

### `metric` (fonction d'√©valuation)
- **Requis** : Oui
- **Type** : Fonction avec signature `(example, prediction, trace=None, pred_name=None, pred_trace=None)`
- **Retour** : Float entre 0.0 et 1.0 OU dict `{'score': float, 'feedback': str}`
- **Exemple** :
```python
def my_metric(example, prediction, trace=None, pred_name=None, pred_trace=None):
    if prediction.output == example.output:
        return 1.0
    else:
        return 0.0
```

### `max_full_evals` (alternative √† `auto`)
- **D√©faut** : None
- **Description** : Nombre maximum d'√©valuations compl√®tes sur train+val
- **Utilisation** : √Ä la place de `auto` pour un contr√¥le pr√©cis du budget

## ‚è±Ô∏è Temps d'ex√©cution estim√©s

Avec Ollama local (llama3.1:8b) et DSPy 3.0+ :

| Configuration | Temps estim√© | Usage |
|--------------|--------------|-------|
| auto='light' | ~5-10 min | Test rapide |
| auto='medium' | ~10-20 min | Standard (recommand√©) |
| auto='heavy' | ~20-40 min | Optimisation maximale |
| max_full_evals=10 | ~10-15 min | Contr√¥le pr√©cis |

## üîç V√©rifier votre version de DSPy

```python
import dspy
print(f"Version DSPy: {dspy.__version__}")
```

Si version < 2.5 :
```bash
pip install --upgrade dspy-ai
```

## üí° Conseils pratiques

### Pour √©conomiser du temps
1. Commencez avec `breadth=3, depth=1` pour valider
2. Puis augmentez progressivement
3. Utilisez un petit subset de donn√©es pour tester

### Pour maximiser les r√©sultats
1. Utilisez `breadth=10, depth=3`
2. Assurez-vous d'avoir au moins 15 exemples d'entra√Ænement
3. Testez votre m√©trique avant d'optimiser

### Pour d√©boguer
```python
# Activer les logs d√©taill√©s
import logging
logging.basicConfig(level=logging.INFO)

# Puis lancer GEPA
optimizer = GEPA(metric=my_metric, breadth=3, depth=1)
```

## üêõ Probl√®mes courants

### Erreur : "AssertionError: GEPA requires a reflection language model"
**Cause** : Le param√®tre `reflection_lm` n'est pas fourni

**Solution** :
```python
reflection_lm = dspy.LM(
    model='ollama_chat/llama3.1:8b',
    api_base='http://localhost:11434',
    temperature=1.0,
    max_tokens=8000
)
optimizer = GEPA(metric=my_metric, auto='light', reflection_lm=reflection_lm)
```

### Erreur : "unexpected keyword argument 'breadth'"
**Cause** : Utilisation de l'ancienne API avec DSPy 3.0+

**Solution** : Remplacer `breadth` et `depth` par `auto='light'` (voir ci-dessus)

### Optimisation trop lente
**Cause** : `breadth` ou `depth` trop √©lev√©s

**Solution** :
```python
# R√©duire les param√®tres
optimizer = GEPA(metric=my_metric, breadth=3, depth=1)
```

### Aucune am√©lioration apr√®s GEPA
**Causes possibles** :
1. Pas assez de donn√©es d'entra√Ænement (< 10 exemples)
2. M√©trique mal d√©finie
3. T√¢che trop simple (d√©j√† √† 90%+)

**Solutions** :
1. Ajouter plus d'exemples dans `trainset`
2. V√©rifier que la m√©trique retourne bien 0-1
3. Augmenter `breadth` et `depth`

## üìö Ressources

- **Documentation officielle** : https://dspy-docs.vercel.app/
- **Paper GEPA** : https://arxiv.org/abs/2507.19457
- **GitHub DSPy** : https://github.com/stanfordnlp/dspy
- **GitHub GEPA** : https://github.com/gepa-ai/gepa

## ‚úÖ Validation de votre configuration

Testez ce code pour v√©rifier que GEPA fonctionne avec DSPy 3.0+ :

```python
import dspy
from dspy.teleprompt import GEPA

# Configuration simple
lm = dspy.LM('ollama_chat/llama3.1:8b', api_base='http://localhost:11434')
dspy.configure(lm=lm)

# IMPORTANT : Cr√©er le mod√®le de r√©flexion (REQUIS)
reflection_lm = dspy.LM(
    model='ollama_chat/llama3.1:8b',
    api_base='http://localhost:11434',
    temperature=1.0,
    max_tokens=8000
)

# Donn√©es minimales
train_examples = [
    dspy.Example(input="Hello", output="Bonjour").with_inputs('input'),
    dspy.Example(input="Goodbye", output="Au revoir").with_inputs('input'),
]

# M√©trique simple (NOUVELLE SIGNATURE avec pred_name et pred_trace)
def metric(example, prediction, trace=None, pred_name=None, pred_trace=None):
    return 1.0 if prediction.output == example.output else 0.0

# Test GEPA
class SimpleTranslator(dspy.Module):
    def __init__(self):
        super().__init__()
        self.translate = dspy.Predict("input -> output")

    def forward(self, input):
        return self.translate(input=input)

translator = SimpleTranslator()

try:
    optimizer = GEPA(
        metric=metric,
        auto='light',
        reflection_lm=reflection_lm  # REQUIS
    )
    optimized = optimizer.compile(translator, trainset=train_examples)
    print("‚úÖ GEPA fonctionne correctement!")
except Exception as e:
    print(f"‚ùå Erreur : {e}")
```

Si ce test fonctionne, votre configuration est correcte ! üéâ
