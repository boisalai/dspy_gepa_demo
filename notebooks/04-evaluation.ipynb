{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration et pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurer le mod√®le de langage\n",
    "lm = dspy.LM(\n",
    "    model='ollama_chat/llama3.1:8b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# Configurer DSPy globalement\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donn√©es d'entra√Ænement\n",
    "trainset = [\n",
    "    {\"ticket\": \"Mon ordinateur ne d√©marre plus depuis ce matin. J'ai une pr√©sentation importante dans 2 heures.\", \"category\": \"Hardware\", \"priority\": \"Urgent\"},\n",
    "    {\"ticket\": \"Je n'arrive pas √† me connecter √† l'imprimante du 3e √©tage. √áa peut attendre.\", \"category\": \"Peripherals\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"Le VPN ne fonctionne plus. Impossible d'acc√©der aux fichiers du serveur.\", \"category\": \"Network\", \"priority\": \"High\"},\n",
    "    {\"ticket\": \"J'ai oubli√© mon mot de passe Outlook. Je peux utiliser le webmail.\", \"category\": \"Account\", \"priority\": \"Medium\"},\n",
    "    {\"ticket\": \"Le site web affiche une erreur 500. Les clients ne peuvent plus commander!\", \"category\": \"Application\", \"priority\": \"Critical\"},\n",
    "    {\"ticket\": \"Ma souris sans fil ne r√©pond plus bien. Les piles sont faibles.\", \"category\": \"Peripherals\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"Le syst√®me de paie ne calcule pas les heures suppl√©mentaires. C'est la fin du mois.\", \"category\": \"Application\", \"priority\": \"Urgent\"},\n",
    "    {\"ticket\": \"J'aimerais une mise √† jour de mon logiciel Adobe quand vous aurez le temps.\", \"category\": \"Software\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"Le serveur de base de donn√©es est tr√®s lent. Toute la production est impact√©e.\", \"category\": \"Infrastructure\", \"priority\": \"Critical\"},\n",
    "    {\"ticket\": \"Je ne re√ßois plus les emails. J'attends des r√©ponses de fournisseurs.\", \"category\": \"Email\", \"priority\": \"High\"},\n",
    "    {\"ticket\": \"Mon √©cran externe ne s'affiche plus. Je peux travailler sur le laptop.\", \"category\": \"Hardware\", \"priority\": \"Medium\"},\n",
    "    {\"ticket\": \"Le wifi de la salle A ne fonctionne pas. R√©union avec des externes dans 30 min.\", \"category\": \"Network\", \"priority\": \"Urgent\"},\n",
    "    {\"ticket\": \"Je voudrais installer Slack pour mieux collaborer avec l'√©quipe.\", \"category\": \"Software\", \"priority\": \"Medium\"},\n",
    "    {\"ticket\": \"Le syst√®me de sauvegarde a √©chou√© cette nuit selon le rapport.\", \"category\": \"Infrastructure\", \"priority\": \"High\"},\n",
    "    {\"ticket\": \"Mon clavier a une touche qui colle. C'est g√©rable mais ennuyeux.\", \"category\": \"Peripherals\", \"priority\": \"Low\"}\n",
    "]\n",
    "\n",
    "# Donn√©es de validation\n",
    "valset = [\n",
    "    {\"ticket\": \"Le serveur de fichiers est inaccessible. Personne ne peut travailler.\", \"category\": \"Infrastructure\", \"priority\": \"Critical\"},\n",
    "    {\"ticket\": \"J'ai besoin d'acc√®s au dossier comptabilit√© pour l'audit. C'est urgent.\", \"category\": \"Account\", \"priority\": \"Urgent\"},\n",
    "    {\"ticket\": \"L'√©cran de mon coll√®gue en vacances clignote. On peut attendre.\", \"category\": \"Hardware\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"Le CRM plante quand j'essaie d'exporter les contacts.\", \"category\": \"Application\", \"priority\": \"High\"},\n",
    "    {\"ticket\": \"Je voudrais changer ma photo de profil quand vous aurez un moment.\", \"category\": \"Account\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"La vid√©oconf√©rence ne fonctionne pas. R√©union avec New York dans 10 minutes!\", \"category\": \"Application\", \"priority\": \"Critical\"},\n",
    "    {\"ticket\": \"Mon antivirus affiche un message d'expiration mais tout fonctionne.\", \"category\": \"Software\", \"priority\": \"Medium\"}\n",
    "]\n",
    "\n",
    "# Cat√©gories et priorit√©s possibles\n",
    "CATEGORIES = [\"Hardware\", \"Software\", \"Network\", \"Application\", \"Infrastructure\", \"Account\", \"Email\", \"Peripherals\"]\n",
    "PRIORITIES = [\"Low\", \"Medium\", \"High\", \"Urgent\", \"Critical\"]\n",
    "\n",
    "print(f\"üìä Donn√©es charg√©es : {len(trainset)} entra√Ænement, {len(valset)} validation\")\n",
    "print(f\"üì¶ {len(CATEGORIES)} cat√©gories, {len(PRIORITIES)} priorit√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 4 : L'√©valuation\n",
    "\n",
    "## Pourquoi √©valuer ?\n",
    "\n",
    "Jusqu'√† pr√©sent, nous avons cr√©√© des modules et observ√© leurs sorties qualitativement. Mais pour :\n",
    "- **Comparer** diff√©rents modules\n",
    "- **Mesurer** les am√©liorations\n",
    "- **Optimiser** automatiquement (avec GEPA)\n",
    "\n",
    "...nous avons besoin de **mesures quantitatives** : les **m√©triques**.\n",
    "\n",
    "## Qu'est-ce qu'une m√©trique ?\n",
    "\n",
    "Une **m√©trique** est une fonction qui prend :\n",
    "- Un **exemple** avec la vraie r√©ponse (ground truth)\n",
    "- Une **pr√©diction** du mod√®le\n",
    "- Et retourne un **score** (g√©n√©ralement entre 0 et 1)\n",
    "\n",
    "### Format d'une m√©trique\n",
    "\n",
    "```python\n",
    "def ma_metrique(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    # Comparer example et prediction\n",
    "    # Retourner un score entre 0 et 1\n",
    "    return score\n",
    "```\n",
    "\n",
    "**Note** : Les param√®tres `trace`, `pred_name` et `pred_trace` sont optionnels et utilis√©s par certains optimiseurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©trique 1 : exact match (correspondance exacte)\n",
    "\n",
    "La m√©trique la plus stricte : tout doit √™tre parfait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ M√©trique : exact match\n",
      "\n",
      "Test 1 : Pr√©diction correcte\n",
      "  Attendu: Hardware | High\n",
      "  Pr√©dit:  Hardware | High\n",
      "  Score: 1.0\n",
      "\n",
      "Test 2 : Cat√©gorie correcte, priorit√© incorrecte\n",
      "  Attendu: Hardware | High\n",
      "  Pr√©dit:  Hardware | Low\n",
      "  Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "def exact_match_metric(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    M√©trique stricte : 1 si cat√©gorie ET priorit√© correctes, 0 sinon\n",
    "    \"\"\"\n",
    "    # Normaliser les cha√Ænes (minuscules, sans espaces)\n",
    "    pred_category = prediction.category.strip().lower()\n",
    "    true_category = example['category'].strip().lower()\n",
    "    \n",
    "    pred_priority = prediction.priority.strip().lower()\n",
    "    true_priority = example['priority'].strip().lower()\n",
    "    \n",
    "    # Les deux doivent √™tre corrects\n",
    "    if pred_category == true_category and pred_priority == true_priority:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Test de la m√©trique\n",
    "print(\"üéØ M√©trique : exact match\")\n",
    "print(\"\\nTest 1 : Pr√©diction correcte\")\n",
    "example1 = {\"ticket\": \"Test\", \"category\": \"Hardware\", \"priority\": \"High\"}\n",
    "pred1 = dspy.Prediction(category=\"Hardware\", priority=\"High\")\n",
    "score1 = exact_match_metric(example1, pred1)\n",
    "print(f\"  Attendu: Hardware | High\")\n",
    "print(f\"  Pr√©dit:  Hardware | High\")\n",
    "print(f\"  Score: {score1}\")\n",
    "\n",
    "print(\"\\nTest 2 : Cat√©gorie correcte, priorit√© incorrecte\")\n",
    "pred2 = dspy.Prediction(category=\"Hardware\", priority=\"Low\")\n",
    "score2 = exact_match_metric(example1, pred2)\n",
    "print(f\"  Attendu: Hardware | High\")\n",
    "print(f\"  Pr√©dit:  Hardware | Low\")\n",
    "print(f\"  Score: {score2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©trique 2 : partial match (correspondance partielle)\n",
    "\n",
    "Plus nuanc√©e : donne des points partiels si au moins un champ est correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ M√©trique : partial match\n",
      "\n",
      "Test 1 : Les deux corrects\n",
      "  Score: 1.0\n",
      "\n",
      "Test 2 : Cat√©gorie correcte uniquement\n",
      "  Score: 0.7\n",
      "\n",
      "Test 3 : Priorit√© correcte uniquement\n",
      "  Score: 0.5\n",
      "\n",
      "Test 4 : Aucun correct\n",
      "  Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "def partial_match_metric(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    M√©trique nuanc√©e avec points partiels :\n",
    "    - 1.0 : Les deux corrects\n",
    "    - 0.7 : Cat√©gorie correcte uniquement\n",
    "    - 0.5 : Priorit√© correcte uniquement\n",
    "    - 0.0 : Aucun correct\n",
    "    \"\"\"\n",
    "    pred_category = prediction.category.strip().lower()\n",
    "    true_category = example['category'].strip().lower()\n",
    "    \n",
    "    pred_priority = prediction.priority.strip().lower()\n",
    "    true_priority = example['priority'].strip().lower()\n",
    "    \n",
    "    category_match = (pred_category == true_category)\n",
    "    priority_match = (pred_priority == true_priority)\n",
    "    \n",
    "    if category_match and priority_match:\n",
    "        return 1.0\n",
    "    elif category_match:\n",
    "        return 0.7  # La cat√©gorie est plus importante\n",
    "    elif priority_match:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Test de la m√©trique\n",
    "print(\"üéØ M√©trique : partial match\")\n",
    "print(\"\\nTest 1 : Les deux corrects\")\n",
    "score1 = partial_match_metric(example1, pred1)\n",
    "print(f\"  Score: {score1}\")\n",
    "\n",
    "print(\"\\nTest 2 : Cat√©gorie correcte uniquement\")\n",
    "score2 = partial_match_metric(example1, pred2)\n",
    "print(f\"  Score: {score2}\")\n",
    "\n",
    "print(\"\\nTest 3 : Priorit√© correcte uniquement\")\n",
    "pred3 = dspy.Prediction(category=\"Software\", priority=\"High\")\n",
    "score3 = partial_match_metric(example1, pred3)\n",
    "print(f\"  Score: {score3}\")\n",
    "\n",
    "print(\"\\nTest 4 : Aucun correct\")\n",
    "pred4 = dspy.Prediction(category=\"Software\", priority=\"Low\")\n",
    "score4 = partial_match_metric(example1, pred4)\n",
    "print(f\"  Score: {score4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction d'√©valuation r√©utilisable\n",
    "\n",
    "Cr√©ons une fonction pour √©valuer n'importe quel module sur un dataset complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä √âvaluation de ChainOfThought sur le dataset de validation\n",
      "======================================================================\\n\n",
      "Score moyen (exact match): 57.14%\n",
      "Score moyen (partial match): 67.14%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_module(module, dataset, metric, verbose=False):\n",
    "    \"\"\"\n",
    "    √âvalue un module sur un dataset complet\n",
    "    \n",
    "    Args:\n",
    "        module: Le module DSPy √† √©valuer\n",
    "        dataset: Liste de dictionnaires avec 'ticket', 'category', 'priority'\n",
    "        metric: Fonction de m√©trique\n",
    "        verbose: Si True, affiche les d√©tails\n",
    "    \n",
    "    Returns:\n",
    "        float: Score moyen (entre 0 et 1)\n",
    "    \"\"\"\n",
    "    total_score = 0\n",
    "    n_examples = len(dataset)\n",
    "    \n",
    "    for i, example in enumerate(dataset):\n",
    "        # Pr√©diction\n",
    "        prediction = module(ticket=example['ticket'])\n",
    "        \n",
    "        # Calcul du score\n",
    "        score = metric(example, prediction)\n",
    "        total_score += score\n",
    "        \n",
    "        # Affichage optionnel\n",
    "        if verbose:\n",
    "            print(f\"Exemple {i+1}/{n_examples}\")\n",
    "            print(f\"  Ticket: {example['ticket'][:50]}...\")\n",
    "            print(f\"  Attendu: {example['category']} | {example['priority']}\")\n",
    "            print(f\"  Pr√©dit:  {prediction.category} | {prediction.priority}\")\n",
    "            print(f\"  Score: {score}\\\\n\")\n",
    "    \n",
    "    # Score moyen\n",
    "    avg_score = total_score / n_examples\n",
    "    return avg_score\n",
    "\n",
    "# Test de la fonction d'√©valuation\n",
    "print(\"üìä √âvaluation de ChainOfThought sur le dataset de validation\")\n",
    "print(\"=\"*70 + \"\\\\n\")\n",
    "\n",
    "score = evaluate_module(cot_classifier, valset, exact_match_metric, verbose=False)\n",
    "print(f\"Score moyen (exact match): {score:.2%}\")\n",
    "\n",
    "score_partial = evaluate_module(cot_classifier, valset, partial_match_metric, verbose=False)\n",
    "print(f\"Score moyen (partial match): {score_partial:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison de modules\n",
    "\n",
    "Maintenant que nous avons des m√©triques, comparons nos diff√©rents modules !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Comparaison des modules\n",
      "======================================================================\\n\n",
      "√âvaluation de Predict...\n",
      "√âvaluation de ChainOfThought...\n",
      "√âvaluation de Sequential...\n",
      "√âvaluation de Validated...\n",
      "√âvaluation de Ensemble...\n",
      "\\n======================================================================\n",
      "R√©sultats\n",
      "======================================================================\\n\n",
      "Module               Exact Match     Partial Match  \n",
      "--------------------------------------------------\n",
      "Predict              57.1%          87.1%         \n",
      "ChainOfThought       57.1%          67.1%         \n",
      "Sequential           42.9%          80.0%         \n",
      "Validated            57.1%          67.1%         \n",
      "Ensemble             57.1%          67.1%         \n",
      "\n",
      "üèÜ Meilleur module (exact match): Predict avec 57.1%\n"
     ]
    }
   ],
   "source": [
    "# Comparer tous nos modules\n",
    "modules_to_compare = [\n",
    "    (\"Predict\", predict_classifier),\n",
    "    (\"ChainOfThought\", cot_classifier),\n",
    "    (\"Sequential\", sequential),\n",
    "    (\"Validated\", validated),\n",
    "    (\"Ensemble\", ensemble)\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Comparaison des modules\")\n",
    "print(\"=\"*70 + \"\\\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, module in modules_to_compare:\n",
    "    print(f\"√âvaluation de {name}...\")\n",
    "    score_exact = evaluate_module(module, valset, exact_match_metric)\n",
    "    score_partial = evaluate_module(module, valset, partial_match_metric)\n",
    "    \n",
    "    results.append({\n",
    "        'module': name,\n",
    "        'exact': score_exact,\n",
    "        'partial': score_partial\n",
    "    })\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "print(\"R√©sultats\")\n",
    "print(\"=\"*70 + \"\\\\n\")\n",
    "\n",
    "print(f\"{'Module':<20} {'Exact Match':<15} {'Partial Match':<15}\")\n",
    "print(\"-\" * 50)\n",
    "for r in results:\n",
    "    print(f\"{r['module']:<20} {r['exact']:<14.1%} {r['partial']:<14.1%}\")\n",
    "\n",
    "# Trouver le meilleur\n",
    "best = max(results, key=lambda x: x['exact'])\n",
    "print(f\"\\nüèÜ Meilleur module (exact match): {best['module']} avec {best['exact']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Bonnes pratiques pour l'√©valuation\n",
    "\n",
    "### ‚úÖ √Ä faire\n",
    "\n",
    "1. **Toujours avoir un dataset de validation s√©par√©** : Ne jamais √©valuer sur les donn√©es d'entra√Ænement\n",
    "2. **Utiliser plusieurs m√©triques** : Exact match + partial match donnent une vue compl√®te\n",
    "3. **Tester sur des cas limites** : Tickets ambigus, tr√®s courts, tr√®s longs\n",
    "4. **Documenter vos m√©triques** : Expliquez ce que signifie chaque score\n",
    "5. **Comparer de mani√®re √©quitable** : M√™me dataset, m√™me m√©trique\n",
    "\n",
    "### ‚ùå √Ä √©viter\n",
    "\n",
    "1. **Une seule m√©trique** : Peut cacher des probl√®mes\n",
    "2. **Dataset trop petit** : Minimum 20-30 exemples pour validation\n",
    "3. **Ignorer les erreurs** : Analyser les √©checs est crucial\n",
    "4. **Sur-optimiser** : Attention au surapprentissage sur le dataset de validation\n",
    "\n",
    "### üìä M√©triques avanc√©es (optionnel)\n",
    "\n",
    "Pour aller plus loin, vous pouvez calculer :\n",
    "- **Pr√©cision par cat√©gorie** : Performance sur chaque cat√©gorie s√©par√©ment\n",
    "- **Matrice de confusion** : Quelles cat√©gories sont confondues\n",
    "- **Temps d'ex√©cution** : Trade-off pr√©cision/vitesse\n",
    "- **Co√ªt** : Nombre de tokens utilis√©s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy-gepa-demo (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
