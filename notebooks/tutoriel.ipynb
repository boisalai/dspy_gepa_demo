{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutoriel DSPy et GEPA : Classification Automatique de Tickets IT\n",
    "\n",
    "Ce tutoriel complet vous guide de mani√®re progressive √† travers **DSPy** (Declarative Self-improving Language Programs) et **GEPA** (Genetic-Pareto Algorithm).\n",
    "\n",
    "## Objectifs d'apprentissage\n",
    "\n",
    "1. Ma√Ætriser les **Signatures** : d√©finir les entr√©es/sorties de vos t√¢ches\n",
    "2. Comprendre les **Modules** : les diff√©rents types et comment les composer\n",
    "3. √âvaluer les performances avec des **m√©triques**\n",
    "4. Optimiser automatiquement avec les **Optimiseurs**\n",
    "5. Utiliser diff√©rents **mod√®les de langage** facilement\n",
    "6. Ma√Ætriser **GEPA** pour l'optimisation avanc√©e\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "- Python 3.9+\n",
    "- Ollama install√© et en cours d'ex√©cution\n",
    "- Un mod√®le t√©l√©charg√© (ex: `ollama pull llama3.1:8b`)\n",
    "\n",
    "## Structure du tutoriel\n",
    "\n",
    "1. **Configuration et Donn√©es** - Pr√©parer l'environnement\n",
    "2. **Les Signatures DSPy** - D√©finir ce que vous voulez faire\n",
    "3. **Les Modules DSPy** - Comment le faire\n",
    "4. **L'√âvaluation** - Mesurer les performances\n",
    "5. **Les Optimiseurs** - Am√©liorer automatiquement\n",
    "6. **Multi-Mod√®les** - Flexibilit√© entre providers\n",
    "7. **GEPA en Pratique** - Optimisation avanc√©e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration initiale\n",
    "\n",
    "Commen√ßons par installer les d√©pendances et configurer notre environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (d√©commentez si n√©cessaire)\n",
    "# !uv pip install dspy-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Biblioth√®ques import√©es avec succ√®s!\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration du mod√®le de langage\n",
    "\n",
    "Nous utilisons Ollama avec Llama 3.1, un mod√®le open-source qui fonctionne localement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Configuration de DSPy avec Ollama...\n",
      "‚úÖ DSPy configur√© avec Ollama Llama 3.1:8b\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Configuration de DSPy avec Ollama...\")\n",
    "\n",
    "# Configurer le mod√®le de langage\n",
    "lm = dspy.LM(\n",
    "    model='ollama_chat/llama3.1:8b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# Configurer DSPy globalement\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "print(\"‚úÖ DSPy configur√© avec Ollama Llama 3.1:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©paration des donn√©es\n",
    "\n",
    "Nous travaillons avec des tickets IT en fran√ßais. Chaque ticket contient :\n",
    "- Une **description** du probl√®me\n",
    "- Une **cat√©gorie** (Hardware, Software, Network, etc.)\n",
    "- Une **priorit√©** (Low, Medium, High, Urgent, Critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Donn√©es charg√©es : 15 entra√Ænement, 7 validation\n",
      "üì¶ 8 cat√©gories, 5 priorit√©s\n"
     ]
    }
   ],
   "source": [
    "# Donn√©es d'entra√Ænement\n",
    "trainset = [\n",
    "    {\"ticket\": \"Mon ordinateur ne d√©marre plus depuis ce matin. J'ai une pr√©sentation importante dans 2 heures.\", \"category\": \"Hardware\", \"priority\": \"Urgent\"},\n",
    "    {\"ticket\": \"Je n'arrive pas √† me connecter √† l'imprimante du 3e √©tage. √áa peut attendre.\", \"category\": \"Peripherals\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"Le VPN ne fonctionne plus. Impossible d'acc√©der aux fichiers du serveur.\", \"category\": \"Network\", \"priority\": \"High\"},\n",
    "    {\"ticket\": \"J'ai oubli√© mon mot de passe Outlook. Je peux utiliser le webmail.\", \"category\": \"Account\", \"priority\": \"Medium\"},\n",
    "    {\"ticket\": \"Le site web affiche une erreur 500. Les clients ne peuvent plus commander!\", \"category\": \"Application\", \"priority\": \"Critical\"},\n",
    "    {\"ticket\": \"Ma souris sans fil ne r√©pond plus bien. Les piles sont faibles.\", \"category\": \"Peripherals\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"Le syst√®me de paie ne calcule pas les heures suppl√©mentaires. C'est la fin du mois.\", \"category\": \"Application\", \"priority\": \"Urgent\"},\n",
    "    {\"ticket\": \"J'aimerais une mise √† jour de mon logiciel Adobe quand vous aurez le temps.\", \"category\": \"Software\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"Le serveur de base de donn√©es est tr√®s lent. Toute la production est impact√©e.\", \"category\": \"Infrastructure\", \"priority\": \"Critical\"},\n",
    "    {\"ticket\": \"Je ne re√ßois plus les emails. J'attends des r√©ponses de fournisseurs.\", \"category\": \"Email\", \"priority\": \"High\"},\n",
    "    {\"ticket\": \"Mon √©cran externe ne s'affiche plus. Je peux travailler sur le laptop.\", \"category\": \"Hardware\", \"priority\": \"Medium\"},\n",
    "    {\"ticket\": \"Le wifi de la salle A ne fonctionne pas. R√©union avec des externes dans 30 min.\", \"category\": \"Network\", \"priority\": \"Urgent\"},\n",
    "    {\"ticket\": \"Je voudrais installer Slack pour mieux collaborer avec l'√©quipe.\", \"category\": \"Software\", \"priority\": \"Medium\"},\n",
    "    {\"ticket\": \"Le syst√®me de sauvegarde a √©chou√© cette nuit selon le rapport.\", \"category\": \"Infrastructure\", \"priority\": \"High\"},\n",
    "    {\"ticket\": \"Mon clavier a une touche qui colle. C'est g√©rable mais ennuyeux.\", \"category\": \"Peripherals\", \"priority\": \"Low\"}\n",
    "]\n",
    "\n",
    "# Donn√©es de validation\n",
    "valset = [\n",
    "    {\"ticket\": \"Le serveur de fichiers est inaccessible. Personne ne peut travailler.\", \"category\": \"Infrastructure\", \"priority\": \"Critical\"},\n",
    "    {\"ticket\": \"J'ai besoin d'acc√®s au dossier comptabilit√© pour l'audit. C'est urgent.\", \"category\": \"Account\", \"priority\": \"Urgent\"},\n",
    "    {\"ticket\": \"L'√©cran de mon coll√®gue en vacances clignote. On peut attendre.\", \"category\": \"Hardware\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"Le CRM plante quand j'essaie d'exporter les contacts.\", \"category\": \"Application\", \"priority\": \"High\"},\n",
    "    {\"ticket\": \"Je voudrais changer ma photo de profil quand vous aurez un moment.\", \"category\": \"Account\", \"priority\": \"Low\"},\n",
    "    {\"ticket\": \"La vid√©oconf√©rence ne fonctionne pas. R√©union avec New York dans 10 minutes!\", \"category\": \"Application\", \"priority\": \"Critical\"},\n",
    "    {\"ticket\": \"Mon antivirus affiche un message d'expiration mais tout fonctionne.\", \"category\": \"Software\", \"priority\": \"Medium\"}\n",
    "]\n",
    "\n",
    "# Cat√©gories et priorit√©s possibles\n",
    "CATEGORIES = [\"Hardware\", \"Software\", \"Network\", \"Application\", \"Infrastructure\", \"Account\", \"Email\", \"Peripherals\"]\n",
    "PRIORITIES = [\"Low\", \"Medium\", \"High\", \"Urgent\", \"Critical\"]\n",
    "\n",
    "print(f\"üìä Donn√©es charg√©es : {len(trainset)} entra√Ænement, {len(valset)} validation\")\n",
    "print(f\"üì¶ {len(CATEGORIES)} cat√©gories, {len(PRIORITIES)} priorit√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : Les signatures DSPy\n",
    "\n",
    "## Qu'est-ce qu'une signature ?\n",
    "\n",
    "Une **signature** dans DSPy est une **d√©claration de ce que votre programme doit faire**, pas comment le faire.\n",
    "\n",
    "### Analogie\n",
    "Imaginez que vous engagez un assistant :\n",
    "- ‚ùå **Sans DSPy** : Vous lui donnez des instructions d√©taill√©es (\"d'abord lis le ticket, ensuite regarde si c'est hardware...\")\n",
    "- ‚úÖ **Avec DSPy** : Vous lui donnez simplement le contrat (\"je te donne un ticket, tu me donnes la cat√©gorie et la priorit√©\")\n",
    "\n",
    "### Composants d'une signature\n",
    "\n",
    "1. **Docstring** : Description de la t√¢che\n",
    "2. **Champs d'entr√©e** (`InputField`) : Ce que vous fournissez\n",
    "3. **Champs de sortie** (`OutputField`) : Ce que vous attendez\n",
    "4. **Descriptions** (optionnelles) : Pr√©cisions sur chaque champ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 1 : Signature simple\n",
    "\n",
    "La forme la plus basique d'une signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Signature simple cr√©√©e\n",
      "   - 1 entr√©e : ticket\n",
      "   - 1 sortie : category\n"
     ]
    }
   ],
   "source": [
    "class BasicSignature(dspy.Signature):\n",
    "    \"\"\"Classifier un ticket IT.\"\"\"\n",
    "    \n",
    "    ticket = dspy.InputField()\n",
    "    category = dspy.OutputField()\n",
    "\n",
    "print(\"‚úÖ Signature simple cr√©√©e\")\n",
    "print(\"   - 1 entr√©e : ticket\")\n",
    "print(\"   - 1 sortie : category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 2 : Signature avec descriptions\n",
    "\n",
    "Ajouter des descriptions aide le mod√®le √† mieux comprendre la t√¢che."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Signature avec descriptions cr√©√©e\n",
      "   Les descriptions aident le mod√®le √† mieux comprendre\n"
     ]
    }
   ],
   "source": [
    "class DescriptiveSignature(dspy.Signature):\n",
    "    \"\"\"Classifier un ticket de support IT selon sa cat√©gorie.\"\"\"\n",
    "    \n",
    "    ticket = dspy.InputField(desc=\"Description du probl√®me rapport√© par l'utilisateur\")\n",
    "    category = dspy.OutputField(desc=\"Cat√©gorie technique du probl√®me\")\n",
    "\n",
    "print(\"‚úÖ Signature avec descriptions cr√©√©e\")\n",
    "print(\"   Les descriptions aident le mod√®le √† mieux comprendre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 3 : Signature avec contraintes\n",
    "\n",
    "Sp√©cifier les valeurs possibles dans la description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Signature avec contraintes cr√©√©e\n",
      "   Les contraintes guident le mod√®le vers des r√©ponses valides\n"
     ]
    }
   ],
   "source": [
    "class ConstrainedSignature(dspy.Signature):\n",
    "    \"\"\"Classifier un ticket IT selon cat√©gorie et priorit√©.\"\"\"\n",
    "    \n",
    "    ticket = dspy.InputField(desc=\"Description du ticket de support IT\")\n",
    "    category = dspy.OutputField(desc=f\"Cat√©gorie parmi: {', '.join(CATEGORIES)}\")\n",
    "    priority = dspy.OutputField(desc=f\"Priorit√© parmi: {', '.join(PRIORITIES)}\")\n",
    "\n",
    "print(\"‚úÖ Signature avec contraintes cr√©√©e\")\n",
    "print(\"   Les contraintes guident le mod√®le vers des r√©ponses valides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 4 : Signature avec contexte suppl√©mentaire\n",
    "\n",
    "Ajouter des entr√©es contextuelles pour des t√¢ches complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Signature contextuelle cr√©√©e\n",
      "   - 2 entr√©es : ticket + historique\n",
      "   - 3 sorties : cat√©gorie + priorit√© + raisonnement\n"
     ]
    }
   ],
   "source": [
    "class ContextualSignature(dspy.Signature):\n",
    "    \"\"\"Classifier un ticket en tenant compte de l'historique utilisateur.\"\"\"\n",
    "    \n",
    "    ticket = dspy.InputField(desc=\"Description du probl√®me actuel\")\n",
    "    user_history = dspy.InputField(desc=\"Historique des tickets pr√©c√©dents de l'utilisateur\")\n",
    "    category = dspy.OutputField(desc=f\"Cat√©gorie parmi: {', '.join(CATEGORIES)}\")\n",
    "    priority = dspy.OutputField(desc=f\"Priorit√© parmi: {', '.join(PRIORITIES)}\")\n",
    "    reasoning = dspy.OutputField(desc=\"Explication de la d√©cision\")\n",
    "\n",
    "print(\"‚úÖ Signature contextuelle cr√©√©e\")\n",
    "print(\"   - 2 entr√©es : ticket + historique\")\n",
    "print(\"   - 3 sorties : cat√©gorie + priorit√© + raisonnement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 5 : Signature avec format de sortie structur√©\n",
    "\n",
    "Demander un format particulier pour la sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Signature avec sortie structur√©e cr√©√©e\n",
      "   Utile pour g√©n√©rer des rapports complets\n"
     ]
    }
   ],
   "source": [
    "class StructuredOutputSignature(dspy.Signature):\n",
    "    \"\"\"Analyser un ticket et produire un rapport structur√©.\"\"\"\n",
    "    \n",
    "    ticket = dspy.InputField(desc=\"Description du ticket\")\n",
    "    category = dspy.OutputField(desc=\"Cat√©gorie technique\")\n",
    "    priority = dspy.OutputField(desc=\"Niveau de priorit√©\")\n",
    "    estimated_time = dspy.OutputField(desc=\"Temps estim√© de r√©solution en heures\")\n",
    "    required_skills = dspy.OutputField(desc=\"Comp√©tences requises (liste s√©par√©e par des virgules)\")\n",
    "\n",
    "print(\"‚úÖ Signature avec sortie structur√©e cr√©√©e\")\n",
    "print(\"   Utile pour g√©n√©rer des rapports complets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Bonnes Pratiques pour les signatures\n",
    "\n",
    "#### ‚úÖ √Ä faire\n",
    "\n",
    "1. **Docstring claire** : D√©crivez la t√¢che en une phrase\n",
    "2. **Noms explicites** : `ticket` plut√¥t que `input`, `category` plut√¥t que `output`\n",
    "3. **Descriptions pr√©cises** : Ajoutez `desc` pour guider le mod√®le\n",
    "4. **Contraintes claires** : Listez les valeurs possibles quand applicable\n",
    "5. **Commencer simple** : Ajoutez des champs progressivement\n",
    "\n",
    "#### ‚ùå √Ä √©viter\n",
    "\n",
    "1. **Trop de champs** : Commencez avec 1-3 sorties maximum\n",
    "2. **Descriptions vagues** : \"texte\" ‚Üí \"description du probl√®me utilisateur\"\n",
    "3. **Noms g√©n√©riques** : `input1`, `output1` ‚Üí `ticket`, `category`\n",
    "4. **Instructions dans le nom** : Le nom d√©crit le contenu, pas l'action\n",
    "\n",
    "### üéØ Signature pour notre tutoriel\n",
    "\n",
    "Nous utiliserons cette signature pour le reste du tutoriel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Signature principale d√©finie : TicketClassifier\n",
      "   Cette signature sera utilis√©e dans tout le tutoriel\n"
     ]
    }
   ],
   "source": [
    "class TicketClassifier(dspy.Signature):\n",
    "    \"\"\"Classifier un ticket de support IT selon sa cat√©gorie et sa priorit√©.\"\"\"\n",
    "    \n",
    "    ticket = dspy.InputField(desc=\"Description du ticket de support IT\")\n",
    "    category = dspy.OutputField(desc=f\"Cat√©gorie parmi: {', '.join(CATEGORIES)}\")\n",
    "    priority = dspy.OutputField(desc=f\"Priorit√© parmi: {', '.join(PRIORITIES)}\")\n",
    "\n",
    "print(\"‚úÖ Signature principale d√©finie : TicketClassifier\")\n",
    "print(\"   Cette signature sera utilis√©e dans tout le tutoriel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 2 : les modules DSPy\n",
    "\n",
    "## Qu'est-ce qu'un module ?\n",
    "\n",
    "Un **module** dans DSPy est un composant qui **utilise une signature** pour g√©n√©rer des pr√©dictions.\n",
    "\n",
    "### Analogie\n",
    "- **Signature** = Le contrat (\"je te donne X, tu me donnes Y\")\n",
    "- **Module** = L'employ√© qui ex√©cute le contrat (avec sa propre m√©thode de travail)\n",
    "\n",
    "### Les diff√©rents types de modules\n",
    "\n",
    "DSPy offre plusieurs modules, chacun avec une strat√©gie diff√©rente :\n",
    "\n",
    "1. **Predict** : G√©n√©ration directe (le plus simple)\n",
    "2. **ChainOfThought** : Raisonnement avant de r√©pondre\n",
    "3. **ReAct** : Raisonnement avec actions possibles\n",
    "4. **ProgramOfThought** : G√©n√©ration de code pour raisonner\n",
    "5. **Modules personnalis√©s** : Composition de plusieurs modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1 : Predict (le plus simple)\n",
    "\n",
    "**Predict** est le module de base : il g√©n√®re directement une r√©ponse.\n",
    "\n",
    "### Fonctionnement\n",
    "1. Re√ßoit les entr√©es\n",
    "2. G√©n√®re imm√©diatement les sorties\n",
    "3. Retourne le r√©sultat\n",
    "\n",
    "### Quand l'utiliser\n",
    "- T√¢ches simples\n",
    "- Besoin de rapidit√©\n",
    "- Premi√®re version d'un syst√®me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Module : Predict\n",
      "üìù Ticket : Mon ordinateur ne d√©marre plus. J'ai une pr√©sentation dans 1 heure.\n",
      "üì¶ Cat√©gorie pr√©dite : Hardware\n",
      "‚ö° Priorit√© pr√©dite : Urgent\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un module Predict avec notre signature\n",
    "predict_classifier = dspy.Predict(TicketClassifier)\n",
    "\n",
    "# Tester sur un exemple\n",
    "test_ticket = \"Mon ordinateur ne d√©marre plus. J'ai une pr√©sentation dans 1 heure.\"\n",
    "result = predict_classifier(ticket=test_ticket)\n",
    "\n",
    "print(\"üîÆ Module : Predict\")\n",
    "print(f\"üìù Ticket : {test_ticket}\")\n",
    "print(f\"üì¶ Cat√©gorie pr√©dite : {result.category}\")\n",
    "print(f\"‚ö° Priorit√© pr√©dite : {result.priority}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-15T13:50:28.356017]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `ticket` (str): Description du ticket de support IT\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `category` (str): Cat√©gorie parmi: Hardware, Software, Network, Application, Infrastructure, Account, Email, Peripherals\n",
      "3. `priority` (str): Priorit√© parmi: Low, Medium, High, Urgent, Critical\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## ticket ## ]]\n",
      "{ticket}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## category ## ]]\n",
      "{category}\n",
      "\n",
      "[[ ## priority ## ]]\n",
      "{priority}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classifier un ticket de support IT selon sa cat√©gorie et sa priorit√©.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## ticket ## ]]\n",
      "Mon antivirus affiche un message d'expiration mais tout fonctionne.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## category ## ]]`, then `[[ ## priority ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "L'expiration de l'antivirus n'est pas une urgence, mais il est recommand√© d'en mettre √† jour pour maintenir la s√©curit√©.\n",
      "\n",
      "[[ ## category ## ]]\n",
      "Software\n",
      "\n",
      "[[ ## priority ## ]]\n",
      "Medium\n",
      "\n",
      "[[ ## completed ## ]]\n",
      " \n",
      "Note: La priorit√© est d√©finie comme \"Moyenne\" car m√™me si l'expiration de l'antivirus n'est pas une urgence, il est important de mettre √† jour les logiciels pour maintenir la s√©curit√©.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-15T13:50:28.366754]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `ticket` (str): Description du ticket de support IT\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `category` (str): Cat√©gorie parmi: Hardware, Software, Network, Application, Infrastructure, Account, Email, Peripherals\n",
      "3. `priority` (str): Priorit√© parmi: Low, Medium, High, Urgent, Critical\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## ticket ## ]]\n",
      "{ticket}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## category ## ]]\n",
      "{category}\n",
      "\n",
      "[[ ## priority ## ]]\n",
      "{priority}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classifier un ticket de support IT selon sa cat√©gorie et sa priorit√©.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## ticket ## ]]\n",
      "Mon antivirus affiche un message d'expiration mais tout fonctionne.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## category ## ]]`, then `[[ ## priority ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "L'expiration de l'antivirus n'est pas une urgence, mais il est recommand√© d'en mettre √† jour pour maintenir la s√©curit√©.\n",
      "\n",
      "[[ ## category ## ]]\n",
      "Software\n",
      "\n",
      "[[ ## priority ## ]]\n",
      "Medium\n",
      "\n",
      "[[ ## completed ## ]]\n",
      " \n",
      "Note: La priorit√© est d√©finie comme \"Moyenne\" car m√™me si l'expiration de l'antivirus n'est pas une urgence, il est important de mettre √† jour les logiciels pour maintenir la s√©curit√©.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-10-16T10:19:29.697009]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `ticket` (str): Description du ticket de support IT\n",
      "Your output fields are:\n",
      "1. `category` (str): Cat√©gorie parmi: Hardware, Software, Network, Application, Infrastructure, Account, Email, Peripherals\n",
      "2. `priority` (str): Priorit√© parmi: Low, Medium, High, Urgent, Critical\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## ticket ## ]]\n",
      "{ticket}\n",
      "\n",
      "[[ ## category ## ]]\n",
      "{category}\n",
      "\n",
      "[[ ## priority ## ]]\n",
      "{priority}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classifier un ticket de support IT selon sa cat√©gorie et sa priorit√©.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## ticket ## ]]\n",
      "Mon ordinateur ne d√©marre plus. J'ai une pr√©sentation dans 1 heure.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## category ## ]]`, then `[[ ## priority ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## category ## ]]\n",
      "Hardware\n",
      "\n",
      "[[ ## priority ## ]]\n",
      "Urgent\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2 : ChainOfThought (avec raisonnement)\n",
    "\n",
    "**ChainOfThought** demande au mod√®le de raisonner avant de r√©pondre.\n",
    "\n",
    "### Fonctionnement\n",
    "1. Re√ßoit les entr√©es\n",
    "2. **G√©n√®re d'abord un raisonnement**\n",
    "3. G√©n√®re ensuite les sorties bas√©es sur ce raisonnement\n",
    "4. Retourne le r√©sultat (avec le raisonnement)\n",
    "\n",
    "### Quand l'utiliser\n",
    "- T√¢ches complexes n√©cessitant de la r√©flexion\n",
    "- Besoin d'expliquer les d√©cisions\n",
    "- Am√©liorer la pr√©cision (+5-15% typiquement)\n",
    "\n",
    "### Avantages\n",
    "- ‚úÖ Meilleure pr√©cision\n",
    "- ‚úÖ Raisonnement inspectable\n",
    "- ‚úÖ Plus robuste sur des cas complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Module : ChainOfThought\n",
      "üìù Ticket : Mon ordinateur ne d√©marre plus. J'ai une pr√©sentation dans 1 heure.\n",
      "üí≠ Raisonnement : non disponible\n",
      "üì¶ Cat√©gorie pr√©dite : Hardware\n",
      "‚ö° Priorit√© pr√©dite : High\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un module ChainOfThought avec notre signature\n",
    "cot_classifier = dspy.ChainOfThought(TicketClassifier)\n",
    "\n",
    "# Tester sur le m√™me exemple\n",
    "result = cot_classifier(ticket=test_ticket)\n",
    "\n",
    "print(\"üß† Module : ChainOfThought\")\n",
    "print(f\"üìù Ticket : {test_ticket}\")\n",
    "print(f\"üí≠ Raisonnement : {getattr(result, 'rationale', 'non disponible')}\")\n",
    "print(f\"üì¶ Cat√©gorie pr√©dite : {result.category}\")\n",
    "print(f\"‚ö° Priorit√© pr√©dite : {result.priority}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison Predict vs ChainOfThought\n",
    "\n",
    "Testons les deux modules sur plusieurs exemples pour voir la diff√©rence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Comparaison Predict vs ChainOfThought\n",
      "======================================================================\n",
      "\n",
      "--- Exemple 1 ---\n",
      "Ticket : Le serveur de fichiers est inaccessible. Personne ne peut travailler.\n",
      "Attendu : Infrastructure | Critical\n",
      "\n",
      "  Predict : Infrastructure | High\n",
      "  ChainOfThought : Infrastructure | High\n",
      "\n",
      "--- Exemple 2 ---\n",
      "Ticket : J'ai besoin d'acc√®s au dossier comptabilit√© pour l'audit. C'est urgent.\n",
      "Attendu : Account | Urgent\n",
      "\n",
      "  Predict : Account | Urgent\n",
      "  ChainOfThought : Account | Urgent\n",
      "\n",
      "--- Exemple 3 ---\n",
      "Ticket : L'√©cran de mon coll√®gue en vacances clignote. On peut attendre.\n",
      "Attendu : Hardware | Low\n",
      "\n",
      "  Predict : Hardware | Low\n",
      "  ChainOfThought : Hardware | Low\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tester sur 3 exemples\n",
    "test_cases = valset[:3]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Comparaison Predict vs ChainOfThought\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for i, example in enumerate(test_cases, 1):\n",
    "    print(f\"--- Exemple {i} ---\")\n",
    "    print(f\"Ticket : {example['ticket']}\")\n",
    "    print(f\"Attendu : {example['category']} | {example['priority']}\\n\")\n",
    "    \n",
    "    # Predict\n",
    "    pred_result = predict_classifier(ticket=example['ticket'])\n",
    "    print(f\"  Predict : {pred_result.category} | {pred_result.priority}\")\n",
    "    \n",
    "    # ChainOfThought\n",
    "    cot_result = cot_classifier(ticket=example['ticket'])\n",
    "    print(f\"  ChainOfThought : {cot_result.category} | {cot_result.priority}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3 : ReAct (raisonnement + actions)\n",
    "\n",
    "**ReAct** alterne entre raisonnement et actions.\n",
    "\n",
    "### Fonctionnement\n",
    "1. Raisonne sur le probl√®me\n",
    "2. D√©cide d'une action √† faire (ex: chercher dans une base de donn√©es)\n",
    "3. Observe le r√©sultat de l'action\n",
    "4. Raisonne √† nouveau avec cette nouvelle information\n",
    "5. R√©p√®te jusqu'√† avoir la r√©ponse\n",
    "\n",
    "### Quand l'utiliser\n",
    "- Besoin d'interactions avec des outils externes\n",
    "- Recherche d'informations n√©cessaire\n",
    "- T√¢ches multi-√©tapes\n",
    "\n",
    "**Note** : ReAct n√©cessite de d√©finir des outils/actions disponibles. C'est plus avanc√©, nous ne le couvrirons pas en d√©tail ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4 : ProgramOfThought (g√©n√©ration de code)\n",
    "\n",
    "**ProgramOfThought** g√©n√®re du code Python pour raisonner.\n",
    "\n",
    "### Fonctionnement\n",
    "1. Analyse le probl√®me\n",
    "2. G√©n√®re du code Python pour le r√©soudre\n",
    "3. Ex√©cute le code\n",
    "4. Utilise le r√©sultat pour g√©n√©rer la r√©ponse\n",
    "\n",
    "### Quand l'utiliser\n",
    "- Probl√®mes math√©matiques\n",
    "- Calculs complexes\n",
    "- Manipulation de donn√©es structur√©es\n",
    "\n",
    "**Exemple typique** : \"Combien font 347 * 892 + 123 / 7 ?\"\n",
    "- Le mod√®le g√©n√®re : `result = 347 * 892 + 123 / 7`\n",
    "- Ex√©cute le code : `309541.57`\n",
    "- Retourne la r√©ponse\n",
    "\n",
    "**Note** : Moins pertinent pour notre classification de tickets, mais tr√®s utile pour d'autres t√¢ches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 5 : modules personnalis√©s (composition)\n",
    "\n",
    "Vous pouvez cr√©er vos propres modules en **composant** plusieurs modules existants.\n",
    "\n",
    "### Pourquoi composer des modules ?\n",
    "- D√©composer une t√¢che complexe en sous-t√¢ches\n",
    "- R√©utiliser des modules existants\n",
    "- Cr√©er des pipelines sophistiqu√©s\n",
    "\n",
    "### Exemple 1 : pipeline s√©quentiel\n",
    "\n",
    "Classifier d'abord la cat√©gorie, puis la priorit√© en fonction de la cat√©gorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Module compos√© : SequentialClassifier\n",
      "üìù Ticket : Mon ordinateur ne d√©marre plus. J'ai une pr√©sentation dans 1 heure.\n",
      "üì¶ Cat√©gorie (√©tape 1) : Hardware\n",
      "‚ö° Priorit√© (√©tape 2, bas√©e sur cat√©gorie) : Urgent\n"
     ]
    }
   ],
   "source": [
    "# D√©finir des signatures sp√©cialis√©es\n",
    "class CategoryClassifier(dspy.Signature):\n",
    "    \"\"\"D√©terminer la cat√©gorie technique d'un ticket IT.\"\"\"\n",
    "    ticket = dspy.InputField(desc=\"Description du ticket\")\n",
    "    category = dspy.OutputField(desc=f\"Cat√©gorie parmi: {', '.join(CATEGORIES)}\")\n",
    "\n",
    "class PriorityClassifier(dspy.Signature):\n",
    "    \"\"\"D√©terminer la priorit√© d'un ticket en fonction de sa cat√©gorie.\"\"\"\n",
    "    ticket = dspy.InputField(desc=\"Description du ticket\")\n",
    "    category = dspy.InputField(desc=\"Cat√©gorie technique d√©j√† identifi√©e\")\n",
    "    priority = dspy.OutputField(desc=f\"Priorit√© parmi: {', '.join(PRIORITIES)}\")\n",
    "\n",
    "# Cr√©er un module compos√©\n",
    "class SequentialClassifier(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.category_predictor = dspy.ChainOfThought(CategoryClassifier)\n",
    "        self.priority_predictor = dspy.ChainOfThought(PriorityClassifier)\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        # √âtape 1 : Pr√©dire la cat√©gorie\n",
    "        category_result = self.category_predictor(ticket=ticket)\n",
    "        \n",
    "        # √âtape 2 : Pr√©dire la priorit√© en utilisant la cat√©gorie\n",
    "        priority_result = self.priority_predictor(\n",
    "            ticket=ticket,\n",
    "            category=category_result.category\n",
    "        )\n",
    "        \n",
    "        # Retourner les deux r√©sultats\n",
    "        return dspy.Prediction(\n",
    "            category=category_result.category,\n",
    "            priority=priority_result.priority\n",
    "        )\n",
    "\n",
    "# Tester le module compos√©\n",
    "sequential = SequentialClassifier()\n",
    "result = sequential(ticket=test_ticket)\n",
    "\n",
    "print(\"üîó Module compos√© : SequentialClassifier\")\n",
    "print(f\"üìù Ticket : {test_ticket}\")\n",
    "print(f\"üì¶ Cat√©gorie (√©tape 1) : {result.category}\")\n",
    "print(f\"‚ö° Priorit√© (√©tape 2, bas√©e sur cat√©gorie) : {result.priority}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 2 : module avec validation\n",
    "\n",
    "Ajouter une √©tape de validation pour v√©rifier que les pr√©dictions sont valides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Module avec validation : ValidatedClassifier\n",
      "üì¶ Cat√©gorie valid√©e : Hardware\n",
      "‚ö° Priorit√© valid√©e : High\n"
     ]
    }
   ],
   "source": [
    "class ValidatedClassifier(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = dspy.ChainOfThought(TicketClassifier)\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        # Pr√©diction\n",
    "        result = self.classifier(ticket=ticket)\n",
    "        \n",
    "        # Validation de la cat√©gorie\n",
    "        if result.category not in CATEGORIES:\n",
    "            print(f\"‚ö†Ô∏è Cat√©gorie invalide '{result.category}', correction...\")\n",
    "            result.category = \"Application\"  # Valeur par d√©faut\n",
    "        \n",
    "        # Validation de la priorit√©\n",
    "        if result.priority not in PRIORITIES:\n",
    "            print(f\"‚ö†Ô∏è Priorit√© invalide '{result.priority}', correction...\")\n",
    "            result.priority = \"Medium\"  # Valeur par d√©faut\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Tester le module avec validation\n",
    "validated = ValidatedClassifier()\n",
    "result = validated(ticket=test_ticket)\n",
    "\n",
    "print(\"\\n‚úÖ Module avec validation : ValidatedClassifier\")\n",
    "print(f\"üì¶ Cat√©gorie valid√©e : {result.category}\")\n",
    "print(f\"‚ö° Priorit√© valid√©e : {result.priority}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 3 : module avec consensus (ensemble)\n",
    "\n",
    "Utiliser plusieurs modules et combiner leurs pr√©dictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó≥Ô∏è Module ensemble : EnsembleClassifier\n",
      "   (Combine 3 pr√©dictions par vote majoritaire)\n",
      "\n",
      "üìù Ticket : Mon ordinateur ne d√©marre plus. J'ai une pr√©sentation dans 1 heure.\n",
      "üì¶ Cat√©gorie (consensus) : Hardware\n",
      "‚ö° Priorit√© (consensus) : High\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class EnsembleClassifier(dspy.Module):\n",
    "    def __init__(self, n_models=3):\n",
    "        super().__init__()\n",
    "        # Cr√©er plusieurs modules\n",
    "        self.classifiers = [\n",
    "            dspy.ChainOfThought(TicketClassifier)\n",
    "            for _ in range(n_models)\n",
    "        ]\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        # Collecter les pr√©dictions de tous les mod√®les\n",
    "        categories = []\n",
    "        priorities = []\n",
    "        \n",
    "        for classifier in self.classifiers:\n",
    "            result = classifier(ticket=ticket)\n",
    "            categories.append(result.category)\n",
    "            priorities.append(result.priority)\n",
    "        \n",
    "        # Vote majoritaire\n",
    "        category_vote = Counter(categories).most_common(1)[0][0]\n",
    "        priority_vote = Counter(priorities).most_common(1)[0][0]\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            category=category_vote,\n",
    "            priority=priority_vote\n",
    "        )\n",
    "\n",
    "# Tester l'ensemble\n",
    "print(\"üó≥Ô∏è Module ensemble : EnsembleClassifier\")\n",
    "print(\"   (Combine 3 pr√©dictions par vote majoritaire)\")\n",
    "print(f\"\\nüìù Ticket : {test_ticket}\")\n",
    "\n",
    "ensemble = EnsembleClassifier(n_models=3)\n",
    "result = ensemble(ticket=test_ticket)\n",
    "\n",
    "print(f\"üì¶ Cat√©gorie (consensus) : {result.category}\")\n",
    "print(f\"‚ö° Priorit√© (consensus) : {result.priority}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Bonnes pratiques pour les modules\n",
    "\n",
    "### ‚úÖ √Ä faire\n",
    "\n",
    "1. **Commencer simple** : Utilisez d'abord `Predict`, puis `ChainOfThought` si besoin\n",
    "2. **Nommer clairement** : `TicketClassifier` plut√¥t que `Classifier1`\n",
    "3. **Un module = une t√¢che** : Gardez les modules focalis√©s\n",
    "4. **Composer progressivement** : Testez chaque module individuellement\n",
    "5. **Documenter** : Ajoutez des docstrings √† vos modules personnalis√©s\n",
    "\n",
    "### ‚ùå √Ä √©viter\n",
    "\n",
    "1. **Utiliser ChainOfThought partout** : Plus lent et plus co√ªteux\n",
    "2. **Modules trop complexes** : Difficiles √† d√©bugger\n",
    "3. **Trop de composition** : Peut devenir difficile √† maintenir\n",
    "4. **Ignorer les erreurs** : Toujours valider les sorties\n",
    "\n",
    "### üéØ R√©sum√© des modules\n",
    "\n",
    "| Module | Rapidit√© | Pr√©cision | Complexit√© | Usage |\n",
    "|--------|----------|-----------|------------|-------|\n",
    "| **Predict** | ‚ö°‚ö°‚ö° | üéØ | üü¢ Simple | T√¢ches simples, prototypage |\n",
    "| **ChainOfThought** | ‚ö°‚ö° | üéØüéØüéØ | üü¢ Simple | T√¢ches complexes, besoin de raisonnement |\n",
    "| **ReAct** | ‚ö° | üéØüéØüéØ | üü° Moyen | Interactions avec outils |\n",
    "| **ProgramOfThought** | ‚ö°‚ö° | üéØüéØüéØüéØ | üü° Moyen | Calculs, manipulation de donn√©es |\n",
    "| **Modules compos√©s** | ‚ö° | üéØüéØüéØüéØ | üî¥ Avanc√© | Pipelines complexes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 3 : L'√©valuation\n",
    "\n",
    "## Pourquoi √©valuer ?\n",
    "\n",
    "Jusqu'√† pr√©sent, nous avons cr√©√© des modules et observ√© leurs sorties qualitativement. Mais pour :\n",
    "- **Comparer** diff√©rents modules\n",
    "- **Mesurer** les am√©liorations\n",
    "- **Optimiser** automatiquement (avec GEPA)\n",
    "\n",
    "...nous avons besoin de **mesures quantitatives** : les **m√©triques**.\n",
    "\n",
    "## Qu'est-ce qu'une m√©trique ?\n",
    "\n",
    "Une **m√©trique** est une fonction qui prend :\n",
    "- Un **exemple** avec la vraie r√©ponse (ground truth)\n",
    "- Une **pr√©diction** du mod√®le\n",
    "- Et retourne un **score** (g√©n√©ralement entre 0 et 1)\n",
    "\n",
    "### Format d'une m√©trique\n",
    "\n",
    "```python\n",
    "def ma_metrique(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    # Comparer example et prediction\n",
    "    # Retourner un score entre 0 et 1\n",
    "    return score\n",
    "```\n",
    "\n",
    "**Note** : Les param√®tres `trace`, `pred_name` et `pred_trace` sont optionnels et utilis√©s par certains optimiseurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©trique 1 : exact match (correspondance exacte)\n",
    "\n",
    "La m√©trique la plus stricte : tout doit √™tre parfait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ M√©trique : exact match\n",
      "\n",
      "Test 1 : Pr√©diction correcte\n",
      "  Attendu: Hardware | High\n",
      "  Pr√©dit:  Hardware | High\n",
      "  Score: 1.0\n",
      "\n",
      "Test 2 : Cat√©gorie correcte, priorit√© incorrecte\n",
      "  Attendu: Hardware | High\n",
      "  Pr√©dit:  Hardware | Low\n",
      "  Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "def exact_match_metric(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    M√©trique stricte : 1 si cat√©gorie ET priorit√© correctes, 0 sinon\n",
    "    \"\"\"\n",
    "    # Normaliser les cha√Ænes (minuscules, sans espaces)\n",
    "    pred_category = prediction.category.strip().lower()\n",
    "    true_category = example['category'].strip().lower()\n",
    "    \n",
    "    pred_priority = prediction.priority.strip().lower()\n",
    "    true_priority = example['priority'].strip().lower()\n",
    "    \n",
    "    # Les deux doivent √™tre corrects\n",
    "    if pred_category == true_category and pred_priority == true_priority:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Test de la m√©trique\n",
    "print(\"üéØ M√©trique : exact match\")\n",
    "print(\"\\nTest 1 : Pr√©diction correcte\")\n",
    "example1 = {\"ticket\": \"Test\", \"category\": \"Hardware\", \"priority\": \"High\"}\n",
    "pred1 = dspy.Prediction(category=\"Hardware\", priority=\"High\")\n",
    "score1 = exact_match_metric(example1, pred1)\n",
    "print(f\"  Attendu: Hardware | High\")\n",
    "print(f\"  Pr√©dit:  Hardware | High\")\n",
    "print(f\"  Score: {score1}\")\n",
    "\n",
    "print(\"\\nTest 2 : Cat√©gorie correcte, priorit√© incorrecte\")\n",
    "pred2 = dspy.Prediction(category=\"Hardware\", priority=\"Low\")\n",
    "score2 = exact_match_metric(example1, pred2)\n",
    "print(f\"  Attendu: Hardware | High\")\n",
    "print(f\"  Pr√©dit:  Hardware | Low\")\n",
    "print(f\"  Score: {score2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©trique 2 : partial match (correspondance partielle)\n",
    "\n",
    "Plus nuanc√©e : donne des points partiels si au moins un champ est correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ M√©trique : partial match\n",
      "\n",
      "Test 1 : Les deux corrects\n",
      "  Score: 1.0\n",
      "\n",
      "Test 2 : Cat√©gorie correcte uniquement\n",
      "  Score: 0.7\n",
      "\n",
      "Test 3 : Priorit√© correcte uniquement\n",
      "  Score: 0.5\n",
      "\n",
      "Test 4 : Aucun correct\n",
      "  Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "def partial_match_metric(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    M√©trique nuanc√©e avec points partiels :\n",
    "    - 1.0 : Les deux corrects\n",
    "    - 0.7 : Cat√©gorie correcte uniquement\n",
    "    - 0.5 : Priorit√© correcte uniquement\n",
    "    - 0.0 : Aucun correct\n",
    "    \"\"\"\n",
    "    pred_category = prediction.category.strip().lower()\n",
    "    true_category = example['category'].strip().lower()\n",
    "    \n",
    "    pred_priority = prediction.priority.strip().lower()\n",
    "    true_priority = example['priority'].strip().lower()\n",
    "    \n",
    "    category_match = (pred_category == true_category)\n",
    "    priority_match = (pred_priority == true_priority)\n",
    "    \n",
    "    if category_match and priority_match:\n",
    "        return 1.0\n",
    "    elif category_match:\n",
    "        return 0.7  # La cat√©gorie est plus importante\n",
    "    elif priority_match:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Test de la m√©trique\n",
    "print(\"üéØ M√©trique : partial match\")\n",
    "print(\"\\nTest 1 : Les deux corrects\")\n",
    "score1 = partial_match_metric(example1, pred1)\n",
    "print(f\"  Score: {score1}\")\n",
    "\n",
    "print(\"\\nTest 2 : Cat√©gorie correcte uniquement\")\n",
    "score2 = partial_match_metric(example1, pred2)\n",
    "print(f\"  Score: {score2}\")\n",
    "\n",
    "print(\"\\nTest 3 : Priorit√© correcte uniquement\")\n",
    "pred3 = dspy.Prediction(category=\"Software\", priority=\"High\")\n",
    "score3 = partial_match_metric(example1, pred3)\n",
    "print(f\"  Score: {score3}\")\n",
    "\n",
    "print(\"\\nTest 4 : Aucun correct\")\n",
    "pred4 = dspy.Prediction(category=\"Software\", priority=\"Low\")\n",
    "score4 = partial_match_metric(example1, pred4)\n",
    "print(f\"  Score: {score4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction d'√©valuation r√©utilisable\n",
    "\n",
    "Cr√©ons une fonction pour √©valuer n'importe quel module sur un dataset complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä √âvaluation de ChainOfThought sur le dataset de validation\n",
      "======================================================================\\n\n",
      "Score moyen (exact match): 57.14%\n",
      "Score moyen (partial match): 67.14%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_module(module, dataset, metric, verbose=False):\n",
    "    \"\"\"\n",
    "    √âvalue un module sur un dataset complet\n",
    "    \n",
    "    Args:\n",
    "        module: Le module DSPy √† √©valuer\n",
    "        dataset: Liste de dictionnaires avec 'ticket', 'category', 'priority'\n",
    "        metric: Fonction de m√©trique\n",
    "        verbose: Si True, affiche les d√©tails\n",
    "    \n",
    "    Returns:\n",
    "        float: Score moyen (entre 0 et 1)\n",
    "    \"\"\"\n",
    "    total_score = 0\n",
    "    n_examples = len(dataset)\n",
    "    \n",
    "    for i, example in enumerate(dataset):\n",
    "        # Pr√©diction\n",
    "        prediction = module(ticket=example['ticket'])\n",
    "        \n",
    "        # Calcul du score\n",
    "        score = metric(example, prediction)\n",
    "        total_score += score\n",
    "        \n",
    "        # Affichage optionnel\n",
    "        if verbose:\n",
    "            print(f\"Exemple {i+1}/{n_examples}\")\n",
    "            print(f\"  Ticket: {example['ticket'][:50]}...\")\n",
    "            print(f\"  Attendu: {example['category']} | {example['priority']}\")\n",
    "            print(f\"  Pr√©dit:  {prediction.category} | {prediction.priority}\")\n",
    "            print(f\"  Score: {score}\\\\n\")\n",
    "    \n",
    "    # Score moyen\n",
    "    avg_score = total_score / n_examples\n",
    "    return avg_score\n",
    "\n",
    "# Test de la fonction d'√©valuation\n",
    "print(\"üìä √âvaluation de ChainOfThought sur le dataset de validation\")\n",
    "print(\"=\"*70 + \"\\\\n\")\n",
    "\n",
    "score = evaluate_module(cot_classifier, valset, exact_match_metric, verbose=False)\n",
    "print(f\"Score moyen (exact match): {score:.2%}\")\n",
    "\n",
    "score_partial = evaluate_module(cot_classifier, valset, partial_match_metric, verbose=False)\n",
    "print(f\"Score moyen (partial match): {score_partial:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison de modules\n",
    "\n",
    "Maintenant que nous avons des m√©triques, comparons nos diff√©rents modules !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Comparaison des modules\n",
      "======================================================================\\n\n",
      "√âvaluation de Predict...\n",
      "√âvaluation de ChainOfThought...\n",
      "√âvaluation de Sequential...\n",
      "√âvaluation de Validated...\n",
      "√âvaluation de Ensemble...\n",
      "\\n======================================================================\n",
      "R√©sultats\n",
      "======================================================================\\n\n",
      "Module               Exact Match     Partial Match  \n",
      "--------------------------------------------------\n",
      "Predict              57.1%          87.1%         \n",
      "ChainOfThought       57.1%          67.1%         \n",
      "Sequential           42.9%          80.0%         \n",
      "Validated            57.1%          67.1%         \n",
      "Ensemble             57.1%          67.1%         \n",
      "\n",
      "üèÜ Meilleur module (exact match): Predict avec 57.1%\n"
     ]
    }
   ],
   "source": [
    "# Comparer tous nos modules\n",
    "modules_to_compare = [\n",
    "    (\"Predict\", predict_classifier),\n",
    "    (\"ChainOfThought\", cot_classifier),\n",
    "    (\"Sequential\", sequential),\n",
    "    (\"Validated\", validated),\n",
    "    (\"Ensemble\", ensemble)\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Comparaison des modules\")\n",
    "print(\"=\"*70 + \"\\\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, module in modules_to_compare:\n",
    "    print(f\"√âvaluation de {name}...\")\n",
    "    score_exact = evaluate_module(module, valset, exact_match_metric)\n",
    "    score_partial = evaluate_module(module, valset, partial_match_metric)\n",
    "    \n",
    "    results.append({\n",
    "        'module': name,\n",
    "        'exact': score_exact,\n",
    "        'partial': score_partial\n",
    "    })\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "print(\"R√©sultats\")\n",
    "print(\"=\"*70 + \"\\\\n\")\n",
    "\n",
    "print(f\"{'Module':<20} {'Exact Match':<15} {'Partial Match':<15}\")\n",
    "print(\"-\" * 50)\n",
    "for r in results:\n",
    "    print(f\"{r['module']:<20} {r['exact']:<14.1%} {r['partial']:<14.1%}\")\n",
    "\n",
    "# Trouver le meilleur\n",
    "best = max(results, key=lambda x: x['exact'])\n",
    "print(f\"\\nüèÜ Meilleur module (exact match): {best['module']} avec {best['exact']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Bonnes pratiques pour l'√©valuation\n",
    "\n",
    "### ‚úÖ √Ä faire\n",
    "\n",
    "1. **Toujours avoir un dataset de validation s√©par√©** : Ne jamais √©valuer sur les donn√©es d'entra√Ænement\n",
    "2. **Utiliser plusieurs m√©triques** : Exact match + partial match donnent une vue compl√®te\n",
    "3. **Tester sur des cas limites** : Tickets ambigus, tr√®s courts, tr√®s longs\n",
    "4. **Documenter vos m√©triques** : Expliquez ce que signifie chaque score\n",
    "5. **Comparer de mani√®re √©quitable** : M√™me dataset, m√™me m√©trique\n",
    "\n",
    "### ‚ùå √Ä √©viter\n",
    "\n",
    "1. **Une seule m√©trique** : Peut cacher des probl√®mes\n",
    "2. **Dataset trop petit** : Minimum 20-30 exemples pour validation\n",
    "3. **Ignorer les erreurs** : Analyser les √©checs est crucial\n",
    "4. **Sur-optimiser** : Attention au surapprentissage sur le dataset de validation\n",
    "\n",
    "### üìä M√©triques avanc√©es (optionnel)\n",
    "\n",
    "Pour aller plus loin, vous pouvez calculer :\n",
    "- **Pr√©cision par cat√©gorie** : Performance sur chaque cat√©gorie s√©par√©ment\n",
    "- **Matrice de confusion** : Quelles cat√©gories sont confondues\n",
    "- **Temps d'ex√©cution** : Trade-off pr√©cision/vitesse\n",
    "- **Co√ªt** : Nombre de tokens utilis√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 4: Les optimiseurs\n",
    "\n",
    "## 4.1 Introduction: modules vs optimiseurs\n",
    "\n",
    "Jusqu'√† pr√©sent, nous avons vu des **modules** (Predict, ChainOfThought, ReAct, etc.). Ces modules **ex√©cutent** des t√¢ches en interrogeant le LLM.\n",
    "\n",
    "Les **optimiseurs**, quant √† eux, **am√©liorent** les modules en :\n",
    "- Ajoutant des exemples de d√©monstration (few-shot learning)\n",
    "- Optimisant les instructions (prompts)\n",
    "- Ajustant les param√®tres\n",
    "- S√©lectionnant les meilleures configurations\n",
    "\n",
    "**Analogie** : Si un module est comme un √©tudiant qui r√©sout un probl√®me, un optimiseur est comme un professeur qui am√©liore la m√©thode de l'√©tudiant en lui montrant des exemples et en affinant ses instructions.\n",
    "\n",
    "### Principaux optimiseurs DSPy\n",
    "\n",
    "1. **BootstrapFewShot** - Le plus simple : g√©n√®re des exemples de d√©monstration\n",
    "2. **BootstrapFewShotWithRandomSearch** - Teste plusieurs combinaisons d'exemples\n",
    "3. **MIPRO** - Optimise √† la fois les instructions et les exemples\n",
    "4. **SignatureOptimizer** - Se concentre uniquement sur l'optimisation des instructions\n",
    "5. **GEPA** - Le plus sophistiqu√© : utilise des algorithmes g√©n√©tiques et la r√©flexion LLM\n",
    "\n",
    "Dans cette section, nous allons explorer les optimiseurs 1-4. GEPA sera couvert en d√©tail dans la Partie 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 BootstrapFewShot: g√©n√©rer des exemples de d√©monstration\n",
    "\n",
    "**BootstrapFewShot** est l'optimiseur le plus simple de DSPy. Il fonctionne en :\n",
    "\n",
    "1. Ex√©cutant votre module sur les donn√©es d'entra√Ænement\n",
    "2. Gardant les pr√©dictions correctes (valid√©es par votre m√©trique)\n",
    "3. Utilisant ces pr√©dictions comme exemples de d√©monstration (few-shot)\n",
    "4. Injectant ces exemples dans le prompt du module optimis√©\n",
    "\n",
    "**Avantages** :\n",
    "- Simple √† comprendre et √† utiliser\n",
    "- Rapide √† ex√©cuter\n",
    "- Am√©lioration typique de 5-15%\n",
    "\n",
    "**Inconv√©nients** :\n",
    "- Ne modifie pas les instructions\n",
    "- Qualit√© d√©pend de la qualit√© des donn√©es d'entra√Ænement\n",
    "\n",
    "### Exemple pratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Optimisation avec BootstrapFewShot...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SimpleTicketClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      6\u001b[39m train_examples = [\n\u001b[32m      7\u001b[39m     dspy.Example(\n\u001b[32m      8\u001b[39m         ticket=ex[\u001b[33m'\u001b[39m\u001b[33mticket\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m trainset\n\u001b[32m     13\u001b[39m ]\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 2. Cr√©er le module de base\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m basic_classifier = \u001b[43mSimpleTicketClassifier\u001b[49m()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 3. √âvaluer AVANT optimisation\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Performance AVANT optimisation:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'SimpleTicketClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "print(\"üîß Optimisation avec BootstrapFewShot...\")\n",
    "\n",
    "# 1. Pr√©parer les donn√©es au format DSPy\n",
    "train_examples = [\n",
    "    dspy.Example(\n",
    "        ticket=ex['ticket'],\n",
    "        category=ex['category'],\n",
    "        priority=ex['priority']\n",
    "    ).with_inputs('ticket')\n",
    "    for ex in trainset\n",
    "]\n",
    "\n",
    "# 2. Cr√©er le module de base\n",
    "basic_classifier = SimpleTicketClassifier()\n",
    "\n",
    "# 3. √âvaluer AVANT optimisation\n",
    "print(\"\\nüìä Performance AVANT optimisation:\")\n",
    "score_before = evaluate_module(basic_classifier, val_examples, exact_match_metric)\n",
    "print(f\"   Score: {score_before:.2%}\")\n",
    "\n",
    "# 4. Configurer l'optimiseur BootstrapFewShot\n",
    "optimizer = BootstrapFewShot(\n",
    "    metric=exact_match_metric,\n",
    "    max_bootstrapped_demos=4,  # Nombre d'exemples √† g√©n√©rer\n",
    "    max_labeled_demos=4         # Nombre max d'exemples √† utiliser\n",
    ")\n",
    "\n",
    "# 5. Compiler (optimiser) le module\n",
    "print(\"\\nüîÑ Compilation avec BootstrapFewShot...\")\n",
    "optimized_classifier = optimizer.compile(\n",
    "    student=basic_classifier,\n",
    "    trainset=train_examples\n",
    ")\n",
    "\n",
    "# 6. √âvaluer APR√àS optimisation\n",
    "print(\"\\nüìä Performance APR√àS optimisation:\")\n",
    "score_after = evaluate_module(optimized_classifier, val_examples, exact_match_metric)\n",
    "print(f\"   Score: {score_after:.2%}\")\n",
    "\n",
    "# 7. Calculer l'am√©lioration\n",
    "improvement = ((score_after - score_before) / score_before) * 100 if score_before > 0 else 0\n",
    "print(f\"\\nüìà Am√©lioration: {improvement:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecter les exemples g√©n√©r√©s\n",
    "\n",
    "BootstrapFewShot a ajout√© des exemples de d√©monstration au module. Nous pouvons les visualiser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecter les exemples de d√©monstration ajout√©s par BootstrapFewShot\n",
    "if hasattr(optimized_classifier, 'classifier'):\n",
    "    predictor = optimized_classifier.classifier\n",
    "    \n",
    "    if hasattr(predictor, 'demos') and predictor.demos:\n",
    "        print(f\"üìö BootstrapFewShot a ajout√© {len(predictor.demos)} exemples de d√©monstration:\\n\")\n",
    "        \n",
    "        for i, demo in enumerate(predictor.demos[:3], 1):  # Afficher les 3 premiers\n",
    "            print(f\"Exemple {i}:\")\n",
    "            print(f\"  Ticket: {demo.ticket[:80]}...\")\n",
    "            print(f\"  Cat√©gorie: {demo.category}\")\n",
    "            print(f\"  Priorit√©: {demo.priority}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Aucun exemple de d√©monstration trouv√© (ou version DSPy diff√©rente)\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Structure du module diff√©rente de celle attendue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 MIPRO: optimisation des instructions et exemples\n",
    "\n",
    "**MIPRO** (Multi-prompt Instruction Proposal Optimizer) est un optimiseur plus avanc√© qui :\n",
    "\n",
    "1. **G√©n√®re plusieurs variantes d'instructions** pour votre signature\n",
    "2. **S√©lectionne les meilleurs exemples** de d√©monstration\n",
    "3. **Teste diff√©rentes combinaisons** (instructions √ó exemples)\n",
    "4. **Garde la meilleure configuration** selon votre m√©trique\n",
    "\n",
    "**Avantages** :\n",
    "- Optimise √† la fois les instructions et les exemples\n",
    "- Am√©lioration typique de 10-25%\n",
    "- Explore l'espace des possibilit√©s de mani√®re syst√©matique\n",
    "\n",
    "**Inconv√©nients** :\n",
    "- Plus lent que BootstrapFewShot (n√©cessite plus d'appels LLM)\n",
    "- Peut prendre 10-20 minutes avec Ollama local\n",
    "\n",
    "### Exemple pratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import MIPRO\n",
    "\n",
    "print(\"üöÄ Optimisation avec MIPRO...\")\n",
    "print(\"‚è∞ Attention : Cela peut prendre 10-20 minutes avec Ollama\\n\")\n",
    "\n",
    "# 1. Cr√©er un module de base\n",
    "mipro_classifier = SimpleTicketClassifier()\n",
    "\n",
    "# 2. Configurer MIPRO\n",
    "optimizer = MIPRO(\n",
    "    metric=exact_match_metric,\n",
    "    num_candidates=5,           # Nombre de variantes d'instructions √† g√©n√©rer\n",
    "    init_temperature=1.0        # Temp√©rature pour la g√©n√©ration d'instructions\n",
    ")\n",
    "\n",
    "# 3. Compiler avec MIPRO\n",
    "# Note: MIPRO n√©cessite √† la fois trainset et valset (optionnel)\n",
    "print(\"üîÑ Compilation avec MIPRO (cela va prendre du temps)...\")\n",
    "\n",
    "try:\n",
    "    mipro_optimized = optimizer.compile(\n",
    "        student=mipro_classifier,\n",
    "        trainset=train_examples,\n",
    "        max_bootstrapped_demos=3,  # Nombre d'exemples √† g√©n√©rer\n",
    "        max_labeled_demos=3,        # Nombre max d'exemples √† utiliser\n",
    "        requires_permission_to_run=False  # Pas de confirmation interactive\n",
    "    )\n",
    "    \n",
    "    # 4. √âvaluer le r√©sultat\n",
    "    print(\"\\nüìä Performance apr√®s MIPRO:\")\n",
    "    score_mipro = evaluate_module(mipro_optimized, val_examples, exact_match_metric)\n",
    "    print(f\"   Score: {score_mipro:.2%}\")\n",
    "    \n",
    "    improvement_mipro = ((score_mipro - score_before) / score_before) * 100 if score_before > 0 else 0\n",
    "    print(f\"   Am√©lioration vs baseline: {improvement_mipro:+.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur lors de l'optimisation MIPRO: {e}\")\n",
    "    print(\"   MIPRO n√©cessite une configuration sp√©cifique selon la version de DSPy\")\n",
    "    print(\"   Consultez la documentation DSPy pour plus de d√©tails.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Autres optimiseurs importants\n",
    "\n",
    "### SignatureOptimizer\n",
    "\n",
    "**SignatureOptimizer** se concentre uniquement sur l'optimisation des instructions de votre signature, sans ajouter d'exemples de d√©monstration.\n",
    "\n",
    "**Utilisation** :\n",
    "```python\n",
    "from dspy.teleprompt import SignatureOptimizer\n",
    "\n",
    "optimizer = SignatureOptimizer(\n",
    "    metric=exact_match_metric,\n",
    "    breadth=10,  # Nombre de variantes √† g√©n√©rer\n",
    "    depth=3      # Nombre d'it√©rations de raffinement\n",
    ")\n",
    "\n",
    "optimized = optimizer.compile(student=classifier, trainset=train_examples)\n",
    "```\n",
    "\n",
    "**Avantages** :\n",
    "- Rapide (pas de g√©n√©ration d'exemples)\n",
    "- Am√©liore la clart√© des instructions\n",
    "- Bon pour les t√¢ches o√π les exemples ne sont pas critiques\n",
    "\n",
    "**Inconv√©nients** :\n",
    "- Am√©lioration modeste (5-10%)\n",
    "- Ne tire pas parti du few-shot learning\n",
    "\n",
    "### BootstrapFewShotWithRandomSearch\n",
    "\n",
    "Extension de BootstrapFewShot qui teste plusieurs combinaisons al√©atoires d'exemples.\n",
    "\n",
    "**Utilisation** :\n",
    "```python\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "optimizer = BootstrapFewShotWithRandomSearch(\n",
    "    metric=exact_match_metric,\n",
    "    max_bootstrapped_demos=4,\n",
    "    num_candidate_programs=8  # Nombre de combinaisons √† tester\n",
    ")\n",
    "\n",
    "optimized = optimizer.compile(student=classifier, trainset=train_examples)\n",
    "```\n",
    "\n",
    "**Avantages** :\n",
    "- Trouve de meilleures combinaisons d'exemples\n",
    "- Plus robuste que BootstrapFewShot simple\n",
    "- Am√©lioration typique de 8-18%\n",
    "\n",
    "**Inconv√©nients** :\n",
    "- Plus lent que BootstrapFewShot (teste plusieurs combinaisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Comparaison des optimiseurs\n",
    "\n",
    "| Optimiseur | Ce qu'il optimise | Vitesse | Am√©lioration typique | Complexit√© | Quand l'utiliser |\n",
    "|------------|------------------|---------|---------------------|------------|------------------|\n",
    "| **BootstrapFewShot** | Exemples uniquement | ‚ö°‚ö°‚ö° Rapide | 5-15% | Simple | Premi√®re optimisation, tests rapides |\n",
    "| **BootstrapFewShotWithRandomSearch** | Exemples (avec recherche) | ‚ö°‚ö° Moyen | 8-18% | Simple | Quand vous avez un peu plus de temps |\n",
    "| **SignatureOptimizer** | Instructions uniquement | ‚ö°‚ö°‚ö° Rapide | 5-10% | Moyen | T√¢ches o√π les instructions sont critiques |\n",
    "| **MIPRO** | Instructions + exemples | ‚ö° Lent | 10-25% | Avanc√© | Production, quand vous visez la meilleure performance |\n",
    "| **GEPA** | Instructions + exemples + r√©flexion | ‚ö° Tr√®s lent | 15-30% | Tr√®s avanc√© | Maximum de performance, recherche |\n",
    "\n",
    "### Guide de s√©lection\n",
    "\n",
    "**Pour d√©buter** :\n",
    "1. Commencez avec **BootstrapFewShot** pour comprendre le concept\n",
    "2. Si les r√©sultats sont bons, passez √† **BootstrapFewShotWithRandomSearch**\n",
    "3. Si vous avez du temps, essayez **MIPRO**\n",
    "\n",
    "**Pour la production** :\n",
    "- Si vous avez des contraintes de temps : **BootstrapFewShotWithRandomSearch**\n",
    "- Si vous visez la meilleure performance : **MIPRO** ou **GEPA**\n",
    "- Si vos instructions sont mal formul√©es : **SignatureOptimizer** d'abord, puis un autre\n",
    "\n",
    "**Pour la recherche** :\n",
    "- **GEPA** pour explorer les limites de performance\n",
    "- **MIPRO** pour une approche plus syst√©matique\n",
    "\n",
    "### Strat√©gie recommand√©e\n",
    "\n",
    "1. **Phase 1 - Exploration** : Utilisez BootstrapFewShot pour tester rapidement\n",
    "2. **Phase 2 - Am√©lioration** : Passez √† MIPRO si les r√©sultats sont prometteurs\n",
    "3. **Phase 3 - Optimisation finale** : Utilisez GEPA pour maximiser la performance (voir Partie 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Introduction √† GEPA\n",
    "\n",
    "**GEPA** (Genetic-Pareto Algorithm) est l'optimiseur le plus sophistiqu√© de DSPy. Il m√©rite une section compl√®te (Partie 7) car il combine plusieurs techniques avanc√©es :\n",
    "\n",
    "### Comment GEPA fonctionne\n",
    "\n",
    "1. **Algorithmes g√©n√©tiques** : √âvolution de populations de prompts\n",
    "2. **R√©flexion LLM** : Utilise un LLM pour analyser les erreurs et proposer des am√©liorations\n",
    "3. **Optimisation Pareto** : √âquilibre plusieurs objectifs (pr√©cision, concision, etc.)\n",
    "4. **It√©rations adaptatives** : Apprend de ses erreurs pour s'am√©liorer\n",
    "\n",
    "### Nouveaut√©s dans DSPy 3.0+\n",
    "\n",
    "GEPA a √©t√© int√©gr√© directement dans DSPy et n√©cessite maintenant :\n",
    "- Un **reflection_lm** : mod√®le d√©di√© √† l'analyse des erreurs\n",
    "- Configuration via **auto** : 'light', 'medium', ou 'heavy'\n",
    "- M√©trique compatible avec les nouveaux param√®tres\n",
    "\n",
    "### Aper√ßu rapide\n",
    "\n",
    "```python\n",
    "from dspy.teleprompt import GEPA\n",
    "\n",
    "# Configuration du mod√®le de r√©flexion\n",
    "reflection_lm = dspy.LM(\n",
    "    model='ollama_chat/llama3.1:8b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=1.0,\n",
    "    max_tokens=8000\n",
    ")\n",
    "\n",
    "# Optimiseur GEPA\n",
    "optimizer = GEPA(\n",
    "    metric=exact_match_metric,\n",
    "    auto='light',  # 'light', 'medium', ou 'heavy'\n",
    "    reflection_lm=reflection_lm\n",
    ")\n",
    "\n",
    "# Compilation\n",
    "optimized = optimizer.compile(\n",
    "    student=classifier,\n",
    "    trainset=train_examples,\n",
    "    valset=val_examples\n",
    ")\n",
    "```\n",
    "\n",
    "### Quand utiliser GEPA\n",
    "\n",
    "- ‚úÖ Vous avez du temps (15-30 minutes minimum)\n",
    "- ‚úÖ Vous visez la meilleure performance possible\n",
    "- ‚úÖ Vous avez suffisamment de donn√©es d'entra√Ænement (20+ exemples)\n",
    "- ‚úÖ Votre m√©trique est bien d√©finie\n",
    "- ‚úÖ Vous √™tes pr√™t √† exp√©rimenter avec les param√®tres\n",
    "\n",
    "**La Partie 7 de ce tutoriel couvre GEPA en profondeur avec des exemples pratiques, des comparaisons de param√®tres, et des conseils d'optimisation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 R√©sum√© de la Partie 4\n",
    "\n",
    "### Ce que nous avons appris\n",
    "\n",
    "1. **Diff√©rence modules vs optimiseurs** :\n",
    "   - Les modules **ex√©cutent** des t√¢ches\n",
    "   - Les optimiseurs **am√©liorent** les modules\n",
    "\n",
    "2. **Les optimiseurs principaux** :\n",
    "   - **BootstrapFewShot** : Simple, rapide, g√©n√®re des exemples\n",
    "   - **BootstrapFewShotWithRandomSearch** : Teste plusieurs combinaisons\n",
    "   - **SignatureOptimizer** : Optimise uniquement les instructions\n",
    "   - **MIPRO** : Optimise instructions + exemples\n",
    "   - **GEPA** : Le plus sophistiqu√© (d√©tails en Partie 7)\n",
    "\n",
    "3. **Comment choisir** :\n",
    "   - D√©buter : BootstrapFewShot\n",
    "   - Production rapide : BootstrapFewShotWithRandomSearch\n",
    "   - Meilleure performance : MIPRO ou GEPA\n",
    "   - Instructions mal formul√©es : SignatureOptimizer\n",
    "\n",
    "### Points cl√©s √† retenir\n",
    "\n",
    "- ‚úÖ Toujours √©valuer **avant** et **apr√®s** optimisation\n",
    "- ‚úÖ Commencer simple, puis complexifier\n",
    "- ‚úÖ Les optimiseurs n√©cessitent des donn√©es d'entra√Ænement de qualit√©\n",
    "- ‚úÖ Plus de temps d'optimisation = g√©n√©ralement meilleure performance\n",
    "- ‚úÖ Votre m√©trique d√©termine ce que l'optimiseur optimise\n",
    "\n",
    "### Prochaines √©tapes\n",
    "\n",
    "- **Partie 5** : Multi-mod√®les (utiliser diff√©rents LLMs)\n",
    "- **Partie 6** : Patterns avanc√©s (optionnel)\n",
    "- **Partie 7** : GEPA en pratique (optimisation approfondie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 5: Multi-mod√®les et flexibilit√©\n",
    "\n",
    "## 5.1 Introduction: pourquoi utiliser plusieurs mod√®les?\n",
    "\n",
    "DSPy offre une **abstraction puissante** : votre code reste le m√™me quel que soit le mod√®le utilis√©. Vous pouvez :\n",
    "\n",
    "1. **Changer de fournisseur** facilement (Ollama ‚Üí OpenAI ‚Üí Anthropic)\n",
    "2. **Comparer les performances** de diff√©rents mod√®les\n",
    "3. **Cr√©er des architectures hybrides** (mod√®le rapide pour cat√©gorie, mod√®le pr√©cis pour priorit√©)\n",
    "4. **Optimiser co√ªt vs performance**\n",
    "\n",
    "### Avantages du multi-mod√®les\n",
    "\n",
    "- üîÑ **Flexibilit√©** : Pas de vendor lock-in\n",
    "- üí∞ **Optimisation des co√ªts** : Mod√®le gratuit (Ollama) pour dev, mod√®le payant pour prod\n",
    "- üéØ **Performance** : Choisir le meilleur mod√®le pour chaque t√¢che\n",
    "- üß™ **Exp√©rimentation** : Tester facilement diff√©rents mod√®les\n",
    "\n",
    "### Ce que nous allons voir\n",
    "\n",
    "1. Configurer diff√©rents fournisseurs (Ollama, OpenAI, Anthropic)\n",
    "2. Comparer les performances de diff√©rents mod√®les\n",
    "3. Cr√©er des architectures hybrides\n",
    "4. G√©rer les cl√©s API de mani√®re s√©curis√©e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Configuration de diff√©rents fournisseurs\n",
    "\n",
    "### 5.2.1 Ollama (local, gratuit)\n",
    "\n",
    "Ollama permet d'ex√©cuter des mod√®les **localement** sans API key ni co√ªts.\n",
    "\n",
    "**Mod√®les recommand√©s** :\n",
    "- `llama3.1:8b` - √âquilibr√©, bon pour la plupart des t√¢ches (4.7 GB)\n",
    "- `mistral:7b` - Rapide, bon pour les t√¢ches simples (4.1 GB)\n",
    "- `qwen2.5:7b` - Haute qualit√©, excellent pour les t√¢ches complexes (4.7 GB)\n",
    "- `gemma2:9b` - Alternative de Google, tr√®s performant (5.4 GB)\n",
    "\n",
    "**Configuration** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Ollama\n",
    "lm_ollama_llama = dspy.LM(\n",
    "    model='ollama_chat/llama3.1:8b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "lm_ollama_mistral = dspy.LM(\n",
    "    model='ollama_chat/mistral:7b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "lm_ollama_qwen = dspy.LM(\n",
    "    model='ollama_chat/qwen2.5:7b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Mod√®les Ollama configur√©s:\")\n",
    "print(\"   - llama3.1:8b\")\n",
    "print(\"   - mistral:7b\")\n",
    "print(\"   - qwen2.5:7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 OpenAI (API, payant)\n",
    "\n",
    "OpenAI propose des mod√®les tr√®s performants via API.\n",
    "\n",
    "**Mod√®les recommand√©s** :\n",
    "- `gpt-4o-mini` - Rapide et √©conomique, bon rapport qualit√©/prix\n",
    "- `gpt-4o` - Haute performance, multimodal\n",
    "- `gpt-4-turbo` - √âquilibr√© performance/co√ªt\n",
    "\n",
    "**Configuration** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configuration OpenAI (n√©cessite OPENAI_API_KEY dans l'environnement)\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    lm_openai_mini = dspy.LM(\n",
    "        model='openai/gpt-4o-mini',\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    lm_openai_4o = dspy.LM(\n",
    "        model='openai/gpt-4o',\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Mod√®les OpenAI configur√©s:\")\n",
    "    print(\"   - gpt-4o-mini\")\n",
    "    print(\"   - gpt-4o\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è OPENAI_API_KEY non d√©finie - mod√®les OpenAI non disponibles\")\n",
    "    print(\"   Pour utiliser OpenAI, d√©finissez la variable d'environnement:\")\n",
    "    print(\"   export OPENAI_API_KEY='votre-cl√©-api'\")\n",
    "    lm_openai_mini = None\n",
    "    lm_openai_4o = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Anthropic (API, payant)\n",
    "\n",
    "Anthropic propose les mod√®les Claude, connus pour leur qualit√© et leur s√©curit√©.\n",
    "\n",
    "**Mod√®les recommand√©s** :\n",
    "- `claude-3-5-haiku-20241022` - Rapide et √©conomique\n",
    "- `claude-3-5-sonnet-20241022` - √âquilibr√©, excellent pour la plupart des t√¢ches\n",
    "- `claude-3-opus-20240229` - Maximum de performance\n",
    "\n",
    "**Configuration** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Anthropic (n√©cessite ANTHROPIC_API_KEY dans l'environnement)\n",
    "if os.getenv('ANTHROPIC_API_KEY'):\n",
    "    lm_claude_haiku = dspy.LM(\n",
    "        model='anthropic/claude-3-5-haiku-20241022',\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    lm_claude_sonnet = dspy.LM(\n",
    "        model='anthropic/claude-3-5-sonnet-20241022',\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Mod√®les Anthropic configur√©s:\")\n",
    "    print(\"   - claude-3-5-haiku\")\n",
    "    print(\"   - claude-3-5-sonnet\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ANTHROPIC_API_KEY non d√©finie - mod√®les Anthropic non disponibles\")\n",
    "    print(\"   Pour utiliser Anthropic, d√©finissez la variable d'environnement:\")\n",
    "    print(\"   export ANTHROPIC_API_KEY='votre-cl√©-api'\")\n",
    "    lm_claude_haiku = None\n",
    "    lm_claude_sonnet = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Comparer les performances de diff√©rents mod√®les\n",
    "\n",
    "Maintenant que nous avons configur√© plusieurs mod√®les, comparons leurs performances sur notre t√¢che de classification de tickets IT.\n",
    "\n",
    "### Fonction de benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_model(lm, model_name, examples, metric):\n",
    "    \"\"\"\n",
    "    √âvalue un mod√®le sur un ensemble d'exemples\n",
    "    \n",
    "    Args:\n",
    "        lm: Le language model DSPy\n",
    "        model_name: Nom du mod√®le (pour affichage)\n",
    "        examples: Liste d'exemples de validation\n",
    "        metric: Fonction de m√©trique\n",
    "    \n",
    "    Returns:\n",
    "        dict avec score et temps d'ex√©cution\n",
    "    \"\"\"\n",
    "    # Configurer DSPy avec ce mod√®le\n",
    "    dspy.configure(lm=lm)\n",
    "    \n",
    "    # Cr√©er un classifier avec ce mod√®le\n",
    "    classifier = SimpleTicketClassifier()\n",
    "    \n",
    "    # Mesurer le temps\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # √âvaluer\n",
    "    total_score = 0\n",
    "    for example in examples:\n",
    "        prediction = classifier(ticket=example['ticket'])\n",
    "        score = metric(example, prediction)\n",
    "        total_score += score\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculer les r√©sultats\n",
    "    avg_score = total_score / len(examples)\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'score': avg_score,\n",
    "        'time': elapsed_time\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Fonction de benchmarking d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des mod√®les Ollama\n",
    "\n",
    "Comparons les 3 mod√®les Ollama locaux :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Comparaison des mod√®les Ollama...\")\n",
    "print(\"‚è∞ Cela va prendre quelques minutes\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Benchmarker llama3.1:8b\n",
    "print(\"1/3 √âvaluation de llama3.1:8b...\")\n",
    "result_llama = benchmark_model(lm_ollama_llama, 'llama3.1:8b', valset, exact_match_metric)\n",
    "results.append(result_llama)\n",
    "print(f\"   Score: {result_llama['score']:.2%} | Temps: {result_llama['time']:.1f}s\\n\")\n",
    "\n",
    "# Benchmarker mistral:7b\n",
    "print(\"2/3 √âvaluation de mistral:7b...\")\n",
    "result_mistral = benchmark_model(lm_ollama_mistral, 'mistral:7b', valset, exact_match_metric)\n",
    "results.append(result_mistral)\n",
    "print(f\"   Score: {result_mistral['score']:.2%} | Temps: {result_mistral['time']:.1f}s\\n\")\n",
    "\n",
    "# Benchmarker qwen2.5:7b\n",
    "print(\"3/3 √âvaluation de qwen2.5:7b...\")\n",
    "result_qwen = benchmark_model(lm_ollama_qwen, 'qwen2.5:7b', valset, exact_match_metric)\n",
    "results.append(result_qwen)\n",
    "print(f\"   Score: {result_qwen['score']:.2%} | Temps: {result_qwen['time']:.1f}s\\n\")\n",
    "\n",
    "# Afficher le r√©sum√©\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä R√âSUM√â DES PERFORMANCES\")\n",
    "print(\"=\" * 60)\n",
    "for r in sorted(results, key=lambda x: x['score'], reverse=True):\n",
    "    print(f\"{r['model']:20} | Score: {r['score']:6.2%} | Temps: {r['time']:5.1f}s\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Architectures hybrides: utiliser diff√©rents mod√®les pour diff√©rentes t√¢ches\n",
    "\n",
    "Une **architecture hybride** utilise diff√©rents mod√®les pour diff√©rentes parties de votre pipeline. Par exemple :\n",
    "\n",
    "- Mod√®le **rapide et √©conomique** pour la cat√©gorisation\n",
    "- Mod√®le **pr√©cis mais co√ªteux** pour la priorisation\n",
    "\n",
    "### Avantages\n",
    "\n",
    "- üí∞ **Optimisation des co√ªts** : Utiliser des mod√®les co√ªteux uniquement quand n√©cessaire\n",
    "- ‚ö° **Optimisation de la vitesse** : Mod√®les rapides pour les t√¢ches simples\n",
    "- üéØ **Optimisation de la qualit√©** : Meilleurs mod√®les pour les t√¢ches critiques\n",
    "\n",
    "### Exemple: pipeline hybride\n",
    "\n",
    "Cr√©ons un classifier qui utilise deux mod√®les diff√©rents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridTicketClassifier(dspy.Module):\n",
    "    \"\"\"\n",
    "    Classifier hybride utilisant 2 mod√®les diff√©rents:\n",
    "    - Mod√®le rapide pour la cat√©gorie\n",
    "    - Mod√®le pr√©cis pour la priorit√©\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fast_lm, accurate_lm):\n",
    "        super().__init__()\n",
    "        self.fast_lm = fast_lm\n",
    "        self.accurate_lm = accurate_lm\n",
    "        \n",
    "        # Signature pour la cat√©gorie\n",
    "        self.category_signature = CategoryClassifier\n",
    "        \n",
    "        # Signature pour la priorit√©\n",
    "        self.priority_signature = PriorityClassifier\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        # √âtape 1: Cat√©gorisation avec le mod√®le rapide\n",
    "        with dspy.settings.context(lm=self.fast_lm):\n",
    "            category_predictor = dspy.ChainOfThought(self.category_signature)\n",
    "            category_result = category_predictor(ticket=ticket)\n",
    "        \n",
    "        # √âtape 2: Priorisation avec le mod√®le pr√©cis\n",
    "        with dspy.settings.context(lm=self.accurate_lm):\n",
    "            priority_predictor = dspy.ChainOfThought(self.priority_signature)\n",
    "            priority_result = priority_predictor(\n",
    "                ticket=ticket,\n",
    "                category=category_result.category\n",
    "            )\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            category=category_result.category,\n",
    "            priority=priority_result.priority\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ Classe HybridTicketClassifier d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester le classifier hybride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÄ Test du classifier hybride\")\n",
    "print(\"   Mod√®le rapide (cat√©gorie): mistral:7b\")\n",
    "print(\"   Mod√®le pr√©cis (priorit√©): llama3.1:8b\\n\")\n",
    "\n",
    "# Cr√©er le classifier hybride\n",
    "hybrid_classifier = HybridTicketClassifier(\n",
    "    fast_lm=lm_ollama_mistral,      # Rapide pour la cat√©gorie\n",
    "    accurate_lm=lm_ollama_llama     # Pr√©cis pour la priorit√©\n",
    ")\n",
    "\n",
    "# Configurer DSPy (requis pour l'ex√©cution)\n",
    "dspy.configure(lm=lm_ollama_llama)\n",
    "\n",
    "# Tester sur quelques exemples\n",
    "print(\"üìù Exemples de pr√©dictions:\\n\")\n",
    "\n",
    "test_tickets = [\n",
    "    \"Mon ordinateur portable ne d√©marre plus, j'ai une pr√©sentation importante dans 2 heures\",\n",
    "    \"Je voudrais acc√®s au VPN pour le t√©l√©travail quand c'est possible\",\n",
    "    \"Toutes les imprimantes de l'√©tage sont hors ligne\"\n",
    "]\n",
    "\n",
    "for i, ticket in enumerate(test_tickets, 1):\n",
    "    result = hybrid_classifier(ticket=ticket)\n",
    "    print(f\"{i}. Ticket: {ticket[:60]}...\")\n",
    "    print(f\"   ‚Üí Cat√©gorie: {result.category} | Priorit√©: {result.priority}\\n\")\n",
    "\n",
    "# √âvaluer sur l'ensemble de validation\n",
    "print(\"üìä √âvaluation sur l'ensemble de validation:\")\n",
    "score_hybrid = evaluate_module(hybrid_classifier, val_examples, exact_match_metric)\n",
    "print(f\"   Score: {score_hybrid:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Guide de s√©lection de mod√®les\n",
    "\n",
    "### Crit√®res de s√©lection\n",
    "\n",
    "| Crit√®re | Ollama (local) | OpenAI | Anthropic |\n",
    "|---------|---------------|--------|-----------|\n",
    "| **Co√ªt** | Gratuit (mat√©riel local) | Payant √† l'usage | Payant √† l'usage |\n",
    "| **Vitesse** | D√©pend du mat√©riel | Rapide (API cloud) | Rapide (API cloud) |\n",
    "| **Confidentialit√©** | ‚úÖ 100% local | ‚ö†Ô∏è Donn√©es envoy√©es √† OpenAI | ‚ö†Ô∏è Donn√©es envoy√©es √† Anthropic |\n",
    "| **Qualit√©** | Bonne (7-8B params) | Excellente | Excellente |\n",
    "| **Disponibilit√©** | N√©cessite installation | API toujours disponible | API toujours disponible |\n",
    "| **Latence** | Faible (local) | Moyenne (r√©seau) | Moyenne (r√©seau) |\n",
    "\n",
    "### Recommandations par cas d'usage\n",
    "\n",
    "#### 1. D√©veloppement et prototypage\n",
    "**Choix recommand√©** : Ollama (llama3.1:8b ou qwen2.5:7b)\n",
    "- ‚úÖ Gratuit, it√©rations rapides\n",
    "- ‚úÖ Pas de limite de requ√™tes\n",
    "- ‚úÖ Confidentialit√© des donn√©es\n",
    "\n",
    "#### 2. Production √† faible volume (<1000 requ√™tes/jour)\n",
    "**Choix recommand√©** : OpenAI (gpt-4o-mini) ou Anthropic (claude-3-5-haiku)\n",
    "- ‚úÖ Co√ªts acceptables\n",
    "- ‚úÖ Haute disponibilit√©\n",
    "- ‚úÖ Excellente qualit√©\n",
    "\n",
    "#### 3. Production √† haut volume (>10000 requ√™tes/jour)\n",
    "**Choix recommand√©** : Architecture hybride\n",
    "- Ollama pour les t√¢ches simples (cat√©gorisation)\n",
    "- API payante pour les t√¢ches critiques (priorisation)\n",
    "- ‚úÖ Optimisation du rapport co√ªt/performance\n",
    "\n",
    "#### 4. Donn√©es sensibles (sant√©, finance, etc.)\n",
    "**Choix recommand√©** : Ollama uniquement\n",
    "- ‚úÖ Aucune donn√©e ne quitte votre infrastructure\n",
    "- ‚úÖ Conformit√© RGPD/HIPAA facilit√©e\n",
    "\n",
    "#### 5. Recherche et exp√©rimentation\n",
    "**Choix recommand√©** : Tous les mod√®les\n",
    "- Tester plusieurs mod√®les pour trouver le meilleur\n",
    "- Utiliser Ollama pour les it√©rations rapides\n",
    "- Valider avec des mod√®les API avant production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 R√©sum√© de la Partie 5\n",
    "\n",
    "### Ce que nous avons appris\n",
    "\n",
    "1. **Abstraction DSPy** : Un seul code fonctionne avec tous les fournisseurs LLM\n",
    "   \n",
    "2. **Configuration de fournisseurs** :\n",
    "   - **Ollama** : Local, gratuit, confidentialit√© maximale\n",
    "   - **OpenAI** : API cloud, haute qualit√©, payant\n",
    "   - **Anthropic** : API cloud, excellente qualit√©, payant\n",
    "\n",
    "3. **Comparaison de mod√®les** :\n",
    "   - Fonction de benchmarking pour comparer performances\n",
    "   - Mesure du score ET du temps d'ex√©cution\n",
    "   - Aide √† la d√©cision data-driven\n",
    "\n",
    "4. **Architectures hybrides** :\n",
    "   - Diff√©rents mod√®les pour diff√©rentes t√¢ches\n",
    "   - Optimisation co√ªt/performance/vitesse\n",
    "   - Utilisation de `dspy.settings.context(lm=...)`\n",
    "\n",
    "5. **Guide de s√©lection** :\n",
    "   - Crit√®res : co√ªt, vitesse, confidentialit√©, qualit√©\n",
    "   - Recommandations par cas d'usage\n",
    "   - Strat√©gies adapt√©es au contexte\n",
    "\n",
    "### Points cl√©s √† retenir\n",
    "\n",
    "- ‚úÖ **Flexibilit√©** : Changer de mod√®le ne n√©cessite que quelques lignes de code\n",
    "- ‚úÖ **Exp√©rimentation** : Tester plusieurs mod√®les est facile et recommand√©\n",
    "- ‚úÖ **Optimisation** : Architectures hybrides pour le meilleur rapport co√ªt/performance\n",
    "- ‚úÖ **Confidentialit√©** : Ollama pour les donn√©es sensibles\n",
    "- ‚úÖ **√âvolutivit√©** : Commencer avec Ollama, migrer vers API si n√©cessaire\n",
    "\n",
    "### Exemple de workflow recommand√©\n",
    "\n",
    "```python\n",
    "# 1. D√©veloppement avec Ollama (gratuit, rapide)\n",
    "lm_dev = dspy.LM('ollama_chat/llama3.1:8b', api_base='http://localhost:11434')\n",
    "dspy.configure(lm=lm_dev)\n",
    "\n",
    "# 2. Test avec plusieurs mod√®les\n",
    "models = [lm_ollama_llama, lm_ollama_qwen, lm_openai_mini]\n",
    "results = [benchmark_model(lm, name, valset, metric) for lm, name in models]\n",
    "\n",
    "# 3. Production avec le meilleur mod√®le ou architecture hybride\n",
    "lm_prod = best_model  # Ou HybridTicketClassifier(fast_lm, accurate_lm)\n",
    "```\n",
    "\n",
    "### Prochaines √©tapes\n",
    "\n",
    "- **Partie 6** : Patterns avanc√©s (optionnel - validation, retry, fallback)\n",
    "- **Partie 7** : GEPA en pratique (optimisation sophistiqu√©e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 6: Patterns avanc√©s (optionnel)\n",
    "\n",
    "## 6.1 Introduction aux patterns avanc√©s\n",
    "\n",
    "Cette section couvre des **patterns de production** pour rendre vos modules DSPy plus robustes, fiables et performants.\n",
    "\n",
    "### Pourquoi utiliser ces patterns?\n",
    "\n",
    "En production, les LLMs peuvent :\n",
    "- ‚ùå G√©n√©rer des sorties invalides (mauvais format, valeurs hors limites)\n",
    "- ‚ùå √âchouer temporairement (timeout, rate limiting)\n",
    "- ‚ùå Produire des r√©sultats incoh√©rents\n",
    "- ‚ùå √ätre indisponibles (downtime API)\n",
    "\n",
    "Les **patterns avanc√©s** permettent de g√©rer ces situations.\n",
    "\n",
    "### Patterns couverts\n",
    "\n",
    "1. **Validation** : V√©rifier et corriger les sorties invalides\n",
    "2. **Retry** : R√©essayer automatiquement en cas d'erreur\n",
    "3. **Fallback** : Utiliser un mod√®le de secours si le principal √©choue\n",
    "4. **Ensemble** : Combiner plusieurs pr√©dictions pour plus de robustesse\n",
    "5. **Cha√Ænage avec contr√¥le** : Pipelines complexes avec branchement conditionnel\n",
    "\n",
    "Ces patterns sont **optionnels** mais fortement recommand√©s pour les applications de production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Pattern de validation\n",
    "\n",
    "Le **pattern de validation** v√©rifie que les sorties du LLM respectent les contraintes de votre application.\n",
    "\n",
    "### Probl√®me\n",
    "\n",
    "Les LLMs peuvent g√©n√©rer :\n",
    "- Des cat√©gories qui n'existent pas (\"Mat√©riel\" au lieu de \"Hardware\")\n",
    "- Des priorit√©s invalides (\"Tr√®s urgent\" au lieu de \"Urgent\")\n",
    "- Des formats incorrects (minuscules au lieu de majuscules)\n",
    "\n",
    "### Solution\n",
    "\n",
    "Cr√©er un module qui :\n",
    "1. Ex√©cute la pr√©diction\n",
    "2. **Valide** la sortie\n",
    "3. **Corrige** ou **rejette** si invalide\n",
    "4. Optionnellement, **r√©essaye** avec des instructions clarifi√©es\n",
    "\n",
    "### Exemple: classifier avec validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidatedTicketClassifier(dspy.Module):\n",
    "    \"\"\"\n",
    "    Classifier avec validation des sorties\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = dspy.ChainOfThought(TicketClassifier)\n",
    "        \n",
    "        # Valeurs valides\n",
    "        self.valid_categories = set(cat.lower() for cat in CATEGORIES)\n",
    "        self.valid_priorities = set(pri.lower() for pri in PRIORITIES)\n",
    "    \n",
    "    def validate_and_correct(self, category, priority):\n",
    "        \"\"\"\n",
    "        Valide et corrige les sorties si n√©cessaire\n",
    "        \n",
    "        Returns:\n",
    "            (category, priority, is_valid)\n",
    "        \"\"\"\n",
    "        category_lower = category.strip().lower()\n",
    "        priority_lower = priority.strip().lower()\n",
    "        \n",
    "        is_valid = True\n",
    "        \n",
    "        # Validation de la cat√©gorie\n",
    "        if category_lower not in self.valid_categories:\n",
    "            # Essayer de trouver une correspondance approximative\n",
    "            if 'hard' in category_lower or 'mat√©r' in category_lower:\n",
    "                category = 'Hardware'\n",
    "            elif 'soft' in category_lower or 'logic' in category_lower:\n",
    "                category = 'Software'\n",
    "            elif 'r√©seau' in category_lower or 'network' in category_lower:\n",
    "                category = 'Network'\n",
    "            elif 'compte' in category_lower or 'account' in category_lower:\n",
    "                category = 'Account'\n",
    "            else:\n",
    "                # Par d√©faut, mettre \"Other\"\n",
    "                category = 'Other'\n",
    "                is_valid = False\n",
    "        else:\n",
    "            # Normaliser la casse\n",
    "            category = next(c for c in CATEGORIES if c.lower() == category_lower)\n",
    "        \n",
    "        # Validation de la priorit√©\n",
    "        if priority_lower not in self.valid_priorities:\n",
    "            # Essayer de mapper\n",
    "            if 'critic' in priority_lower or 'critique' in priority_lower:\n",
    "                priority = 'Critical'\n",
    "            elif 'urgent' in priority_lower:\n",
    "                priority = 'Urgent'\n",
    "            elif 'high' in priority_lower or 'haut' in priority_lower:\n",
    "                priority = 'High'\n",
    "            elif 'medium' in priority_lower or 'moyen' in priority_lower:\n",
    "                priority = 'Medium'\n",
    "            else:\n",
    "                priority = 'Low'\n",
    "                is_valid = False\n",
    "        else:\n",
    "            # Normaliser la casse\n",
    "            priority = next(p for p in PRIORITIES if p.lower() == priority_lower)\n",
    "        \n",
    "        return category, priority, is_valid\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        # Pr√©diction initiale\n",
    "        result = self.classifier(ticket=ticket)\n",
    "        \n",
    "        # Validation et correction\n",
    "        category, priority, is_valid = self.validate_and_correct(\n",
    "            result.category,\n",
    "            result.priority\n",
    "        )\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            category=category,\n",
    "            priority=priority,\n",
    "            is_valid=is_valid\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ Classe ValidatedTicketClassifier d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du classifier avec validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Test du classifier avec validation\\n\")\n",
    "\n",
    "# Configurer le mod√®le\n",
    "dspy.configure(lm=lm_ollama_llama)\n",
    "\n",
    "# Cr√©er le classifier valid√©\n",
    "validated_classifier = ValidatedTicketClassifier()\n",
    "\n",
    "# Tester sur quelques exemples\n",
    "test_examples = [\n",
    "    \"Mon imprimante ne fonctionne pas\",\n",
    "    \"Besoin d'acc√®s au serveur de fichiers\",\n",
    "    \"Le r√©seau est tr√®s lent, urgent!\"\n",
    "]\n",
    "\n",
    "for i, ticket in enumerate(test_examples, 1):\n",
    "    result = validated_classifier(ticket=ticket)\n",
    "    status = \"‚úÖ Valide\" if result.is_valid else \"‚ö†Ô∏è Corrig√©\"\n",
    "    print(f\"{i}. {ticket}\")\n",
    "    print(f\"   ‚Üí {result.category} | {result.priority} | {status}\\n\")\n",
    "\n",
    "# √âvaluer sur l'ensemble de validation\n",
    "print(\"üìä √âvaluation sur l'ensemble de validation:\")\n",
    "score = evaluate_module(validated_classifier, val_examples, exact_match_metric)\n",
    "print(f\"   Score: {score:.2%}\")\n",
    "\n",
    "# Compter les corrections effectu√©es\n",
    "corrections = 0\n",
    "for example in val_examples[:10]:\n",
    "    result = validated_classifier(ticket=example['ticket'])\n",
    "    if not result.is_valid:\n",
    "        corrections += 1\n",
    "\n",
    "print(f\"   Corrections appliqu√©es: {corrections}/10 sur les premiers exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Pattern de retry (r√©essayer en cas d'erreur)\n",
    "\n",
    "Le **pattern de retry** r√©essaye automatiquement une op√©ration en cas d'√©chec temporaire.\n",
    "\n",
    "### Probl√®me\n",
    "\n",
    "Les APIs LLM peuvent √©chouer pour diverses raisons :\n",
    "- Timeout r√©seau\n",
    "- Rate limiting (trop de requ√™tes)\n",
    "- Surcharge temporaire du service\n",
    "- Erreurs intermittentes\n",
    "\n",
    "### Solution\n",
    "\n",
    "Impl√©menter une logique de retry avec :\n",
    "1. **Nombre maximum de tentatives** (ex: 3)\n",
    "2. **D√©lai exponentiel** entre les tentatives (1s, 2s, 4s)\n",
    "3. **Gestion des erreurs** sp√©cifiques\n",
    "\n",
    "### Exemple: classifier avec retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class RetryTicketClassifier(dspy.Module):\n",
    "    \"\"\"\n",
    "    Classifier avec logique de retry en cas d'erreur\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_retries=3, initial_delay=1.0):\n",
    "        super().__init__()\n",
    "        self.classifier = dspy.ChainOfThought(TicketClassifier)\n",
    "        self.max_retries = max_retries\n",
    "        self.initial_delay = initial_delay\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        last_error = None\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                # Tentative de pr√©diction\n",
    "                result = self.classifier(ticket=ticket)\n",
    "                \n",
    "                # Succ√®s - retourner le r√©sultat\n",
    "                return dspy.Prediction(\n",
    "                    category=result.category,\n",
    "                    priority=result.priority,\n",
    "                    attempts=attempt + 1\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                \n",
    "                # Si c'est la derni√®re tentative, on va lever l'erreur\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    break\n",
    "                \n",
    "                # Calculer le d√©lai avec backoff exponentiel\n",
    "                delay = self.initial_delay * (2 ** attempt)\n",
    "                \n",
    "                print(f\"‚ö†Ô∏è Tentative {attempt + 1} √©chou√©e: {e}\")\n",
    "                print(f\"   Nouvelle tentative dans {delay:.1f}s...\")\n",
    "                \n",
    "                time.sleep(delay)\n",
    "        \n",
    "        # Toutes les tentatives ont √©chou√©\n",
    "        raise Exception(f\"√âchec apr√®s {self.max_retries} tentatives: {last_error}\")\n",
    "\n",
    "print(\"‚úÖ Classe RetryTicketClassifier d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Pattern de fallback (mod√®le de secours)\n",
    "\n",
    "Le **pattern de fallback** utilise un mod√®le de secours si le mod√®le principal √©choue.\n",
    "\n",
    "### Probl√®me\n",
    "\n",
    "- Le mod√®le principal (API payante) peut √™tre indisponible\n",
    "- Vous voulez garantir la disponibilit√© du service\n",
    "- Budget limit√© : utiliser un mod√®le local en secours\n",
    "\n",
    "### Solution\n",
    "\n",
    "Cr√©er un module qui :\n",
    "1. Essaye avec le **mod√®le principal** (haute qualit√©)\n",
    "2. Si √©chec, bascule vers le **mod√®le de secours** (local/gratuit)\n",
    "3. Retourne quelle strat√©gie a √©t√© utilis√©e\n",
    "\n",
    "### Exemple: classifier avec fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FallbackTicketClassifier(dspy.Module):\n",
    "    \"\"\"\n",
    "    Classifier avec fallback vers un mod√®le de secours\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, primary_lm, fallback_lm):\n",
    "        super().__init__()\n",
    "        self.primary_lm = primary_lm\n",
    "        self.fallback_lm = fallback_lm\n",
    "        self.signature = TicketClassifier\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        # Tentative avec le mod√®le principal\n",
    "        try:\n",
    "            with dspy.settings.context(lm=self.primary_lm):\n",
    "                predictor = dspy.ChainOfThought(self.signature)\n",
    "                result = predictor(ticket=ticket)\n",
    "                \n",
    "                return dspy.Prediction(\n",
    "                    category=result.category,\n",
    "                    priority=result.priority,\n",
    "                    model_used='primary'\n",
    "                )\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Mod√®le principal √©chou√©: {e}\")\n",
    "            print(f\"   Basculement vers le mod√®le de secours...\")\n",
    "            \n",
    "            # Fallback vers le mod√®le de secours\n",
    "            try:\n",
    "                with dspy.settings.context(lm=self.fallback_lm):\n",
    "                    predictor = dspy.ChainOfThought(self.signature)\n",
    "                    result = predictor(ticket=ticket)\n",
    "                    \n",
    "                    return dspy.Prediction(\n",
    "                        category=result.category,\n",
    "                        priority=result.priority,\n",
    "                        model_used='fallback'\n",
    "                    )\n",
    "            \n",
    "            except Exception as fallback_error:\n",
    "                # Les deux mod√®les ont √©chou√©\n",
    "                raise Exception(f\"√âchec des deux mod√®les. Fallback error: {fallback_error}\")\n",
    "\n",
    "print(\"‚úÖ Classe FallbackTicketClassifier d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du classifier avec fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÄ Test du classifier avec fallback\")\n",
    "print(\"   Mod√®le principal: llama3.1:8b\")\n",
    "print(\"   Mod√®le de secours: mistral:7b\\n\")\n",
    "\n",
    "# Cr√©er le classifier avec fallback\n",
    "fallback_classifier = FallbackTicketClassifier(\n",
    "    primary_lm=lm_ollama_llama,\n",
    "    fallback_lm=lm_ollama_mistral\n",
    ")\n",
    "\n",
    "# Tester (normalement, le mod√®le principal devrait fonctionner)\n",
    "test_ticket = \"Mon imprimante ne fonctionne plus\"\n",
    "result = fallback_classifier(ticket=test_ticket)\n",
    "\n",
    "print(f\"Ticket: {test_ticket}\")\n",
    "print(f\"R√©sultat: {result.category} | {result.priority}\")\n",
    "print(f\"Mod√®le utilis√©: {result.model_used}\")\n",
    "print()\n",
    "\n",
    "# Note: Dans un cas r√©el, le fallback se d√©clencherait si:\n",
    "# - L'API est indisponible\n",
    "# - Le rate limit est atteint\n",
    "# - Le timeout est d√©pass√©\n",
    "# - Une erreur r√©seau se produit\n",
    "\n",
    "print(\"üí° Le pattern de fallback garantit la disponibilit√© du service\")\n",
    "print(\"   m√™me en cas de probl√®me avec le mod√®le principal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Pattern de raffinement it√©ratif (Refine)\n",
    "\n",
    "`dspy.Refine` est un module qui am√©liore it√©rativement une pr√©diction en :\n",
    "1. **Ex√©cutant le module N fois** avec diff√©rents param√®tres\n",
    "2. **√âvaluant chaque pr√©diction** avec une fonction de r√©compense\n",
    "3. **Retournant la meilleure pr√©diction** ou s'arr√™tant si le seuil est atteint\n",
    "\n",
    "### Diff√©rence avec les autres modules :\n",
    "\n",
    "| Module | Approche |\n",
    "|--------|----------|\n",
    "| `ChainOfThought` | Une seule tentative avec raisonnement |\n",
    "| `ReAct` | Raisonnement + actions s√©quentielles |\n",
    "| `Refine` | **Plusieurs tentatives √©valu√©es par score de qualit√©** |\n",
    "\n",
    "### Cas d'usage id√©aux :\n",
    "- Classifications **ambigu√´s** n√©cessitant plusieurs analyses\n",
    "- Situations o√π la **qualit√© est critique** et on peut se permettre plus de calculs\n",
    "- T√¢ches avec des **crit√®res de qualit√© mesurables** (via fonction de r√©compense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinedTicketClassifier(dspy.Module):\n",
    "    \"\"\"\n",
    "    Classifier avec raffinement it√©ratif.\n",
    "    \n",
    "    Utilise dspy.Refine pour ex√©cuter le classifier plusieurs fois\n",
    "    et retourner la meilleure pr√©diction selon une fonction de r√©compense.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, N=3, threshold=1.0):\n",
    "        super().__init__()\n",
    "        self.valid_categories = {'hardware', 'software', 'network', 'account', 'application'}\n",
    "        self.valid_priorities = {'critical', 'urgent', 'high', 'medium', 'low'}\n",
    "        \n",
    "        # Module de base √† raffiner\n",
    "        base_module = dspy.ChainOfThought(TicketClassifier)\n",
    "        \n",
    "        # Cr√©er le module Refine avec fonction de r√©compense\n",
    "        self.refine = dspy.Refine(\n",
    "            module=base_module,\n",
    "            N=N,  # Nombre de tentatives\n",
    "            reward_fn=self._reward_function,  # Fonction d'√©valuation\n",
    "            threshold=threshold  # Arr√™t anticip√© si atteint\n",
    "        )\n",
    "    \n",
    "    def _reward_function(self, args, prediction):\n",
    "        \"\"\"\n",
    "        Fonction de r√©compense : √©value la qualit√© de la pr√©diction.\n",
    "        \n",
    "        Retourne un score entre 0.0 et 1.0 :\n",
    "        - 1.0 : cat√©gorie ET priorit√© valides\n",
    "        - 0.5 : seulement l'un des deux valide\n",
    "        - 0.0 : les deux invalides\n",
    "        \"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # V√©rifier la validit√© de la cat√©gorie\n",
    "        if hasattr(prediction, 'category'):\n",
    "            if prediction.category.strip().lower() in self.valid_categories:\n",
    "                score += 0.5\n",
    "        \n",
    "        # V√©rifier la validit√© de la priorit√©\n",
    "        if hasattr(prediction, 'priority'):\n",
    "            if prediction.priority.strip().lower() in self.valid_priorities:\n",
    "                score += 0.5\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        # Refine ex√©cutera le module N fois et retournera la meilleure pr√©diction\n",
    "        result = self.refine(ticket=ticket)\n",
    "        return dspy.Prediction(\n",
    "            category=result.category,\n",
    "            priority=result.priority\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du classifier avec raffinement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Test du classifier avec raffinement it√©ratif\\n\")\n",
    "\n",
    "# Cr√©er le classifier avec 3 tentatives\n",
    "refined_classifier = RefinedTicketClassifier(N=3, threshold=1.0)\n",
    "\n",
    "# Ticket ambigu pour tester le raffinement\n",
    "ticket_ambigu = \"Le syst√®me affiche des messages d'erreur √©tranges. Parfois √ßa marche, parfois non.\"\n",
    "\n",
    "print(f\"Ticket: {ticket_ambigu}\\n\")\n",
    "\n",
    "# Classifier avec raffinement\n",
    "result = refined_classifier(ticket=ticket_ambigu)\n",
    "\n",
    "print(f\"‚úÖ R√©sultat apr√®s raffinement:\")\n",
    "print(f\"   Cat√©gorie: {result.category}\")\n",
    "print(f\"   Priorit√©: {result.priority}\")\n",
    "\n",
    "print(\"\\nüí° Le module Refine a ex√©cut√© le classifier jusqu'√† 3 fois\")\n",
    "print(\"   et a retourn√© la pr√©diction avec le meilleur score de qualit√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Comparaison : ChainOfThought vs Refine\n",
    "\n",
    "| Aspect | ChainOfThought | Refine |\n",
    "|--------|----------------|--------|\n",
    "| **Nombre de tentatives** | 1 | N (configurable) |\n",
    "| **√âvaluation** | Aucune | Fonction de r√©compense |\n",
    "| **Co√ªt (appels LLM)** | Faible (1x) | Plus √©lev√© (Nx) |\n",
    "| **Qualit√©** | Bonne | Potentiellement meilleure |\n",
    "| **Cas d'usage** | T√¢ches standard | T√¢ches critiques/ambigu√´s |\n",
    "\n",
    "### üéØ Quand utiliser Refine ?\n",
    "\n",
    "‚úÖ **Utilisez Refine quand :**\n",
    "- La qualit√© est **critique** (d√©cisions importantes)\n",
    "- Les tickets sont **ambigus** ou complexes\n",
    "- Vous avez une **fonction de qualit√©** claire\n",
    "- Le **co√ªt suppl√©mentaire** est acceptable\n",
    "\n",
    "‚ùå **√âvitez Refine si :**\n",
    "- Vous avez des **contraintes de latence** strictes\n",
    "- Les **co√ªts** doivent √™tre minimis√©s\n",
    "- La t√¢che est **simple** et ChainOfThought suffit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Pattern d'ensemble (combiner plusieurs pr√©dictions)\n",
    "\n",
    "Le **pattern d'ensemble** combine les pr√©dictions de plusieurs mod√®les pour am√©liorer la robustesse et la pr√©cision.\n",
    "\n",
    "### Probl√®me\n",
    "\n",
    "- Un seul mod√®le peut faire des erreurs\n",
    "- Diff√©rents mod√®les ont diff√©rentes forces\n",
    "- Vous voulez maximiser la fiabilit√©\n",
    "\n",
    "### Solution\n",
    "\n",
    "Cr√©er un module qui :\n",
    "1. Ex√©cute la pr√©diction avec **plusieurs mod√®les**\n",
    "2. **Combine** les r√©sultats (vote majoritaire, moyenne pond√©r√©e, etc.)\n",
    "3. Retourne la pr√©diction la plus consensuelle\n",
    "\n",
    "### Strat√©gies de combinaison\n",
    "\n",
    "- **Vote majoritaire** : La pr√©diction la plus fr√©quente\n",
    "- **Vote pond√©r√©** : Chaque mod√®le a un poids diff√©rent\n",
    "- **Consensus strict** : Tous les mod√®les doivent √™tre d'accord\n",
    "\n",
    "### Exemple: classifier d'ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class EnsembleTicketClassifier(dspy.Module):\n",
    "    \"\"\"\n",
    "    Classifier d'ensemble utilisant plusieurs mod√®les et vote majoritaire\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, models):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            models: Liste de tuples (lm, weight) o√π weight est le poids du mod√®le\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "        self.signature = TicketClassifier\n",
    "    \n",
    "    def forward(self, ticket):\n",
    "        predictions = []\n",
    "        \n",
    "        # Obtenir les pr√©dictions de chaque mod√®le\n",
    "        for lm, weight in self.models:\n",
    "            try:\n",
    "                with dspy.settings.context(lm=lm):\n",
    "                    predictor = dspy.ChainOfThought(self.signature)\n",
    "                    result = predictor(ticket=ticket)\n",
    "                    \n",
    "                    # Ajouter la pr√©diction avec son poids\n",
    "                    for _ in range(weight):\n",
    "                        predictions.append({\n",
    "                            'category': result.category.strip().lower(),\n",
    "                            'priority': result.priority.strip().lower()\n",
    "                        })\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur avec un mod√®le: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not predictions:\n",
    "            raise Exception(\"Aucun mod√®le n'a pu faire de pr√©diction\")\n",
    "        \n",
    "        # Vote majoritaire pour la cat√©gorie\n",
    "        categories = [p['category'] for p in predictions]\n",
    "        category_counts = Counter(categories)\n",
    "        winning_category = category_counts.most_common(1)[0][0]\n",
    "        \n",
    "        # Vote majoritaire pour la priorit√©\n",
    "        priorities = [p['priority'] for p in predictions]\n",
    "        priority_counts = Counter(priorities)\n",
    "        winning_priority = priority_counts.most_common(1)[0][0]\n",
    "        \n",
    "        # Normaliser les r√©sultats\n",
    "        category = next((c for c in CATEGORIES if c.lower() == winning_category), winning_category)\n",
    "        priority = next((p for p in PRIORITIES if p.lower() == winning_priority), winning_priority)\n",
    "        \n",
    "        # Calculer la confiance (pourcentage d'accord)\n",
    "        category_confidence = category_counts[winning_category] / len(predictions)\n",
    "        priority_confidence = priority_counts[winning_priority] / len(predictions)\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            category=category,\n",
    "            priority=priority,\n",
    "            category_confidence=category_confidence,\n",
    "            priority_confidence=priority_confidence,\n",
    "            num_models=len(self.models)\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ Classe EnsembleTicketClassifier d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du classifier d'ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Test du classifier d'ensemble\")\n",
    "print(\"   Combinaison de 3 mod√®les avec vote majoritaire\\n\")\n",
    "\n",
    "# Cr√©er l'ensemble avec 3 mod√®les\n",
    "# Format: (mod√®le, poids)\n",
    "ensemble_classifier = EnsembleTicketClassifier([\n",
    "    (lm_ollama_llama, 2),    # Poids 2 (meilleur mod√®le)\n",
    "    (lm_ollama_qwen, 2),     # Poids 2 (aussi tr√®s bon)\n",
    "    (lm_ollama_mistral, 1)   # Poids 1 (plus rapide mais moins pr√©cis)\n",
    "])\n",
    "\n",
    "# Tester sur quelques exemples\n",
    "test_tickets = [\n",
    "    \"Mon ordinateur portable ne d√©marre plus, pr√©sentation urgente dans 1h\",\n",
    "    \"Besoin d'acc√®s au VPN pour le t√©l√©travail\",\n",
    "]\n",
    "\n",
    "for i, ticket in enumerate(test_tickets, 1):\n",
    "    print(f\"{i}. Ticket: {ticket}\")\n",
    "    result = ensemble_classifier(ticket=ticket)\n",
    "    print(f\"   ‚Üí Cat√©gorie: {result.category} (confiance: {result.category_confidence:.1%})\")\n",
    "    print(f\"   ‚Üí Priorit√©: {result.priority} (confiance: {result.priority_confidence:.1%})\")\n",
    "    print()\n",
    "\n",
    "# √âvaluer sur l'ensemble de validation\n",
    "print(\"üìä √âvaluation de l'ensemble sur la validation:\")\n",
    "score_ensemble = evaluate_module(ensemble_classifier, val_examples, exact_match_metric)\n",
    "print(f\"   Score: {score_ensemble:.2%}\")\n",
    "print()\n",
    "\n",
    "print(\"üí° L'ensemble combine les forces de plusieurs mod√®les\")\n",
    "print(\"   pour am√©liorer la robustesse et la pr√©cision.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Combiner les patterns\n",
    "\n",
    "En production, vous pouvez **combiner plusieurs patterns** pour maximiser la robustesse :\n",
    "\n",
    "### Exemple: classifier de production complet\n",
    "\n",
    "```python\n",
    "class ProductionTicketClassifier(dspy.Module):\n",
    "    \"\"\"\n",
    "    Classifier de production avec tous les patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, primary_lm, fallback_lm, ensemble_models):\n",
    "        super().__init__()\n",
    "        self.primary_lm = primary_lm\n",
    "        self.fallback_lm = fallback_lm\n",
    "        self.ensemble_models = ensemble_models\n",
    "        self.valid_categories = set(cat.lower() for cat in CATEGORIES)\n",
    "        self.valid_priorities = set(pri.lower() for pri in PRIORITIES)\n",
    "    \n",
    "    def forward(self, ticket, use_ensemble=False):\n",
    "        # 1. D√©cider de la strat√©gie\n",
    "        if use_ensemble:\n",
    "            # Utiliser l'ensemble pour les cas critiques\n",
    "            classifier = EnsembleTicketClassifier(self.ensemble_models)\n",
    "        else:\n",
    "            # Utiliser le fallback pour les cas normaux\n",
    "            classifier = FallbackTicketClassifier(self.primary_lm, self.fallback_lm)\n",
    "        \n",
    "        # 2. Ex√©cuter avec retry\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                result = classifier(ticket=ticket)\n",
    "                \n",
    "                # 3. Valider et corriger\n",
    "                category, priority, is_valid = self.validate_and_correct(\n",
    "                    result.category,\n",
    "                    result.priority\n",
    "                )\n",
    "                \n",
    "                return dspy.Prediction(\n",
    "                    category=category,\n",
    "                    priority=priority,\n",
    "                    is_valid=is_valid,\n",
    "                    strategy='ensemble' if use_ensemble else 'fallback',\n",
    "                    attempts=attempt + 1\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                time.sleep(2 ** attempt)\n",
    "```\n",
    "\n",
    "### Quand utiliser chaque pattern\n",
    "\n",
    "| Pattern | Quand l'utiliser | Co√ªt |\n",
    "|---------|-----------------|------|\n",
    "| **Validation** | Toujours (critique) | Faible |\n",
    "| **Retry** | APIs externes | Faible |\n",
    "| **Fallback** | Haute disponibilit√© requise | Moyen |\n",
    "| **Ensemble** | Pr√©cision maximale requise | √âlev√© |\n",
    "| **Combinaison** | Production critique | Tr√®s √©lev√© |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 R√©sum√© de la Partie 6\n",
    "\n",
    "### Ce que nous avons appris\n",
    "\n",
    "1. **Pattern de validation** :\n",
    "   - V√©rifier que les sorties respectent les contraintes\n",
    "   - Corriger automatiquement les valeurs invalides\n",
    "   - Normaliser les formats\n",
    "\n",
    "2. **Pattern de retry** :\n",
    "   - R√©essayer automatiquement en cas d'erreur temporaire\n",
    "   - Backoff exponentiel (1s, 2s, 4s, 8s...)\n",
    "   - Nombre maximum de tentatives\n",
    "\n",
    "3. **Pattern de fallback** :\n",
    "   - Mod√®le de secours si le principal √©choue\n",
    "   - Garantir la disponibilit√© du service\n",
    "   - Compromis qualit√©/disponibilit√©\n",
    "\n",
    "4. **Pattern d'ensemble** :\n",
    "   - Combiner plusieurs mod√®les (vote majoritaire)\n",
    "   - Am√©liorer la robustesse\n",
    "   - Mesurer la confiance\n",
    "\n",
    "5. **Combinaison de patterns** :\n",
    "   - Utiliser plusieurs patterns ensemble\n",
    "   - Architecture de production robuste\n",
    "   - Adapter selon les besoins\n",
    "\n",
    "### Points cl√©s √† retenir\n",
    "\n",
    "- ‚úÖ **Validation** : Toujours valider les sorties en production\n",
    "- ‚úÖ **Retry** : G√©rer les erreurs temporaires automatiquement\n",
    "- ‚úÖ **Fallback** : Avoir un plan B pour la disponibilit√©\n",
    "- ‚úÖ **Ensemble** : Utiliser pour les cas critiques n√©cessitant haute pr√©cision\n",
    "- ‚úÖ **Combinaison** : Adapter les patterns selon vos contraintes\n",
    "\n",
    "### Compromis √† consid√©rer\n",
    "\n",
    "| Aspect | Simple | Production robuste |\n",
    "|--------|--------|-------------------|\n",
    "| **Complexit√© du code** | Faible | √âlev√©e |\n",
    "| **Co√ªt d'ex√©cution** | Faible | √âlev√© (multiple LLM calls) |\n",
    "| **Latence** | Rapide | Plus lente |\n",
    "| **Fiabilit√©** | Moyenne | Tr√®s √©lev√©e |\n",
    "| **Maintenance** | Simple | Plus complexe |\n",
    "\n",
    "### Recommandations\n",
    "\n",
    "**Pour d√©buter** :\n",
    "- Commencer simple (sans patterns)\n",
    "- Ajouter la validation d√®s que possible\n",
    "- Ajouter les autres patterns selon les besoins\n",
    "\n",
    "**Pour la production** :\n",
    "- Validation : **obligatoire**\n",
    "- Retry : **fortement recommand√©** pour les APIs\n",
    "- Fallback : selon l'importance de la disponibilit√©\n",
    "- Ensemble : uniquement si la pr√©cision est critique\n",
    "\n",
    "**Strat√©gie progressive** :\n",
    "1. Phase 1 : Module simple + validation\n",
    "2. Phase 2 : Ajouter retry pour g√©rer les erreurs\n",
    "3. Phase 3 : Ajouter fallback pour la disponibilit√©\n",
    "4. Phase 4 : Ensemble pour les cas critiques seulement\n",
    "\n",
    "### Prochaines √©tapes\n",
    "\n",
    "- **Partie 7** : GEPA en pratique (optimisation sophistiqu√©e avec algorithmes g√©n√©tiques)\n",
    "- **Partie 8** : Conclusion et mise en production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 7: GEPA en pratique\n",
    "\n",
    "## 7.1 Introduction √† GEPA\n",
    "\n",
    "**GEPA** (Genetic-Pareto Algorithm) est l'optimiseur le plus sophistiqu√© de DSPy. Il combine plusieurs techniques avanc√©es pour am√©liorer automatiquement vos prompts.\n",
    "\n",
    "### Qu'est-ce que GEPA?\n",
    "\n",
    "GEPA utilise une approche inspir√©e de l'√©volution biologique :\n",
    "\n",
    "1. **üß¨ Algorithmes g√©n√©tiques** : G√©n√®re des \"populations\" de prompts qui √©voluent\n",
    "2. **ü§î R√©flexion LLM** : Utilise un LLM pour analyser les erreurs et proposer des am√©liorations\n",
    "3. **üìä Optimisation Pareto** : √âquilibre plusieurs objectifs (pr√©cision, concision, etc.)\n",
    "4. **üîÑ It√©rations adaptatives** : Apprend de ses erreurs pour s'am√©liorer\n",
    "\n",
    "### Comment √ßa fonctionne?\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ 1. POPULATION INITIALE                                  ‚îÇ\n",
    "‚îÇ    G√©n√®re plusieurs variantes de prompts               ‚îÇ\n",
    "‚îÇ    ‚Üì                                                    ‚îÇ\n",
    "‚îÇ 2. √âVALUATION                                          ‚îÇ\n",
    "‚îÇ    Teste chaque variante sur les donn√©es d'entra√Ænement‚îÇ\n",
    "‚îÇ    ‚Üì                                                    ‚îÇ\n",
    "‚îÇ 3. S√âLECTION                                           ‚îÇ\n",
    "‚îÇ    Garde les meilleurs (front de Pareto)               ‚îÇ\n",
    "‚îÇ    ‚Üì                                                    ‚îÇ\n",
    "‚îÇ 4. R√âFLEXION                                           ‚îÇ\n",
    "‚îÇ    LLM analyse les erreurs et propose des am√©liorations‚îÇ\n",
    "‚îÇ    ‚Üì                                                    ‚îÇ\n",
    "‚îÇ 5. MUTATION                                            ‚îÇ\n",
    "‚îÇ    G√©n√®re de nouvelles variantes bas√©es sur la r√©flexion‚îÇ\n",
    "‚îÇ    ‚Üì                                                    ‚îÇ\n",
    "‚îÇ 6. R√âP√àTE jusqu'√† convergence                          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Pourquoi GEPA est diff√©rent?\n",
    "\n",
    "| Optimiseur | Approche | R√©flexion LLM | Am√©lioration typique |\n",
    "|------------|----------|---------------|---------------------|\n",
    "| BootstrapFewShot | Exemples fixes | ‚ùå Non | 5-15% |\n",
    "| MIPRO | Variations syst√©matiques | ‚ùå Non | 10-25% |\n",
    "| **GEPA** | **√âvolution + R√©flexion** | **‚úÖ Oui** | **15-30%** |\n",
    "\n",
    "### Nouveaut√©s dans DSPy 3.0+\n",
    "\n",
    "GEPA a √©t√© int√©gr√© directement dans DSPy et n√©cessite maintenant :\n",
    "- **reflection_lm** : Un mod√®le LLM d√©di√© √† l'analyse des erreurs\n",
    "- **auto** : Niveau d'optimisation ('light', 'medium', 'heavy')\n",
    "- **M√©trique compatible** : Doit accepter les param√®tres GEPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Configuration de GEPA\n",
    "\n",
    "### Pr√©requis\n",
    "\n",
    "Avant d'utiliser GEPA, vous devez avoir :\n",
    "\n",
    "1. ‚úÖ **Donn√©es d'entra√Ænement** : Au moins 15-20 exemples de qualit√©\n",
    "2. ‚úÖ **Donn√©es de validation** : 5-10 exemples s√©par√©s pour √©viter le surapprentissage\n",
    "3. ‚úÖ **M√©trique d'√©valuation** : Fonction retournant un score entre 0 et 1\n",
    "4. ‚úÖ **Module √† optimiser** : Votre module DSPy de base\n",
    "5. ‚úÖ **Temps** : 10-30 minutes selon le niveau d'optimisation\n",
    "\n",
    "### Configuration du mod√®le de r√©flexion\n",
    "\n",
    "Le **reflection_lm** est un LLM utilis√© par GEPA pour analyser les erreurs et proposer des am√©liorations. Il est distinct du mod√®le principal.\n",
    "\n",
    "**Recommandations** :\n",
    "- Utiliser un mod√®le avec bonne capacit√© de raisonnement\n",
    "- Temp√©rature √©lev√©e (1.0) pour plus de cr√©ativit√©\n",
    "- Max tokens √©lev√© (8000+) pour des analyses d√©taill√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Configuration de GEPA\\n\")\n",
    "\n",
    "# 1. Configurer le mod√®le principal (celui qu'on optimise)\n",
    "lm_main = dspy.LM(\n",
    "    model='ollama_chat/llama3.1:8b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "dspy.configure(lm=lm_main)\n",
    "\n",
    "# 2. Configurer le mod√®le de r√©flexion pour GEPA\n",
    "# Important: Temp√©rature √©lev√©e pour plus de cr√©ativit√© dans l'analyse\n",
    "reflection_lm = dspy.LM(\n",
    "    model='ollama_chat/llama3.1:8b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=1.0,      # Haute temp√©rature = plus de cr√©ativit√©\n",
    "    max_tokens=8000       # Tokens √©lev√©s = analyses d√©taill√©es\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Mod√®le principal configur√©: llama3.1:8b (temp=0.3)\")\n",
    "print(\"‚úÖ Mod√®le de r√©flexion configur√©: llama3.1:8b (temp=1.0)\")\n",
    "print()\n",
    "\n",
    "# 3. Pr√©parer les donn√©es au format DSPy\n",
    "train_examples = [\n",
    "    dspy.Example(\n",
    "        ticket=ex['ticket'],\n",
    "        category=ex['category'],\n",
    "        priority=ex['priority']\n",
    "    ).with_inputs('ticket')\n",
    "    for ex in trainset\n",
    "]\n",
    "\n",
    "val_examples = [\n",
    "    dspy.Example(\n",
    "        ticket=ex['ticket'],\n",
    "        category=ex['category'],\n",
    "        priority=ex['priority']\n",
    "    ).with_inputs('ticket')\n",
    "    for ex in valset\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Donn√©es pr√©par√©es:\")\n",
    "print(f\"   - Entra√Ænement: {len(train_examples)} exemples\")\n",
    "print(f\"   - Validation: {len(val_examples)} exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Optimisation avec GEPA (mode 'light')\n",
    "\n",
    "Le mode **'light'** est le niveau d'optimisation le plus rapide de GEPA. Il est id√©al pour :\n",
    "- Premi√®re exp√©rimentation avec GEPA\n",
    "- Tests rapides (5-10 minutes)\n",
    "- Validation du concept\n",
    "- Ressources limit√©es\n",
    "\n",
    "### Niveaux d'optimisation GEPA\n",
    "\n",
    "| Niveau | Temps estim√© | Appels LLM | Am√©lioration | Usage |\n",
    "|--------|-------------|------------|--------------|-------|\n",
    "| **light** | 5-10 min | ~200-400 | 10-20% | Tests, prototypage |\n",
    "| **medium** | 10-20 min | ~400-800 | 15-25% | Production l√©g√®re |\n",
    "| **heavy** | 20-40 min | ~800-1600 | 20-30% | Maximum performance |\n",
    "\n",
    "### Exemple pratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import GEPA\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üß¨ OPTIMISATION GEPA - MODE 'LIGHT'\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# 1. Cr√©er le module √† optimiser\n",
    "print(\"1Ô∏è‚É£ Cr√©ation du module de base...\")\n",
    "baseline_classifier = SimpleTicketClassifier()\n",
    "\n",
    "# 2. √âvaluer AVANT optimisation\n",
    "print(\"2Ô∏è‚É£ √âvaluation AVANT optimisation...\")\n",
    "score_before = evaluate_module(baseline_classifier, val_examples, exact_match_metric)\n",
    "print(f\"   üìä Score baseline: {score_before:.2%}\\n\")\n",
    "\n",
    "# 3. Configurer l'optimiseur GEPA\n",
    "print(\"3Ô∏è‚É£ Configuration de l'optimiseur GEPA...\")\n",
    "optimizer = GEPA(\n",
    "    metric=exact_match_metric,\n",
    "    auto='light',                    # Mode rapide\n",
    "    reflection_lm=reflection_lm      # Mod√®le pour l'analyse des erreurs\n",
    ")\n",
    "print(\"   ‚úÖ Optimiseur configur√© (mode: light)\\n\")\n",
    "\n",
    "# 4. Lancer l'optimisation\n",
    "print(\"4Ô∏è‚É£ Lancement de l'optimisation GEPA...\")\n",
    "print(\"   ‚è∞ Cela va prendre 5-10 minutes avec Ollama\")\n",
    "print(\"   ‚òï C'est le moment de prendre un caf√©!\\n\")\n",
    "\n",
    "try:\n",
    "    optimized_classifier = optimizer.compile(\n",
    "        student=baseline_classifier,\n",
    "        trainset=train_examples,\n",
    "        valset=val_examples\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Optimisation GEPA termin√©e!\\n\")\n",
    "    \n",
    "    # 5. √âvaluer APR√àS optimisation\n",
    "    print(\"5Ô∏è‚É£ √âvaluation APR√àS optimisation...\")\n",
    "    score_after = evaluate_module(optimized_classifier, val_examples, exact_match_metric)\n",
    "    print(f\"   üìä Score optimis√©: {score_after:.2%}\\n\")\n",
    "    \n",
    "    # 6. Calculer l'am√©lioration\n",
    "    improvement = ((score_after - score_before) / score_before) * 100 if score_before > 0 else 0\n",
    "    improvement_abs = score_after - score_before\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"üìà R√âSULTATS DE L'OPTIMISATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Score AVANT:      {score_before:.2%}\")\n",
    "    print(f\"Score APR√àS:      {score_after:.2%}\")\n",
    "    print(f\"Am√©lioration:     {improvement_abs:+.2%} ({improvement:+.1f}%)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Erreur lors de l'optimisation GEPA: {e}\")\n",
    "    print(\"   V√©rifiez que:\")\n",
    "    print(\"   - Ollama est en cours d'ex√©cution\")\n",
    "    print(\"   - Le mod√®le llama3.1:8b est t√©l√©charg√©\")\n",
    "    print(\"   - Vous avez suffisamment de m√©moire disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Analyser les prompts optimis√©s\n",
    "\n",
    "Une des forces de GEPA est qu'il **g√©n√®re des prompts explicites** que vous pouvez inspecter et comprendre. Cela permet de :\n",
    "- üîç Voir ce que GEPA a chang√©\n",
    "- üìö Apprendre comment am√©liorer vos prompts manuellement\n",
    "- ‚úÖ Valider que les modifications ont du sens\n",
    "- üéì Comprendre pourquoi la performance s'est am√©lior√©e\n",
    "\n",
    "### Inspection des prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Inspection des prompts optimis√©s par GEPA\\n\")\n",
    "\n",
    "# Essayer d'acc√©der aux prompts optimis√©s\n",
    "if hasattr(optimized_classifier, 'classifier'):\n",
    "    predictor = optimized_classifier.classifier\n",
    "    \n",
    "    # 1. Signature optimis√©e\n",
    "    if hasattr(predictor, 'extended_signature'):\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üìù SIGNATURE OPTIMIS√âE\")\n",
    "        print(\"=\" * 70)\n",
    "        sig = predictor.extended_signature\n",
    "        print(f\"Docstring: {sig.__doc__}\")\n",
    "        print()\n",
    "        \n",
    "        # Afficher les champs\n",
    "        if hasattr(sig, 'input_fields'):\n",
    "            print(\"Champs d'entr√©e:\")\n",
    "            for name, field in sig.input_fields.items():\n",
    "                desc = getattr(field, 'desc', 'N/A')\n",
    "                print(f\"  - {name}: {desc}\")\n",
    "        \n",
    "        if hasattr(sig, 'output_fields'):\n",
    "            print(\"\\nChamps de sortie:\")\n",
    "            for name, field in sig.output_fields.items():\n",
    "                desc = getattr(field, 'desc', 'N/A')\n",
    "                print(f\"  - {name}: {desc}\")\n",
    "        print()\n",
    "    \n",
    "    # 2. Exemples de d√©monstration\n",
    "    if hasattr(predictor, 'demos') and predictor.demos:\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üìö EXEMPLES DE D√âMONSTRATION G√âN√âR√âS\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Nombre d'exemples: {len(predictor.demos)}\\n\")\n",
    "        \n",
    "        # Afficher les 3 premiers exemples\n",
    "        for i, demo in enumerate(predictor.demos[:3], 1):\n",
    "            print(f\"Exemple {i}:\")\n",
    "            print(f\"  Ticket: {demo.ticket[:80]}...\")\n",
    "            if hasattr(demo, 'category'):\n",
    "                print(f\"  Cat√©gorie: {demo.category}\")\n",
    "            if hasattr(demo, 'priority'):\n",
    "                print(f\"  Priorit√©: {demo.priority}\")\n",
    "            print()\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Aucun exemple de d√©monstration trouv√©\")\n",
    "        print(\"   (GEPA peut optimiser uniquement les instructions)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Structure du module diff√©rente\")\n",
    "    print(\"   L'optimisation s'est concentr√©e sur d'autres aspects\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üí° Ce que GEPA a fait:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úÖ Analys√© les erreurs sur les donn√©es d'entra√Ænement\")\n",
    "print(\"‚úÖ G√©n√©r√© des variantes de prompts\")\n",
    "print(\"‚úÖ Utilis√© la r√©flexion LLM pour proposer des am√©liorations\")\n",
    "print(\"‚úÖ S√©lectionn√© la meilleure configuration via Pareto\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Tester le classifier optimis√©\n",
    "\n",
    "Maintenant que GEPA a optimis√© notre classifier, testons-le sur de nouveaux exemples pour voir la diff√©rence.\n",
    "\n",
    "### Comparaison c√¥te √† c√¥te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Test comparatif: Baseline vs GEPA optimis√©\\n\")\n",
    "\n",
    "# Exemples de test\n",
    "test_cases = [\n",
    "    {\n",
    "        'ticket': \"Mon ordinateur portable ne s'allume plus, j'ai une r√©union importante dans 1h\",\n",
    "        'expected_category': 'Hardware',\n",
    "        'expected_priority': 'Urgent'\n",
    "    },\n",
    "    {\n",
    "        'ticket': \"Je voudrais acc√®s √† la base de donn√©es pour faire des analyses\",\n",
    "        'expected_category': 'Account',\n",
    "        'expected_priority': 'Medium'\n",
    "    },\n",
    "    {\n",
    "        'ticket': \"Le WiFi est compl√®tement HS dans tout le b√¢timent!\",\n",
    "        'expected_category': 'Network',\n",
    "        'expected_priority': 'Critical'\n",
    "    },\n",
    "    {\n",
    "        'ticket': \"Mon logiciel de comptabilit√© plante quand j'exporte en PDF\",\n",
    "        'expected_category': 'Software',\n",
    "        'expected_priority': 'High'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Ticket':<50} | {'Attendu':<20} | {'Baseline':<20} | {'GEPA':<20}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "correct_baseline = 0\n",
    "correct_gepa = 0\n",
    "\n",
    "for test in test_cases:\n",
    "    ticket = test['ticket']\n",
    "    expected = f\"{test['expected_category']}/{test['expected_priority']}\"\n",
    "    \n",
    "    # Pr√©diction baseline\n",
    "    pred_baseline = baseline_classifier(ticket=ticket)\n",
    "    baseline_result = f\"{pred_baseline.category}/{pred_baseline.priority}\"\n",
    "    baseline_match = (pred_baseline.category == test['expected_category'] and \n",
    "                     pred_baseline.priority == test['expected_priority'])\n",
    "    \n",
    "    # Pr√©diction GEPA\n",
    "    pred_gepa = optimized_classifier(ticket=ticket)\n",
    "    gepa_result = f\"{pred_gepa.category}/{pred_gepa.priority}\"\n",
    "    gepa_match = (pred_gepa.category == test['expected_category'] and \n",
    "                 pred_gepa.priority == test['expected_priority'])\n",
    "    \n",
    "    if baseline_match:\n",
    "        correct_baseline += 1\n",
    "    if gepa_match:\n",
    "        correct_gepa += 1\n",
    "    \n",
    "    # Afficher avec indicateurs de succ√®s\n",
    "    baseline_icon = \"‚úÖ\" if baseline_match else \"‚ùå\"\n",
    "    gepa_icon = \"‚úÖ\" if gepa_match else \"‚ùå\"\n",
    "    \n",
    "    print(f\"{ticket[:48]:<50} | {expected:<20} | {baseline_icon} {baseline_result:<17} | {gepa_icon} {gepa_result:<17}\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(f\"Pr√©cision sur les exemples de test:\")\n",
    "print(f\"  Baseline: {correct_baseline}/{len(test_cases)} ({correct_baseline/len(test_cases)*100:.0f}%)\")\n",
    "print(f\"  GEPA:     {correct_gepa}/{len(test_cases)} ({correct_gepa/len(test_cases)*100:.0f}%)\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Conseils pour optimiser avec GEPA\n",
    "\n",
    "### 7.6.1 Qualit√© des donn√©es\n",
    "\n",
    "La qualit√© de l'optimisation GEPA d√©pend **fortement** de vos donn√©es :\n",
    "\n",
    "‚úÖ **Bonnes pratiques** :\n",
    "- Minimum 15-20 exemples d'entra√Ænement (id√©alement 30-50)\n",
    "- Exemples **diversifi√©s** couvrant tous les cas d'usage\n",
    "- Labels **corrects** et **coh√©rents**\n",
    "- Donn√©es de validation **s√©par√©es** du trainset\n",
    "\n",
    "‚ùå **√Ä √©viter** :\n",
    "- Trop peu d'exemples (<10)\n",
    "- Exemples r√©p√©titifs ou tr√®s similaires\n",
    "- Labels incoh√©rents ou ambigus\n",
    "- Utiliser les m√™mes donn√©es pour train et validation\n",
    "\n",
    "### 7.6.2 Choix de la m√©trique\n",
    "\n",
    "Votre **m√©trique d√©termine ce que GEPA optimise** :\n",
    "\n",
    "```python\n",
    "# M√©trique stricte (tout ou rien)\n",
    "def exact_match(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    return 1.0 if (prediction.category == example.category and \n",
    "                   prediction.priority == example.priority) else 0.0\n",
    "\n",
    "# M√©trique avec cr√©dit partiel (souvent meilleure pour GEPA)\n",
    "def partial_match(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    category_match = prediction.category == example.category\n",
    "    priority_match = prediction.priority == example.priority\n",
    "    \n",
    "    if category_match and priority_match:\n",
    "        return 1.0\n",
    "    elif category_match:\n",
    "        return 0.7  # Cat√©gorie plus importante\n",
    "    elif priority_match:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0\n",
    "```\n",
    "\n",
    "üí° **Conseil** : Les m√©triques avec cr√©dit partiel donnent g√©n√©ralement de meilleurs r√©sultats car elles fournissent plus de signal d'apprentissage √† GEPA.\n",
    "\n",
    "### 7.6.3 Choix du niveau d'optimisation\n",
    "\n",
    "| Situation | Niveau recommand√© | Raison |\n",
    "|-----------|------------------|---------|\n",
    "| Premi√®re exp√©rimentation | **light** | Test rapide du concept |\n",
    "| Prototype pour d√©mo | **light** | Balance vitesse/performance |\n",
    "| Application production (non-critique) | **medium** | Bon compromis |\n",
    "| Application production (critique) | **heavy** | Maximum de performance |\n",
    "| Recherche / benchmark | **heavy** | Explorer les limites |\n",
    "\n",
    "### 7.6.4 Configuration du mod√®le de r√©flexion\n",
    "\n",
    "Le **reflection_lm** influence la qualit√© des am√©liorations :\n",
    "\n",
    "‚úÖ **Bonnes pratiques** :\n",
    "- Utiliser un mod√®le avec bonne capacit√© de raisonnement\n",
    "- Temp√©rature √©lev√©e (0.8-1.2) pour la cr√©ativit√©\n",
    "- Max tokens √©lev√© (6000-10000) pour analyses d√©taill√©es\n",
    "- Peut √™tre le m√™me mod√®le que le mod√®le principal\n",
    "\n",
    "‚ùå **√Ä √©viter** :\n",
    "- Mod√®les trop petits (<7B param√®tres)\n",
    "- Temp√©rature trop basse (<0.5)\n",
    "- Max tokens trop faible (<4000)\n",
    "\n",
    "### 7.6.5 √âviter le surapprentissage\n",
    "\n",
    "GEPA peut **surapprendre** sur les donn√©es d'entra√Ænement :\n",
    "\n",
    "‚úÖ **Pr√©vention** :\n",
    "- Toujours avoir un **valset s√©par√©**\n",
    "- Valider sur de **nouvelles donn√©es** apr√®s optimisation\n",
    "- Comparer les scores train vs validation\n",
    "- Si grand √©cart : vos donn√©es ne sont pas assez diversifi√©es\n",
    "\n",
    "```python\n",
    "# Bon: √âvaluation sur donn√©es s√©par√©es\n",
    "score_train = evaluate_module(optimized, train_examples, metric)\n",
    "score_val = evaluate_module(optimized, val_examples, metric)\n",
    "\n",
    "if score_train - score_val > 0.2:\n",
    "    print(\"‚ö†Ô∏è Possible surapprentissage!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 Troubleshooting et erreurs courantes\n",
    "\n",
    "### Erreur 1: `TypeError: GEPA.__init__() got an unexpected keyword argument`\n",
    "\n",
    "**Sympt√¥me** :\n",
    "```\n",
    "TypeError: GEPA.__init__() got an unexpected keyword argument 'breadth'\n",
    "```\n",
    "\n",
    "**Cause** : Utilisation de param√®tres de l'ancienne API GEPA (pre-3.0)\n",
    "\n",
    "**Solution** :\n",
    "```python\n",
    "# ‚ùå Ancienne API (ne fonctionne plus)\n",
    "optimizer = GEPA(\n",
    "    metric=my_metric,\n",
    "    breadth=10,\n",
    "    depth=3\n",
    ")\n",
    "\n",
    "# ‚úÖ Nouvelle API (DSPy 3.0+)\n",
    "optimizer = GEPA(\n",
    "    metric=my_metric,\n",
    "    auto='light',  # ou 'medium', 'heavy'\n",
    "    reflection_lm=reflection_lm\n",
    ")\n",
    "```\n",
    "\n",
    "### Erreur 2: `TypeError: metric() missing required positional argument`\n",
    "\n",
    "**Sympt√¥me** :\n",
    "```\n",
    "TypeError: metric() missing 2 required positional arguments: 'pred_name' and 'pred_trace'\n",
    "```\n",
    "\n",
    "**Cause** : M√©trique pas compatible avec l'API GEPA\n",
    "\n",
    "**Solution** : Ajouter les param√®tres optionnels √† votre m√©trique\n",
    "```python\n",
    "# ‚ùå Ancienne signature\n",
    "def my_metric(example, prediction):\n",
    "    return 1.0 if prediction.category == example.category else 0.0\n",
    "\n",
    "# ‚úÖ Nouvelle signature (compatible GEPA)\n",
    "def my_metric(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    return 1.0 if prediction.category == example.category else 0.0\n",
    "```\n",
    "\n",
    "### Erreur 3: Ollama timeout ou erreur de connexion\n",
    "\n",
    "**Sympt√¥me** :\n",
    "```\n",
    "ConnectionError: Failed to connect to Ollama\n",
    "```\n",
    "\n",
    "**Causes possibles** :\n",
    "1. Ollama n'est pas d√©marr√©\n",
    "2. Mod√®le non t√©l√©charg√©\n",
    "3. M√©moire insuffisante\n",
    "\n",
    "**Solutions** :\n",
    "```bash\n",
    "# 1. V√©rifier qu'Ollama tourne\n",
    "ollama list\n",
    "\n",
    "# 2. D√©marrer Ollama si n√©cessaire\n",
    "ollama serve\n",
    "\n",
    "# 3. T√©l√©charger le mod√®le\n",
    "ollama pull llama3.1:8b\n",
    "\n",
    "# 4. V√©rifier la m√©moire disponible\n",
    "# GEPA + Ollama n√©cessite ~8-12 GB RAM\n",
    "```\n",
    "\n",
    "### Erreur 4: GEPA ne s'am√©liore pas\n",
    "\n",
    "**Sympt√¥me** : Score apr√®s optimisation ‚âà score avant\n",
    "\n",
    "**Causes possibles** :\n",
    "1. Donn√©es d'entra√Ænement insuffisantes ou de mauvaise qualit√©\n",
    "2. M√©trique mal d√©finie\n",
    "3. T√¢che trop difficile pour le mod√®le\n",
    "4. Module d√©j√† bien optimis√©\n",
    "\n",
    "**Solutions** :\n",
    "```python\n",
    "# V√©rifier la qualit√© des donn√©es\n",
    "print(f\"Nombre d'exemples train: {len(trainset)}\")\n",
    "print(f\"Nombre d'exemples val: {len(valset)}\")\n",
    "\n",
    "# V√©rifier la m√©trique\n",
    "for ex in trainset[:5]:\n",
    "    pred = baseline(ticket=ex['ticket'])\n",
    "    score = metric(ex, pred)\n",
    "    print(f\"Score: {score} | Pred: {pred.category}/{pred.priority} | Truth: {ex['category']}/{ex['priority']}\")\n",
    "\n",
    "# Essayer un niveau plus √©lev√©\n",
    "optimizer = GEPA(\n",
    "    metric=metric,\n",
    "    auto='heavy',  # au lieu de 'light'\n",
    "    reflection_lm=reflection_lm\n",
    ")\n",
    "```\n",
    "\n",
    "### Erreur 5: Out of Memory (OOM)\n",
    "\n",
    "**Sympt√¥me** : Ollama ou Python crash avec erreur de m√©moire\n",
    "\n",
    "**Solutions** :\n",
    "1. Utiliser un mod√®le plus petit : `mistral:7b` au lieu de `llama3.1:8b`\n",
    "2. R√©duire `max_tokens` du reflection_lm\n",
    "3. Utiliser `auto='light'` au lieu de `medium` ou `heavy`\n",
    "4. Fermer les autres applications\n",
    "5. Utiliser une API cloud au lieu d'Ollama local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 R√©sum√© de la Partie 7\n",
    "\n",
    "### Ce que nous avons appris\n",
    "\n",
    "1. **GEPA : L'optimiseur le plus sophistiqu√©**\n",
    "   - Combine algorithmes g√©n√©tiques + r√©flexion LLM + Pareto\n",
    "   - Am√©lioration typique : 15-30%\n",
    "   - N√©cessite un mod√®le de r√©flexion (reflection_lm)\n",
    "\n",
    "2. **Configuration essentielle**\n",
    "   - `auto` : 'light', 'medium', ou 'heavy'\n",
    "   - `reflection_lm` : Mod√®le pour analyser les erreurs (temp=1.0, max_tokens=8000)\n",
    "   - `metric` : Doit accepter les param√®tres GEPA (trace, pred_name, pred_trace)\n",
    "\n",
    "3. **Niveaux d'optimisation**\n",
    "   - **light** : 5-10 min, ~200-400 appels LLM, 10-20% am√©lioration\n",
    "   - **medium** : 10-20 min, ~400-800 appels LLM, 15-25% am√©lioration\n",
    "   - **heavy** : 20-40 min, ~800-1600 appels LLM, 20-30% am√©lioration\n",
    "\n",
    "4. **Inspection des r√©sultats**\n",
    "   - Voir les prompts optimis√©s\n",
    "   - Comprendre les changements\n",
    "   - Valider les am√©liorations\n",
    "\n",
    "5. **Bonnes pratiques**\n",
    "   - Donn√©es : 15-20+ exemples diversifi√©s\n",
    "   - M√©trique : Cr√©dit partiel souvent meilleur\n",
    "   - Validation : Toujours sur donn√©es s√©par√©es\n",
    "   - Mod√®le : ‚â•7B param√®tres recommand√©\n",
    "\n",
    "6. **Troubleshooting**\n",
    "   - Erreurs d'API : V√©rifier la signature de la m√©trique\n",
    "   - Pas d'am√©lioration : V√©rifier qualit√© des donn√©es\n",
    "   - OOM : R√©duire niveau ou utiliser mod√®le plus petit\n",
    "\n",
    "### Points cl√©s √† retenir\n",
    "\n",
    "- ‚úÖ **GEPA est puissant** mais n√©cessite temps et ressources\n",
    "- ‚úÖ **Commencer avec 'light'** pour tester le concept\n",
    "- ‚úÖ **Qualit√© des donn√©es = qualit√© des r√©sultats**\n",
    "- ‚úÖ **Toujours valider** sur donn√©es s√©par√©es\n",
    "- ‚úÖ **Inspecter les prompts** pour comprendre les am√©liorations\n",
    "\n",
    "### Quand utiliser GEPA?\n",
    "\n",
    "| Situation | GEPA? | Alternative |\n",
    "|-----------|-------|-------------|\n",
    "| Prototypage rapide | ‚ùå Non | Module simple |\n",
    "| Tests initiaux | ‚ùå Non | BootstrapFewShot |\n",
    "| Application production (non-critique) | ‚ö†Ô∏è Peut-√™tre | MIPRO |\n",
    "| Application production (critique) | ‚úÖ Oui | GEPA medium/heavy |\n",
    "| Recherche / Maximum performance | ‚úÖ Oui | GEPA heavy |\n",
    "| Ressources limit√©es | ‚ùå Non | BootstrapFewShot |\n",
    "\n",
    "### Workflow recommand√©\n",
    "\n",
    "```python\n",
    "# Phase 1: Baseline\n",
    "classifier = SimpleTicketClassifier()\n",
    "score_baseline = evaluate(classifier, valset, metric)\n",
    "\n",
    "# Phase 2: Optimisation simple\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "optimizer_simple = BootstrapFewShot(metric=metric)\n",
    "classifier_simple = optimizer_simple.compile(classifier, trainset)\n",
    "score_simple = evaluate(classifier_simple, valset, metric)\n",
    "\n",
    "# Phase 3: GEPA (si am√©lioration justifie le temps)\n",
    "if score_simple < target_score:\n",
    "    from dspy.teleprompt import GEPA\n",
    "    optimizer_gepa = GEPA(metric=metric, auto='light', reflection_lm=reflection_lm)\n",
    "    classifier_gepa = optimizer_gepa.compile(classifier, trainset, valset)\n",
    "    score_gepa = evaluate(classifier_gepa, valset, metric)\n",
    "    \n",
    "    # Phase 4: GEPA heavy si n√©cessaire\n",
    "    if score_gepa < target_score:\n",
    "        optimizer_heavy = GEPA(metric=metric, auto='heavy', reflection_lm=reflection_lm)\n",
    "        classifier_final = optimizer_heavy.compile(classifier, trainset, valset)\n",
    "```\n",
    "\n",
    "### Ressources additionnelles\n",
    "\n",
    "- üìÑ [Paper GEPA (arXiv)](https://arxiv.org/abs/2507.19457)\n",
    "- üíª [GitHub GEPA](https://github.com/gepa-ai/gepa)\n",
    "- üìñ [Documentation DSPy](https://dspy-docs.vercel.app/)\n",
    "\n",
    "### Prochaines √©tapes\n",
    "\n",
    "- **Partie 8** : Conclusion et mise en production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 8: Conclusion et mise en production\n",
    "\n",
    "## 8.1 R√©capitulatif du parcours\n",
    "\n",
    "F√©licitations! üéâ Vous avez parcouru un tutoriel complet sur DSPy et GEPA. R√©capitulons ce que vous avez appris :\n",
    "\n",
    "### Partie 0: Configuration\n",
    "‚úÖ Installation de DSPy et Ollama  \n",
    "‚úÖ Configuration des mod√®les locaux  \n",
    "‚úÖ Chargement des donn√©es d'entra√Ænement\n",
    "\n",
    "### Partie 1: Signatures\n",
    "‚úÖ D√©finition des entr√©es/sorties avec `dspy.Signature`  \n",
    "‚úÖ 5 exemples progressifs de signatures  \n",
    "‚úÖ Bonnes pratiques pour des signatures efficaces\n",
    "\n",
    "### Partie 2: Modules\n",
    "‚úÖ `Predict` : Module de base  \n",
    "‚úÖ `ChainOfThought` : Raisonnement explicite  \n",
    "‚úÖ `ReAct` : Raisonnement + actions  \n",
    "‚úÖ `ProgramOfThought` : Code + raisonnement  \n",
    "‚úÖ Composition de modules (s√©quentiel, validation, ensemble)\n",
    "\n",
    "### Partie 3: √âvaluation\n",
    "‚úÖ M√©triques d'√©valuation (exact match, partial match)  \n",
    "‚úÖ Fonction `evaluate_module`  \n",
    "‚úÖ Comparaison de diff√©rents modules\n",
    "\n",
    "### Partie 4: Optimiseurs\n",
    "‚úÖ `BootstrapFewShot` : G√©n√©ration d'exemples  \n",
    "‚úÖ `MIPRO` : Optimisation instructions + exemples  \n",
    "‚úÖ `SignatureOptimizer` : Optimisation d'instructions  \n",
    "‚úÖ Comparaison et guide de s√©lection\n",
    "\n",
    "### Partie 5: Multi-mod√®les\n",
    "‚úÖ Configuration Ollama, OpenAI, Anthropic  \n",
    "‚úÖ Benchmarking de mod√®les  \n",
    "‚úÖ Architectures hybrides  \n",
    "‚úÖ Guide de s√©lection par cas d'usage\n",
    "\n",
    "### Partie 6: Patterns avanc√©s\n",
    "‚úÖ Validation des sorties  \n",
    "‚úÖ Retry automatique  \n",
    "‚úÖ Fallback (mod√®le de secours)  \n",
    "‚úÖ Ensemble (vote majoritaire)  \n",
    "‚úÖ Combinaison de patterns\n",
    "\n",
    "### Partie 7: GEPA en pratique\n",
    "‚úÖ Configuration et utilisation de GEPA  \n",
    "‚úÖ Niveaux d'optimisation (light/medium/heavy)  \n",
    "‚úÖ Inspection des prompts optimis√©s  \n",
    "‚úÖ Bonnes pratiques et troubleshooting\n",
    "\n",
    "**Vous ma√Ætrisez maintenant les concepts fondamentaux et avanc√©s de DSPy!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Checklist de mise en production\n",
    "\n",
    "Avant de d√©ployer votre application DSPy en production, voici une checklist compl√®te :\n",
    "\n",
    "### 8.2.1 Donn√©es et m√©triques\n",
    "\n",
    "- [ ] **Donn√©es d'entra√Ænement de qualit√©**\n",
    "  - Au moins 30-50 exemples diversifi√©s\n",
    "  - Labels v√©rifi√©s et coh√©rents\n",
    "  - Couverture de tous les cas d'usage importants\n",
    "  \n",
    "- [ ] **Donn√©es de validation s√©par√©es**\n",
    "  - 15-20% des donn√©es totales\n",
    "  - Jamais utilis√©es pour l'entra√Ænement\n",
    "  - Repr√©sentatives de la production\n",
    "  \n",
    "- [ ] **M√©trique bien d√©finie**\n",
    "  - Refl√®te les objectifs m√©tier\n",
    "  - Compatible avec GEPA (param√®tres optionnels)\n",
    "  - Test√©e sur des cas limites\n",
    "\n",
    "- [ ] **Donn√©es de test pour la production**\n",
    "  - Ensemble de test compl√®tement s√©par√©\n",
    "  - Mis √† jour r√©guli√®rement\n",
    "  - Utilis√© pour monitoring continu\n",
    "\n",
    "### 8.2.2 Optimisation\n",
    "\n",
    "- [ ] **Module de base test√©**\n",
    "  - Fonctionne correctement sur les cas simples\n",
    "  - Performance baseline document√©e\n",
    "  - Code propre et maintenable\n",
    "\n",
    "- [ ] **Optimisation appropri√©e**\n",
    "  - BootstrapFewShot ou MIPRO pour d√©marrer\n",
    "  - GEPA si performance critique\n",
    "  - Niveau d'optimisation adapt√© aux contraintes\n",
    "\n",
    "- [ ] **Validation crois√©e**\n",
    "  - Performance train vs validation v√©rifi√©e\n",
    "  - Pas de surapprentissage d√©tect√©\n",
    "  - Tests sur donn√©es r√©elles de production\n",
    "\n",
    "### 8.2.3 Robustesse\n",
    "\n",
    "- [ ] **Validation des sorties**\n",
    "  - V√©rification des formats\n",
    "  - Valeurs dans les plages attendues\n",
    "  - Gestion des cas invalides\n",
    "\n",
    "- [ ] **Gestion des erreurs**\n",
    "  - Retry pour les erreurs temporaires\n",
    "  - Fallback si mod√®le principal √©choue\n",
    "  - Logs d√©taill√©s pour le debugging\n",
    "\n",
    "- [ ] **Monitoring**\n",
    "  - M√©triques de performance en temps r√©el\n",
    "  - Alertes sur d√©gradation\n",
    "  - Collecte des erreurs\n",
    "\n",
    "### 8.2.4 Infrastructure\n",
    "\n",
    "- [ ] **Choix du mod√®le**\n",
    "  - Ollama pour confidentialit√©/co√ªts\n",
    "  - API cloud pour disponibilit√©/performance\n",
    "  - Architecture hybride pour optimiser\n",
    "\n",
    "- [ ] **Ressources suffisantes**\n",
    "  - RAM : 8-16 GB pour Ollama\n",
    "  - CPU/GPU : Selon le mod√®le\n",
    "  - Bande passante : Pour APIs cloud\n",
    "\n",
    "- [ ] **S√©curit√©**\n",
    "  - Cl√©s API stock√©es dans variables d'environnement\n",
    "  - Pas de secrets dans le code\n",
    "  - Logs ne contenant pas de donn√©es sensibles\n",
    "\n",
    "### 8.2.5 Documentation\n",
    "\n",
    "- [ ] **Code document√©**\n",
    "  - Docstrings pour toutes les classes/fonctions\n",
    "  - Commentaires pour la logique complexe\n",
    "  - README avec instructions de d√©ploiement\n",
    "\n",
    "- [ ] **Tests automatis√©s**\n",
    "  - Tests unitaires pour les composants\n",
    "  - Tests d'int√©gration end-to-end\n",
    "  - Tests de r√©gression sur donn√©es fixes\n",
    "\n",
    "- [ ] **Versioning**\n",
    "  - Git avec commits clairs\n",
    "  - Tags pour les versions de production\n",
    "  - Historique des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Adapter ce tutoriel √† votre cas d'usage\n",
    "\n",
    "Ce tutoriel utilise la classification de tickets IT comme exemple, mais DSPy peut √™tre appliqu√© √† de nombreux cas d'usage. Voici comment adapter ce code √† votre probl√®me.\n",
    "\n",
    "### 8.3.1 D√©finir votre t√¢che\n",
    "\n",
    "**Questions √† se poser** :\n",
    "1. Quelle est mon entr√©e? (texte, image, tableau, etc.)\n",
    "2. Quelle est ma sortie attendue? (classification, extraction, g√©n√©ration, etc.)\n",
    "3. Ai-je des exemples d'entr√©e/sortie?\n",
    "4. Comment mesurer si la sortie est correcte?\n",
    "\n",
    "### 8.3.2 Cr√©er votre signature\n",
    "\n",
    "```python\n",
    "# Exemple 1: Analyse de sentiments\n",
    "class SentimentAnalysis(dspy.Signature):\n",
    "    \"\"\"Analyser le sentiment d'un avis client\"\"\"\n",
    "    review = dspy.InputField(desc=\"Avis client en texte libre\")\n",
    "    sentiment = dspy.OutputField(desc=\"Sentiment: Positif, N√©gatif, ou Neutre\")\n",
    "    confidence = dspy.OutputField(desc=\"Niveau de confiance: Faible, Moyen, √âlev√©\")\n",
    "\n",
    "# Exemple 2: Extraction d'informations\n",
    "class InformationExtraction(dspy.Signature):\n",
    "    \"\"\"Extraire des informations structur√©es d'un texte\"\"\"\n",
    "    text = dspy.InputField(desc=\"Texte source\")\n",
    "    entities = dspy.OutputField(desc=\"Entit√©s trouv√©es (personnes, lieux, organisations)\")\n",
    "    dates = dspy.OutputField(desc=\"Dates mentionn√©es\")\n",
    "    \n",
    "# Exemple 3: G√©n√©ration de contenu\n",
    "class ContentGeneration(dspy.Signature):\n",
    "    \"\"\"G√©n√©rer une description de produit marketing\"\"\"\n",
    "    product_name = dspy.InputField(desc=\"Nom du produit\")\n",
    "    features = dspy.InputField(desc=\"Liste des caract√©ristiques principales\")\n",
    "    tone = dspy.InputField(desc=\"Ton souhait√©: Professionnel, D√©contract√©, Technique\")\n",
    "    description = dspy.OutputField(desc=\"Description marketing en 2-3 phrases\")\n",
    "\n",
    "# Exemple 4: Question-r√©ponse\n",
    "class QuestionAnswering(dspy.Signature):\n",
    "    \"\"\"R√©pondre √† une question bas√©e sur un contexte\"\"\"\n",
    "    context = dspy.InputField(desc=\"Contexte ou document source\")\n",
    "    question = dspy.InputField(desc=\"Question de l'utilisateur\")\n",
    "    answer = dspy.OutputField(desc=\"R√©ponse concise bas√©e sur le contexte\")\n",
    "    source = dspy.OutputField(desc=\"Citation du contexte utilis√© pour r√©pondre\")\n",
    "```\n",
    "\n",
    "### 8.3.3 Pr√©parer vos donn√©es\n",
    "\n",
    "```python\n",
    "# Format de base pour vos donn√©es\n",
    "trainset = [\n",
    "    {\n",
    "        'input_field1': 'valeur1',\n",
    "        'input_field2': 'valeur2',\n",
    "        'output_field': 'sortie attendue'\n",
    "    },\n",
    "    # ... plus d'exemples\n",
    "]\n",
    "\n",
    "# Convertir au format DSPy\n",
    "train_examples = [\n",
    "    dspy.Example(\n",
    "        input_field1=ex['input_field1'],\n",
    "        input_field2=ex['input_field2'],\n",
    "        output_field=ex['output_field']\n",
    "    ).with_inputs('input_field1', 'input_field2')\n",
    "    for ex in trainset\n",
    "]\n",
    "```\n",
    "\n",
    "### 8.3.4 D√©finir votre m√©trique\n",
    "\n",
    "```python\n",
    "def your_metric(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    M√©trique adapt√©e √† votre t√¢che\n",
    "    \n",
    "    Retourne un score entre 0.0 et 1.0\n",
    "    \"\"\"\n",
    "    # Exemple 1: Exact match\n",
    "    if prediction.output_field == example.output_field:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "    # Exemple 2: Similarit√© partielle\n",
    "    # from difflib import SequenceMatcher\n",
    "    # similarity = SequenceMatcher(None, \n",
    "    #     prediction.output_field.lower(), \n",
    "    #     example.output_field.lower()\n",
    "    # ).ratio()\n",
    "    # return similarity\n",
    "    \n",
    "    # Exemple 3: M√©trique composite\n",
    "    # score = 0.0\n",
    "    # if prediction.field1 == example.field1:\n",
    "    #     score += 0.5\n",
    "    # if prediction.field2 == example.field2:\n",
    "    #     score += 0.5\n",
    "    # return score\n",
    "```\n",
    "\n",
    "### 8.3.5 Template de d√©marrage complet\n",
    "\n",
    "```python\n",
    "import dspy\n",
    "\n",
    "# 1. Configuration\n",
    "lm = dspy.LM(\n",
    "    model='ollama_chat/llama3.1:8b',\n",
    "    api_base='http://localhost:11434',\n",
    "    temperature=0.3\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# 2. Signature\n",
    "class YourTask(dspy.Signature):\n",
    "    \"\"\"Description claire de votre t√¢che\"\"\"\n",
    "    input_field = dspy.InputField(desc=\"Description de l'entr√©e\")\n",
    "    output_field = dspy.OutputField(desc=\"Description de la sortie\")\n",
    "\n",
    "# 3. Module\n",
    "class YourModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predictor = dspy.ChainOfThought(YourTask)\n",
    "    \n",
    "    def forward(self, input_field):\n",
    "        result = self.predictor(input_field=input_field)\n",
    "        return dspy.Prediction(output_field=result.output_field)\n",
    "\n",
    "# 4. Donn√©es\n",
    "trainset = [...]  # Vos donn√©es\n",
    "train_examples = [\n",
    "    dspy.Example(**ex).with_inputs('input_field')\n",
    "    for ex in trainset\n",
    "]\n",
    "\n",
    "# 5. M√©trique\n",
    "def your_metric(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
    "    return 1.0 if prediction.output_field == example.output_field else 0.0\n",
    "\n",
    "# 6. √âvaluation\n",
    "module = YourModule()\n",
    "from Partie3 import evaluate_module  # Utiliser la fonction du tutoriel\n",
    "score = evaluate_module(module, train_examples[:10], your_metric)\n",
    "print(f\"Score baseline: {score:.2%}\")\n",
    "\n",
    "# 7. Optimisation (optionnel)\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "optimizer = BootstrapFewShot(metric=your_metric, max_bootstrapped_demos=3)\n",
    "optimized_module = optimizer.compile(module, trainset=train_examples)\n",
    "score_optimized = evaluate_module(optimized_module, train_examples[:10], your_metric)\n",
    "print(f\"Score optimis√©: {score_optimized:.2%}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Prochaines √©tapes et apprentissage continu\n",
    "\n",
    "### 8.4.1 Approfondir DSPy\n",
    "\n",
    "**Concepts avanc√©s √† explorer** :\n",
    "\n",
    "1. **Retrieval-Augmented Generation (RAG)**\n",
    "   - Combiner DSPy avec des bases de donn√©es vectorielles\n",
    "   - Modules : `dspy.Retrieve`, `dspy.RetrieveThenGenerate`\n",
    "   - Cas d'usage : QA sur documents, chatbots avec connaissance sp√©cifique\n",
    "\n",
    "2. **Agents multi-√©tapes**\n",
    "   - Cha√Ænes de d√©cisions complexes\n",
    "   - Utiliser `ReAct` pour des t√¢ches it√©ratives\n",
    "   - Cas d'usage : Assistants autonomes, automatisation de workflows\n",
    "\n",
    "3. **Fine-tuning de mod√®les**\n",
    "   - DSPy peut g√©n√©rer des datasets pour fine-tuning\n",
    "   - Exporter les prompts optimis√©s comme donn√©es d'entra√Ænement\n",
    "   - Cas d'usage : Mod√®les sp√©cialis√©s pour votre domaine\n",
    "\n",
    "4. **Optimiseurs avanc√©s**\n",
    "   - `BayesianSignatureOptimizer` : Optimisation bay√©sienne\n",
    "   - `KNNFewShot` : S√©lection dynamique d'exemples\n",
    "   - Combinaison d'optimiseurs\n",
    "\n",
    "### 8.4.2 Cas d'usage inspirants\n",
    "\n",
    "**Applications r√©elles de DSPy** :\n",
    "\n",
    "- üè• **Sant√©** : Extraction d'informations m√©dicales, classification de sympt√¥mes\n",
    "- üíº **Entreprise** : Analyse de contrats, classification de documents\n",
    "- üéì **√âducation** : Correction automatique, g√©n√©ration de quiz\n",
    "- üõí **E-commerce** : Cat√©gorisation de produits, recommandations\n",
    "- üì∞ **M√©dias** : R√©sum√©s d'articles, d√©tection de fake news\n",
    "- üí¨ **Customer Support** : Classification de tickets (comme ce tutoriel!), routage automatique\n",
    "\n",
    "### 8.4.3 Ressources recommand√©es\n",
    "\n",
    "**Documentation officielle** :\n",
    "- üìñ [DSPy Documentation](https://dspy-docs.vercel.app/) - Guide complet\n",
    "- üíª [DSPy GitHub](https://github.com/stanfordnlp/dspy) - Code source et exemples\n",
    "- üìÑ [Paper DSPy](https://arxiv.org/abs/2310.03714) - Recherche originale\n",
    "\n",
    "**GEPA** :\n",
    "- üìÑ [Paper GEPA](https://arxiv.org/abs/2507.19457) - Algorithme d√©taill√©\n",
    "- üíª [GEPA GitHub](https://github.com/gepa-ai/gepa) - Impl√©mentation\n",
    "\n",
    "**Ollama** :\n",
    "- üìñ [Ollama Documentation](https://ollama.ai/docs) - Guide d'installation\n",
    "- ü§ñ [Ollama Models Library](https://ollama.ai/library) - Catalogue de mod√®les\n",
    "- üí¨ [Ollama Discord](https://discord.gg/ollama) - Communaut√© active\n",
    "\n",
    "**Communaut√© et support** :\n",
    "- üí¨ [DSPy Discord](https://discord.gg/dspy) - Discussions et aide\n",
    "- üê¶ [Twitter @DSPy_ai](https://twitter.com/dspy_ai) - Actualit√©s\n",
    "- üì∫ [Tutoriels YouTube](https://www.youtube.com/results?search_query=dspy+tutorial) - Vid√©os explicatives\n",
    "\n",
    "### 8.4.4 Contribuer √† l'√©cosyst√®me\n",
    "\n",
    "**Fa√ßons de contribuer** :\n",
    "\n",
    "1. **Partager vos cas d'usage**\n",
    "   - Publier vos exp√©riences sur GitHub\n",
    "   - √âcrire des articles de blog\n",
    "   - Pr√©senter dans des meetups\n",
    "\n",
    "2. **Am√©liorer la documentation**\n",
    "   - Signaler des erreurs ou ambigu√Øt√©s\n",
    "   - Proposer de nouveaux exemples\n",
    "   - Traduire la documentation\n",
    "\n",
    "3. **D√©velopper des extensions**\n",
    "   - Nouveaux optimiseurs\n",
    "   - Nouveaux modules\n",
    "   - Int√©grations avec d'autres outils\n",
    "\n",
    "4. **Aider la communaut√©**\n",
    "   - R√©pondre aux questions sur Discord\n",
    "   - Partager vos solutions\n",
    "   - Mentorer les d√©butants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Conclusion\n",
    "\n",
    "### Le pouvoir de DSPy\n",
    "\n",
    "DSPy repr√©sente un **changement de paradigme** dans le d√©veloppement avec les LLMs :\n",
    "\n",
    "**Avant DSPy** :\n",
    "- ‚ùå Prompts √©crits manuellement et fragiles\n",
    "- ‚ùå Difficile de maintenir la coh√©rence\n",
    "- ‚ùå Optimisation par essai-erreur\n",
    "- ‚ùå Code sp√©cifique √† chaque mod√®le\n",
    "\n",
    "**Avec DSPy** :\n",
    "- ‚úÖ Prompts optimis√©s automatiquement\n",
    "- ‚úÖ Abstraction propre et maintenable\n",
    "- ‚úÖ Optimisation algorithmique (GEPA, MIPRO)\n",
    "- ‚úÖ Ind√©pendance du fournisseur LLM\n",
    "\n",
    "### Principes cl√©s √† retenir\n",
    "\n",
    "1. **D√©claratif > Imp√©ratif**\n",
    "   - D√©finissez *ce que* vous voulez (Signature)\n",
    "   - Laissez DSPy d√©terminer *comment* le faire\n",
    "\n",
    "2. **Optimisation algorithmique > Ing√©nierie manuelle**\n",
    "   - Les optimiseurs trouvent de meilleurs prompts que l'humain\n",
    "   - GEPA utilise la r√©flexion LLM pour s'am√©liorer\n",
    "\n",
    "3. **Composition > Monolithe**\n",
    "   - Construisez des syst√®mes complexes √† partir de modules simples\n",
    "   - Chaque module a une responsabilit√© claire\n",
    "\n",
    "4. **Mesure > Intuition**\n",
    "   - D√©finissez des m√©triques claires\n",
    "   - Validez sur des donn√©es r√©elles\n",
    "   - It√©rez bas√© sur les donn√©es\n",
    "\n",
    "5. **Flexibilit√© > Lock-in**\n",
    "   - Changez de mod√®le sans changer le code\n",
    "   - Testez facilement diff√©rentes approches\n",
    "   - Adaptez selon vos contraintes\n",
    "\n",
    "### Votre parcours commence maintenant\n",
    "\n",
    "Vous avez maintenant tous les outils pour :\n",
    "- üöÄ Construire des applications LLM robustes et performantes\n",
    "- üîß Optimiser automatiquement vos prompts avec GEPA\n",
    "- üéØ Adapter DSPy √† vos cas d'usage sp√©cifiques\n",
    "- üåü Contribuer √† l'√©cosyst√®me DSPy\n",
    "\n",
    "### Message final\n",
    "\n",
    "L'IA g√©n√©rative √©volue rapidement. **DSPy vous donne une base solide** pour construire des syst√®mes qui :\n",
    "- √âvoluent avec les nouveaux mod√®les\n",
    "- S'am√©liorent automatiquement\n",
    "- Restent maintenables √† long terme\n",
    "\n",
    "**N'attendez plus** :\n",
    "1. Identifiez un probl√®me dans votre domaine\n",
    "2. Cr√©ez une signature DSPy\n",
    "3. Collectez quelques exemples\n",
    "4. Laissez GEPA optimiser\n",
    "5. D√©ployez en production\n",
    "\n",
    "Chaque grande application commence par un premier exemple. **Le v√¥tre est √† port√©e de main.**\n",
    "\n",
    "---\n",
    "\n",
    "### Remerciements\n",
    "\n",
    "Merci d'avoir suivi ce tutoriel jusqu'au bout! üôè\n",
    "\n",
    "Si ce tutoriel vous a √©t√© utile :\n",
    "- ‚≠ê Donnez une √©toile au projet sur GitHub\n",
    "- üí¨ Partagez vos r√©ussites avec la communaut√©\n",
    "- üêõ Signalez les erreurs ou am√©liorations possibles\n",
    "- ü§ù Aidez d'autres d√©veloppeurs √† d√©marrer avec DSPy\n",
    "\n",
    "**Bon d√©veloppement avec DSPy et GEPA!** üéâ\n",
    "\n",
    "---\n",
    "\n",
    "*Ce tutoriel a √©t√© cr√©√© pour aider la communaut√© francophone √† d√©couvrir DSPy et GEPA. N'h√©sitez pas √† l'adapter, le partager et le faire √©voluer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\" \" * 25 + \"üéì TUTORIEL TERMIN√â! üéì\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Vous avez compl√©t√© le tutoriel DSPy et GEPA!\")\n",
    "print()\n",
    "print(\"üìä R√©sum√© de ce que vous avez appris:\")\n",
    "print()\n",
    "print(\"   ‚úÖ Partie 0: Configuration et installation\")\n",
    "print(\"   ‚úÖ Partie 1: Signatures (5 exemples)\")\n",
    "print(\"   ‚úÖ Partie 2: Modules (Predict, ChainOfThought, ReAct, ProgramOfThought)\")\n",
    "print(\"   ‚úÖ Partie 3: √âvaluation et m√©triques\")\n",
    "print(\"   ‚úÖ Partie 4: Optimiseurs (BootstrapFewShot, MIPRO, etc.)\")\n",
    "print(\"   ‚úÖ Partie 5: Multi-mod√®les et architectures hybrides\")\n",
    "print(\"   ‚úÖ Partie 6: Patterns avanc√©s (validation, retry, fallback, ensemble)\")\n",
    "print(\"   ‚úÖ Partie 7: GEPA en pratique\")\n",
    "print(\"   ‚úÖ Partie 8: Conclusion et mise en production\")\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"üöÄ Prochaines √©tapes sugg√©r√©es:\")\n",
    "print()\n",
    "print(\"   1. Adaptez ce code √† votre cas d'usage\")\n",
    "print(\"   2. Collectez vos propres donn√©es d'entra√Ænement\")\n",
    "print(\"   3. Exp√©rimentez avec diff√©rents mod√®les\")\n",
    "print(\"   4. Optimisez avec GEPA\")\n",
    "print(\"   5. D√©ployez en production!\")\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"üí° Ressources:\")\n",
    "print()\n",
    "print(\"   üìñ Documentation: https://dspy-docs.vercel.app/\")\n",
    "print(\"   üíª GitHub DSPy:   https://github.com/stanfordnlp/dspy\")\n",
    "print(\"   üí¨ Discord:       https://discord.gg/dspy\")\n",
    "print(\"   üìÑ Paper GEPA:    https://arxiv.org/abs/2507.19457\")\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Bon d√©veloppement avec DSPy! üéâ\")\n",
    "print()\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just add a ‚Äòno_think: str‚Äô input field on your signature and pass it ‚Äòfoo.Predict(no_think=‚Äú/no_think‚Äù‚Äô\n",
    "\n",
    "# https://github.com/Columbia-NLP-Lab/PAPILLON/blob/main/papillon_tutorial.ipynb\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy-gepa-demo (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}