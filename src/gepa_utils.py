"""
GEPA optimization utilities.

This module provides utilities for optimizing DSPy modules using GEPA
(Genetic-Pareto Algorithm), the most sophisticated optimizer in DSPy.
"""

from dspy.teleprompt import GEPA
import dspy
from typing import Callable, List


def optimize_with_gepa(
    module: dspy.Module,
    trainset: List[dspy.Example],
    valset: List[dspy.Example],
    metric: Callable,
    reflection_lm: dspy.LM,
    auto: str = 'light'
) -> dspy.Module:
    """
    Optimize a module using GEPA.

    GEPA combines genetic algorithms, LLM reflection, and Pareto optimization
    to find optimal prompts and demonstrations.

    Args:
        module: The DSPy module to optimize
        trainset: Training examples
        valset: Validation examples (for preventing overfitting)
        metric: Metric function (must be compatible with GEPA)
        reflection_lm: Language model for error analysis
        auto: Optimization level ('light', 'medium', or 'heavy')

    Returns:
        Optimized module

    GEPA optimization levels:
    - 'light': 5-10 minutes, ~200-400 LLM calls, 10-20% improvement
    - 'medium': 10-20 minutes, ~400-800 LLM calls, 15-25% improvement
    - 'heavy': 20-40 minutes, ~800-1600 LLM calls, 20-30% improvement
    """
    print("=" * 70)
    print(f"üß¨ OPTIMIZING WITH GEPA - MODE '{auto.upper()}'")
    print("=" * 70)
    print()

    # Estimate time
    time_estimates = {
        'light': '5-10 minutes',
        'medium': '10-20 minutes',
        'heavy': '20-40 minutes'
    }

    print(f"‚è∞ Estimated time: {time_estimates.get(auto, 'unknown')}")
    print("‚òï This is a good time for a coffee break!\n")

    # Configure GEPA optimizer
    optimizer = GEPA(
        metric=metric,
        auto=auto,
        reflection_lm=reflection_lm
    )

    try:
        # Run optimization
        optimized = optimizer.compile(
            student=module,
            trainset=trainset,
            valset=valset
        )

        print("\n‚úÖ GEPA optimization complete!")
        return optimized

    except Exception as e:
        print(f"\n‚ùå GEPA optimization error: {e}")
        print("   Troubleshooting tips:")
        print("   - Check that Ollama is running (ollama list)")
        print("   - Verify model is downloaded (ollama pull llama3.1:8b)")
        print("   - Ensure sufficient memory (~8-12 GB RAM)")
        print("   - Check metric signature (needs trace, pred_name, pred_trace params)")
        raise


def inspect_gepa_prompts(optimized_module: dspy.Module):
    """
    Inspect the prompts and demonstrations generated by GEPA.

    Args:
        optimized_module: The GEPA-optimized module
    """
    print("üîç Inspecting GEPA optimizations\n")

    if not hasattr(optimized_module, 'classifier'):
        print("‚ÑπÔ∏è Module structure doesn't match expected format")
        return

    predictor = optimized_module.classifier

    # 1. Check for optimized signature
    if hasattr(predictor, 'extended_signature'):
        print("=" * 70)
        print("üìù OPTIMIZED SIGNATURE")
        print("=" * 70)
        sig = predictor.extended_signature
        print(f"Docstring: {sig.__doc__}")
        print()

        # Show input fields
        if hasattr(sig, 'input_fields'):
            print("Input fields:")
            for name, field in sig.input_fields.items():
                desc = getattr(field, 'desc', 'N/A')
                print(f"  - {name}: {desc}")

        # Show output fields
        if hasattr(sig, 'output_fields'):
            print("\nOutput fields:")
            for name, field in sig.output_fields.items():
                desc = getattr(field, 'desc', 'N/A')
                print(f"  - {name}: {desc}")
        print()

    # 2. Check for demonstration examples
    if hasattr(predictor, 'demos') and predictor.demos:
        print("=" * 70)
        print("üìö DEMONSTRATION EXAMPLES")
        print("=" * 70)
        print(f"Number of examples: {len(predictor.demos)}\n")

        # Show first 3 examples
        for i, demo in enumerate(predictor.demos[:3], 1):
            print(f"Example {i}:")
            print(f"  Ticket: {demo.ticket[:80]}...")
            if hasattr(demo, 'category'):
                print(f"  Category: {demo.category}")
            if hasattr(demo, 'priority'):
                print(f"  Priority: {demo.priority}")
            print()
    else:
        print("‚ÑπÔ∏è No demonstration examples found")
        print("   (GEPA may have optimized only instructions)")

    print("=" * 70)
    print("üí° What GEPA did:")
    print("=" * 70)
    print("‚úÖ Analyzed errors on training data")
    print("‚úÖ Generated prompt variants")
    print("‚úÖ Used LLM reflection to propose improvements")
    print("‚úÖ Selected best configuration via Pareto optimization")
    print("=" * 70)


def compare_before_after_gepa(
    baseline_module: dspy.Module,
    optimized_module: dspy.Module,
    test_cases: List[dict],
    metric: Callable
):
    """
    Compare baseline vs GEPA-optimized module on test cases.

    Args:
        baseline_module: Original module
        optimized_module: GEPA-optimized module
        test_cases: List of test examples
        metric: Evaluation metric
    """
    print("üß™ Comparing Baseline vs GEPA\n")
    print("=" * 100)
    print(f"{'Ticket':<50} | {'Expected':<20} | {'Baseline':<20} | {'GEPA':<20}")
    print("=" * 100)

    correct_baseline = 0
    correct_gepa = 0

    for test in test_cases:
        ticket = test['ticket']
        expected = f"{test['category']}/{test['priority']}"

        # Baseline prediction
        pred_baseline = baseline_module(ticket=ticket)
        baseline_result = f"{pred_baseline.category}/{pred_baseline.priority}"
        baseline_match = (pred_baseline.category == test['category'] and
                         pred_baseline.priority == test['priority'])

        # GEPA prediction
        pred_gepa = optimized_module(ticket=ticket)
        gepa_result = f"{pred_gepa.category}/{pred_gepa.priority}"
        gepa_match = (pred_gepa.category == test['category'] and
                     pred_gepa.priority == test['priority'])

        if baseline_match:
            correct_baseline += 1
        if gepa_match:
            correct_gepa += 1

        # Display with indicators
        baseline_icon = "‚úÖ" if baseline_match else "‚ùå"
        gepa_icon = "‚úÖ" if gepa_match else "‚ùå"

        print(f"{ticket[:48]:<50} | {expected:<20} | {baseline_icon} {baseline_result:<17} | {gepa_icon} {gepa_result:<17}")

    print("=" * 100)
    print(f"Accuracy on test cases:")
    print(f"  Baseline: {correct_baseline}/{len(test_cases)} ({correct_baseline/len(test_cases)*100:.0f}%)")
    print(f"  GEPA:     {correct_gepa}/{len(test_cases)} ({correct_gepa/len(test_cases)*100:.0f}%)")
    print("=" * 100)


if __name__ == "__main__":
    # Example usage
    from config import configure_ollama, configure_reflection_lm
    from modules import SimpleTicketClassifier
    from data import get_train_examples, get_val_examples
    from metrics import exact_match_metric
    from evaluation import evaluate_module

    print("Testing GEPA utilities...\n")

    # Configure models
    lm_main = configure_ollama()
    reflection_lm = configure_reflection_lm()

    # Get data
    train_examples = get_train_examples()
    val_examples = get_val_examples()

    # Create baseline module
    baseline = SimpleTicketClassifier()

    # Evaluate baseline
    print("üìä Evaluating baseline...")
    score_before = evaluate_module(baseline, val_examples, exact_match_metric)
    print(f"   Baseline score: {score_before:.2%}\n")

    # Optimize with GEPA (light mode for testing)
    optimized = optimize_with_gepa(
        baseline,
        train_examples,
        val_examples,
        exact_match_metric,
        reflection_lm,
        auto='light'
    )

    # Evaluate optimized
    print("\nüìä Evaluating GEPA-optimized module...")
    score_after = evaluate_module(optimized, val_examples, exact_match_metric)
    print(f"   GEPA score: {score_after:.2%}")

    # Calculate improvement
    improvement = ((score_after - score_before) / score_before * 100) if score_before > 0 else 0
    print(f"   Improvement: {improvement:+.1f}%\n")

    # Inspect optimizations
    inspect_gepa_prompts(optimized)
